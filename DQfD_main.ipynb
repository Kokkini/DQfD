{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQfD_main.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/Kokkini/DQfD/blob/master/DQfD_main.ipynb",
      "authorship_tag": "ABX9TyNEjqFU1creNTrO+bzwCaXi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kokkini/DQfD/blob/master/DQfD_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLKIVoRu16Fy",
        "colab_type": "code",
        "outputId": "d6489f26-e798-4266-beb8-9cae3a92b639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "# !pip install stable-baselines[mpi]==2.10.0\n",
        "!pip install gym\n",
        "!pip install pynput"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Collecting pynput\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/0a/ea13c055a90b1aff5945e7eb330584f15e5282aead15a8f3cdb977a1534e/pynput-1.6.8-py2.py3-none-any.whl (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pynput) (1.12.0)\n",
            "Collecting python-xlib>=0.17; \"linux\" in sys_platform\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/10/2eb938852a9bdf6745808f141c9fede76b1bd5a9530859bacc71985d29d9/python_xlib-0.27-py2.py3-none-any.whl (174kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 7.4MB/s \n",
            "\u001b[?25hInstalling collected packages: python-xlib, pynput\n",
            "Successfully installed pynput-1.6.8 python-xlib-0.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99IlmkkQ7mcr",
        "colab_type": "code",
        "outputId": "1b2bd0b1-aae6-41b0-e914-735a98d74242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun  5 03:55:38 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7VAg5r42H9q",
        "colab_type": "code",
        "outputId": "70a36e01-4b7f-499a-97c6-0208d0346baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from getpass import getpass\n",
        "\n",
        "def clone_with_token(repo_name, owner_name=\"Kokkini\", user_email=\"trannhatquang1104@gmail.com\", user_name=\"Kokkini\"):\n",
        "  GIT_TOKEN = getpass('insert token: ')\n",
        "  GIT_PATH = f\"https://{GIT_TOKEN}@github.com/{owner_name}/{repo_name}.git\"\n",
        "  !git config --global user.email \"{user_email}\"\n",
        "  !git config --global user.name \"{user_name}\"\n",
        "  !git clone \"{GIT_PATH}\"\n",
        "  GIT_TOKEN, GIT_PATH = \"\", \"\"\n",
        "clone_with_token(\"DQfD\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "insert token: ··········\n",
            "Cloning into 'DQfD'...\n",
            "remote: Enumerating objects: 249, done.\u001b[K\n",
            "remote: Counting objects: 100% (249/249), done.\u001b[K\n",
            "remote: Compressing objects: 100% (207/207), done.\u001b[K\n",
            "remote: Total 249 (delta 148), reused 92 (delta 37), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (249/249), 232.52 KiB | 5.81 MiB/s, done.\n",
            "Resolving deltas: 100% (148/148), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tBPFxBF55tf",
        "colab_type": "code",
        "outputId": "0f1d99ac-0767-41e5-991d-7e31294bc1a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd DQfD/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DQfD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1mT261H2VMr",
        "colab_type": "code",
        "outputId": "9226885d-22a6-4860-d1d6-18cca8f51964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_atari.py --pre_train_timesteps=1e5 --num_timesteps=2e6 --batch_size=64 --buffer_size=5e5 --lr=5e-4 --save_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/models14\" --load_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/models14\" --demo_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/human.BreakoutNoFrameskip-v4.pkl\" --log_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/logs14\" "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "| loss_td                 | 0.008279212  |\n",
            "| losses_all              | 0.005423574  |\n",
            "| max 100 episode reward  | 38           |\n",
            "| mean 100 episode reward | 5.25         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1080872      |\n",
            "------------------------------------------\n",
            " 54% 1083364/2000000 [2:22:22<1:56:18, 131.36it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.112        |\n",
            "| elapsed time            | 02:41:57     |\n",
            "| episodes                | 3510         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022620908 |\n",
            "| loss_margin             | 0.02006504   |\n",
            "| loss_n_td               | 0.0030918634 |\n",
            "| loss_td                 | 0.008019887  |\n",
            "| losses_all              | 0.0060844594 |\n",
            "| max 100 episode reward  | 25           |\n",
            "| mean 100 episode reward | 4.97         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1083368      |\n",
            "------------------------------------------\n",
            " 54% 1085612/2000000 [2:22:40<1:52:45, 135.16it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.112        |\n",
            "| elapsed time            | 02:42:16     |\n",
            "| episodes                | 3520         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002265745  |\n",
            "| loss_margin             | 0.0219187    |\n",
            "| loss_n_td               | 0.00522039   |\n",
            "| loss_td                 | 0.011171844  |\n",
            "| losses_all              | 0.0064630304 |\n",
            "| max 100 episode reward  | 25           |\n",
            "| mean 100 episode reward | 4.86         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1085619      |\n",
            "------------------------------------------\n",
            " 54% 1088405/2000000 [2:23:02<1:54:59, 132.13it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.112        |\n",
            "| elapsed time            | 02:42:38     |\n",
            "| episodes                | 3530         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021699916 |\n",
            "| loss_margin             | 0.0018461496 |\n",
            "| loss_n_td               | 0.0066420026 |\n",
            "| loss_td                 | 0.037273236  |\n",
            "| losses_all              | 0.0071869995 |\n",
            "| max 100 episode reward  | 25           |\n",
            "| mean 100 episode reward | 4.68         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1088414      |\n",
            "------------------------------------------\n",
            " 55% 1091318/2000000 [2:23:26<1:54:44, 132.00it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.112         |\n",
            "| elapsed time            | 02:43:01      |\n",
            "| episodes                | 3540          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.002294911   |\n",
            "| loss_margin             | 0.00056767464 |\n",
            "| loss_n_td               | 0.0033996773  |\n",
            "| loss_td                 | 0.012696369   |\n",
            "| losses_all              | 0.004650558   |\n",
            "| max 100 episode reward  | 25            |\n",
            "| mean 100 episode reward | 4.64          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1091318       |\n",
            "-------------------------------------------\n",
            " 55% 1093918/2000000 [2:23:47<2:02:04, 123.71it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.112        |\n",
            "| elapsed time            | 02:43:23     |\n",
            "| episodes                | 3550         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022497436 |\n",
            "| loss_margin             | 0.034564063  |\n",
            "| loss_n_td               | 0.0032908511 |\n",
            "| loss_td                 | 0.014445646  |\n",
            "| losses_all              | 0.0075752866 |\n",
            "| max 100 episode reward  | 25           |\n",
            "| mean 100 episode reward | 4.66         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1093921      |\n",
            "------------------------------------------\n",
            " 55% 1097053/2000000 [2:24:12<1:54:04, 131.92it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.112        |\n",
            "| elapsed time            | 02:43:48     |\n",
            "| episodes                | 3560         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002305643  |\n",
            "| loss_margin             | 0.011519039  |\n",
            "| loss_n_td               | 0.005168181  |\n",
            "| loss_td                 | 0.03382092   |\n",
            "| losses_all              | 0.0072834715 |\n",
            "| max 100 episode reward  | 25           |\n",
            "| mean 100 episode reward | 4.69         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1097059      |\n",
            "------------------------------------------\n",
            " 55% 1099797/2000000 [2:24:34<1:53:03, 132.71it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.111         |\n",
            "| elapsed time            | 02:44:10      |\n",
            "| episodes                | 3570          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0023373747  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 1.9855504e-06 |\n",
            "| loss_td                 | 0.009784738   |\n",
            "| losses_all              | 0.0039589703  |\n",
            "| max 100 episode reward  | 22            |\n",
            "| mean 100 episode reward | 4.31          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1099801       |\n",
            "-------------------------------------------\n",
            " 55% 1099991/2000000 [2:24:37<2:03:57, 121.01it/s]saved checkpoint\n",
            " 55% 1103382/2000000 [2:25:03<1:54:41, 130.30it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.111         |\n",
            "| elapsed time            | 02:44:39      |\n",
            "| episodes                | 3580          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0022554852  |\n",
            "| loss_margin             | 0.010518167   |\n",
            "| loss_n_td               | 0.00078259414 |\n",
            "| loss_td                 | 0.005276688   |\n",
            "| losses_all              | 0.0045702793  |\n",
            "| max 100 episode reward  | 22            |\n",
            "| mean 100 episode reward | 4.4           |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1103391       |\n",
            "-------------------------------------------\n",
            " 55% 1106429/2000000 [2:25:27<1:52:21, 132.54it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.111        |\n",
            "| elapsed time            | 02:45:03     |\n",
            "| episodes                | 3590         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021826876 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0115435235 |\n",
            "| loss_td                 | 0.007296476  |\n",
            "| losses_all              | 0.004514939  |\n",
            "| max 100 episode reward  | 22           |\n",
            "| mean 100 episode reward | 4.53         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1106433      |\n",
            "------------------------------------------\n",
            " 55% 1109683/2000000 [2:25:53<1:58:23, 125.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.111        |\n",
            "| elapsed time            | 02:45:29     |\n",
            "| episodes                | 3600         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022983605 |\n",
            "| loss_margin             | 0.012795612  |\n",
            "| loss_n_td               | 0.0014478383 |\n",
            "| loss_td                 | 0.007883147  |\n",
            "| losses_all              | 0.0050353343 |\n",
            "| max 100 episode reward  | 22           |\n",
            "| mean 100 episode reward | 4.58         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1109696      |\n",
            "------------------------------------------\n",
            " 56% 1112817/2000000 [2:26:18<1:51:19, 132.83it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.111        |\n",
            "| elapsed time            | 02:45:54     |\n",
            "| episodes                | 3610         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022592633 |\n",
            "| loss_margin             | 0.0092463195 |\n",
            "| loss_n_td               | 0.0011289762 |\n",
            "| loss_td                 | 0.0068673277 |\n",
            "| losses_all              | 0.0046627494 |\n",
            "| max 100 episode reward  | 20           |\n",
            "| mean 100 episode reward | 4.56         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1112825      |\n",
            "------------------------------------------\n",
            " 56% 1116200/2000000 [2:26:45<1:49:59, 133.92it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.111        |\n",
            "| elapsed time            | 02:46:21     |\n",
            "| episodes                | 3620         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002251889  |\n",
            "| loss_margin             | 0.0023441315 |\n",
            "| loss_n_td               | 0.0008669419 |\n",
            "| loss_td                 | 0.006596661  |\n",
            "| losses_all              | 0.003958741  |\n",
            "| max 100 episode reward  | 24           |\n",
            "| mean 100 episode reward | 5.19         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1116207      |\n",
            "------------------------------------------\n",
            " 56% 1119845/2000000 [2:27:14<1:50:35, 132.65it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.11         |\n",
            "| elapsed time            | 02:46:50     |\n",
            "| episodes                | 3630         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022106944 |\n",
            "| loss_margin             | 0.04148402   |\n",
            "| loss_n_td               | 0.003080373  |\n",
            "| loss_td                 | 0.041644562  |\n",
            "| losses_all              | 0.010209487  |\n",
            "| max 100 episode reward  | 24           |\n",
            "| mean 100 episode reward | 5.46         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1119847      |\n",
            "------------------------------------------\n",
            " 56% 1122994/2000000 [2:27:39<1:50:26, 132.36it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.11         |\n",
            "| elapsed time            | 02:47:15     |\n",
            "| episodes                | 3640         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022288363 |\n",
            "| loss_margin             | 0.0053083375 |\n",
            "| loss_n_td               | 0.0019189146 |\n",
            "| loss_td                 | 0.0037327744 |\n",
            "| losses_all              | 0.0036488366 |\n",
            "| max 100 episode reward  | 24           |\n",
            "| mean 100 episode reward | 5.66         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1123008      |\n",
            "------------------------------------------\n",
            " 56% 1125914/2000000 [2:28:03<1:49:25, 133.12it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.11          |\n",
            "| elapsed time            | 02:47:38      |\n",
            "| episodes                | 3650          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0022407956  |\n",
            "| loss_margin             | 0.015169144   |\n",
            "| loss_n_td               | 0.00021523288 |\n",
            "| loss_td                 | 0.008212981   |\n",
            "| losses_all              | 0.005063215   |\n",
            "| max 100 episode reward  | 24            |\n",
            "| mean 100 episode reward | 5.7           |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1125923       |\n",
            "-------------------------------------------\n",
            " 56% 1129715/2000000 [2:28:33<1:47:34, 134.84it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.11         |\n",
            "| elapsed time            | 02:48:08     |\n",
            "| episodes                | 3660         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022894805 |\n",
            "| loss_margin             | 0.017275102  |\n",
            "| loss_n_td               | 0.0029551075 |\n",
            "| loss_td                 | 0.009672012  |\n",
            "| losses_all              | 0.005441818  |\n",
            "| max 100 episode reward  | 24           |\n",
            "| mean 100 episode reward | 5.95         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1129716      |\n",
            "------------------------------------------\n",
            " 57% 1132560/2000000 [2:28:55<1:55:15, 125.43it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.11         |\n",
            "| elapsed time            | 02:48:31     |\n",
            "| episodes                | 3670         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0023256845 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0017075823 |\n",
            "| loss_td                 | 0.008867782  |\n",
            "| losses_all              | 0.0040770406 |\n",
            "| max 100 episode reward  | 24           |\n",
            "| mean 100 episode reward | 6.07         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1132562      |\n",
            "------------------------------------------\n",
            " 57% 1136138/2000000 [2:29:24<1:50:43, 130.04it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.11          |\n",
            "| elapsed time            | 02:48:59      |\n",
            "| episodes                | 3680          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0022482728  |\n",
            "| loss_margin             | 0.00031396374 |\n",
            "| loss_n_td               | 0.002319714   |\n",
            "| loss_td                 | 0.030374937   |\n",
            "| losses_all              | 0.0062925783  |\n",
            "| max 100 episode reward  | 24            |\n",
            "| mean 100 episode reward | 6.25          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1136138       |\n",
            "-------------------------------------------\n",
            " 57% 1139824/2000000 [2:29:53<1:46:20, 134.82it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.11          |\n",
            "| elapsed time            | 02:49:29      |\n",
            "| episodes                | 3690          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0022773254  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 2.9884226e-05 |\n",
            "| loss_td                 | 0.008623657   |\n",
            "| losses_all              | 0.0037984268  |\n",
            "| max 100 episode reward  | 24            |\n",
            "| mean 100 episode reward | 6.44          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1139837       |\n",
            "-------------------------------------------\n",
            " 57% 1143854/2000000 [2:30:25<1:47:10, 133.14it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.109        |\n",
            "| elapsed time            | 02:50:00     |\n",
            "| episodes                | 3700         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022124967 |\n",
            "| loss_margin             | 0.046340745  |\n",
            "| loss_n_td               | 0.0052350014 |\n",
            "| loss_td                 | 0.011451161  |\n",
            "| losses_all              | 0.00809605   |\n",
            "| max 100 episode reward  | 40           |\n",
            "| mean 100 episode reward | 7.26         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1143868      |\n",
            "------------------------------------------\n",
            " 57% 1147809/2000000 [2:30:56<1:47:35, 132.01it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.109         |\n",
            "| elapsed time            | 02:50:31      |\n",
            "| episodes                | 3710          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0022213277  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00016726338 |\n",
            "| loss_td                 | 0.009093426   |\n",
            "| losses_all              | 0.0039833784  |\n",
            "| max 100 episode reward  | 40            |\n",
            "| mean 100 episode reward | 7.82          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1147812       |\n",
            "-------------------------------------------\n",
            " 58% 1151017/2000000 [2:31:22<1:47:49, 131.23it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.109        |\n",
            "| elapsed time            | 02:50:57     |\n",
            "| episodes                | 3720         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022802642 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0014072567 |\n",
            "| loss_td                 | 0.010599881  |\n",
            "| losses_all              | 0.004185417  |\n",
            "| max 100 episode reward  | 40           |\n",
            "| mean 100 episode reward | 7.67         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1151026      |\n",
            "------------------------------------------\n",
            " 58% 1154298/2000000 [2:31:48<1:48:30, 129.89it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.109        |\n",
            "| elapsed time            | 02:51:23     |\n",
            "| episodes                | 3730         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022359474 |\n",
            "| loss_margin             | 0.01905894   |\n",
            "| loss_n_td               | 0.0033361271 |\n",
            "| loss_td                 | 0.0058154147 |\n",
            "| losses_all              | 0.005148438  |\n",
            "| max 100 episode reward  | 40           |\n",
            "| mean 100 episode reward | 7.72         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1154303      |\n",
            "------------------------------------------\n",
            " 58% 1157562/2000000 [2:32:14<1:46:54, 131.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.109        |\n",
            "| elapsed time            | 02:51:49     |\n",
            "| episodes                | 3740         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002223832  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0007510732 |\n",
            "| loss_td                 | 0.008246253  |\n",
            "| losses_all              | 0.0040830392 |\n",
            "| max 100 episode reward  | 40           |\n",
            "| mean 100 episode reward | 7.64         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1157575      |\n",
            "------------------------------------------\n",
            " 58% 1161121/2000000 [2:32:42<1:46:56, 130.74it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.109        |\n",
            "| elapsed time            | 02:52:17     |\n",
            "| episodes                | 3750         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022263632 |\n",
            "| loss_margin             | 0.025722435  |\n",
            "| loss_n_td               | 0.006597503  |\n",
            "| loss_td                 | 0.0120144375 |\n",
            "| losses_all              | 0.0067940047 |\n",
            "| max 100 episode reward  | 40           |\n",
            "| mean 100 episode reward | 8.1          |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1161132      |\n",
            "------------------------------------------\n",
            " 58% 1164617/2000000 [2:33:09<1:45:57, 131.41it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.109        |\n",
            "| elapsed time            | 02:52:45     |\n",
            "| episodes                | 3760         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022223769 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0028510953 |\n",
            "| loss_td                 | 0.007781856  |\n",
            "| losses_all              | 0.0038167513 |\n",
            "| max 100 episode reward  | 40           |\n",
            "| mean 100 episode reward | 8.09         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1164627      |\n",
            "------------------------------------------\n",
            " 58% 1167774/2000000 [2:33:34<1:45:50, 131.04it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.108        |\n",
            "| elapsed time            | 02:53:10     |\n",
            "| episodes                | 3770         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021783193 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.000375967  |\n",
            "| loss_td                 | 0.007527865  |\n",
            "| losses_all              | 0.0035800661 |\n",
            "| max 100 episode reward  | 40           |\n",
            "| mean 100 episode reward | 8.09         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1167782      |\n",
            "------------------------------------------\n",
            " 59% 1171357/2000000 [2:34:03<1:43:41, 133.20it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.108       |\n",
            "| elapsed time            | 02:53:38    |\n",
            "| episodes                | 3780        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.002200491 |\n",
            "| loss_margin             | 0.009473771 |\n",
            "| loss_n_td               | 0.004551363 |\n",
            "| loss_td                 | 0.009286458 |\n",
            "| losses_all              | 0.005116986 |\n",
            "| max 100 episode reward  | 40          |\n",
            "| mean 100 episode reward | 8.23        |\n",
            "| min 100 episode reward  | 1           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1171357     |\n",
            "-----------------------------------------\n",
            " 59% 1175461/2000000 [2:34:35<1:43:44, 132.47it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.108         |\n",
            "| elapsed time            | 02:54:11      |\n",
            "| episodes                | 3790          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0022672832  |\n",
            "| loss_margin             | 0.013151338   |\n",
            "| loss_n_td               | 0.00037866848 |\n",
            "| loss_td                 | 0.0056529     |\n",
            "| losses_all              | 0.0047181677  |\n",
            "| max 100 episode reward  | 40            |\n",
            "| mean 100 episode reward | 8.32          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1175474       |\n",
            "-------------------------------------------\n",
            " 59% 1179541/2000000 [2:35:07<1:43:30, 132.10it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.108       |\n",
            "| elapsed time            | 02:54:43    |\n",
            "| episodes                | 3800        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.002231324 |\n",
            "| loss_margin             | 0.027480135 |\n",
            "| loss_n_td               | 0.010374989 |\n",
            "| loss_td                 | 0.012503514 |\n",
            "| losses_all              | 0.007550203 |\n",
            "| max 100 episode reward  | 37          |\n",
            "| mean 100 episode reward | 7.87        |\n",
            "| min 100 episode reward  | 1           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1179543     |\n",
            "-----------------------------------------\n",
            " 59% 1183245/2000000 [2:35:37<1:42:12, 133.19it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.108         |\n",
            "| elapsed time            | 02:55:12      |\n",
            "| episodes                | 3810          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0023166162  |\n",
            "| loss_margin             | 0.00094622374 |\n",
            "| loss_n_td               | 0.0006984577  |\n",
            "| loss_td                 | 0.008512687   |\n",
            "| losses_all              | 0.0038120612  |\n",
            "| max 100 episode reward  | 37            |\n",
            "| mean 100 episode reward | 7.55          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1183248       |\n",
            "-------------------------------------------\n",
            " 59% 1187477/2000000 [2:36:10<1:44:44, 129.30it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.108        |\n",
            "| elapsed time            | 02:55:46     |\n",
            "| episodes                | 3820         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022462565 |\n",
            "| loss_margin             | 0.025315158  |\n",
            "| loss_n_td               | 0.0037190015 |\n",
            "| loss_td                 | 0.016348595  |\n",
            "| losses_all              | 0.007130279  |\n",
            "| max 100 episode reward  | 37           |\n",
            "| mean 100 episode reward | 7.82         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1187482      |\n",
            "------------------------------------------\n",
            " 60% 1191709/2000000 [2:36:43<1:43:24, 130.27it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.108        |\n",
            "| elapsed time            | 02:56:19     |\n",
            "| episodes                | 3830         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022897474 |\n",
            "| loss_margin             | 0.020724177  |\n",
            "| loss_n_td               | 0.0030798065 |\n",
            "| loss_td                 | 0.009526427  |\n",
            "| losses_all              | 0.0060982597 |\n",
            "| max 100 episode reward  | 37           |\n",
            "| mean 100 episode reward | 7.96         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1191721      |\n",
            "------------------------------------------\n",
            " 60% 1196135/2000000 [2:37:18<1:47:04, 125.13it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.107        |\n",
            "| elapsed time            | 02:56:54     |\n",
            "| episodes                | 3840         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002165463  |\n",
            "| loss_margin             | 0.014477063  |\n",
            "| loss_n_td               | 0.004608427  |\n",
            "| loss_td                 | 0.015471628  |\n",
            "| losses_all              | 0.0058811503 |\n",
            "| max 100 episode reward  | 37           |\n",
            "| mean 100 episode reward | 8.27         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1196141      |\n",
            "------------------------------------------\n",
            " 60% 1199996/2000000 [2:37:49<1:38:37, 135.20it/s]saved checkpoint\n",
            " 60% 1200897/2000000 [2:37:56<1:39:45, 133.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.107        |\n",
            "| elapsed time            | 02:57:31     |\n",
            "| episodes                | 3850         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022591567 |\n",
            "| loss_margin             | 0.014139708  |\n",
            "| loss_n_td               | 0.008809726  |\n",
            "| loss_td                 | 0.0077849557 |\n",
            "| losses_all              | 0.0056702397 |\n",
            "| max 100 episode reward  | 22           |\n",
            "| mean 100 episode reward | 8.5          |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1200910      |\n",
            "------------------------------------------\n",
            " 60% 1204791/2000000 [2:38:26<1:40:46, 131.52it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.107        |\n",
            "| elapsed time            | 02:58:02     |\n",
            "| episodes                | 3860         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022009125 |\n",
            "| loss_margin             | 0.01868299   |\n",
            "| loss_n_td               | 0.0050292513 |\n",
            "| loss_td                 | 0.009445262  |\n",
            "| losses_all              | 0.005736349  |\n",
            "| max 100 episode reward  | 22           |\n",
            "| mean 100 episode reward | 8.48         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1204796      |\n",
            "------------------------------------------\n",
            " 60% 1208565/2000000 [2:38:56<1:41:23, 130.10it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.107        |\n",
            "| elapsed time            | 02:58:32     |\n",
            "| episodes                | 3870         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022245424 |\n",
            "| loss_margin             | 0.017373726  |\n",
            "| loss_n_td               | 0.0012917545 |\n",
            "| loss_td                 | 0.03513401   |\n",
            "| losses_all              | 0.007351918  |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 8.96         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1208577      |\n",
            "------------------------------------------\n",
            " 61% 1212701/2000000 [2:39:29<1:41:18, 129.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.107        |\n",
            "| elapsed time            | 02:59:05     |\n",
            "| episodes                | 3880         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022171543 |\n",
            "| loss_margin             | 0.011269737  |\n",
            "| loss_n_td               | 0.0021117756 |\n",
            "| loss_td                 | 0.043017186  |\n",
            "| losses_all              | 0.0070568696 |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 9.19         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1212704      |\n",
            "------------------------------------------\n",
            " 61% 1215965/2000000 [2:39:55<1:39:13, 131.70it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.107        |\n",
            "| elapsed time            | 02:59:30     |\n",
            "| episodes                | 3890         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0023294848 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.004746712  |\n",
            "| loss_td                 | 0.00469152   |\n",
            "| losses_all              | 0.0036983099 |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 9.14         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1215975      |\n",
            "------------------------------------------\n",
            " 61% 1219445/2000000 [2:40:22<1:37:49, 132.97it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.106         |\n",
            "| elapsed time            | 02:59:58      |\n",
            "| episodes                | 3900          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0021833077  |\n",
            "| loss_margin             | 0.0060510226  |\n",
            "| loss_n_td               | 0.00023889795 |\n",
            "| loss_td                 | 0.0037588526  |\n",
            "| losses_all              | 0.0034045437  |\n",
            "| max 100 episode reward  | 31            |\n",
            "| mean 100 episode reward | 9             |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1219452       |\n",
            "-------------------------------------------\n",
            " 61% 1223686/2000000 [2:40:55<1:37:43, 132.40it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.106        |\n",
            "| elapsed time            | 03:00:31     |\n",
            "| episodes                | 3910         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022269231 |\n",
            "| loss_margin             | 0.06673324   |\n",
            "| loss_n_td               | 0.011537264  |\n",
            "| loss_td                 | 0.014119591  |\n",
            "| losses_all              | 0.009458579  |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 9.25         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1223692      |\n",
            "------------------------------------------\n",
            " 61% 1227443/2000000 [2:41:25<1:35:05, 135.40it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.106        |\n",
            "| elapsed time            | 03:01:01     |\n",
            "| episodes                | 3920         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022123898 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0017800241 |\n",
            "| loss_td                 | 0.0056110425 |\n",
            "| losses_all              | 0.0036983872 |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 8.9          |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1227455      |\n",
            "------------------------------------------\n",
            " 62% 1232059/2000000 [2:42:01<1:34:33, 135.35it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.106       |\n",
            "| elapsed time            | 03:01:37    |\n",
            "| episodes                | 3930        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.002260223 |\n",
            "| loss_margin             | 0.03256152  |\n",
            "| loss_n_td               | 0.019243462 |\n",
            "| loss_td                 | 0.021295898 |\n",
            "| losses_all              | 0.00861931  |\n",
            "| max 100 episode reward  | 31          |\n",
            "| mean 100 episode reward | 9.13        |\n",
            "| min 100 episode reward  | 1           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1232065     |\n",
            "-----------------------------------------\n",
            " 62% 1236936/2000000 [2:42:39<1:34:39, 134.36it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.106        |\n",
            "| elapsed time            | 03:02:15     |\n",
            "| episodes                | 3940         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002231149  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.006802959  |\n",
            "| losses_all              | 0.0034252792 |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 9.57         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1236948      |\n",
            "------------------------------------------\n",
            " 62% 1241462/2000000 [2:43:14<1:35:44, 132.05it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.106        |\n",
            "| elapsed time            | 03:02:50     |\n",
            "| episodes                | 3950         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002203301  |\n",
            "| loss_margin             | 0.024474977  |\n",
            "| loss_n_td               | 0.001860086  |\n",
            "| loss_td                 | 0.0055184914 |\n",
            "| losses_all              | 0.0055848258 |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 9.51         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1241465      |\n",
            "------------------------------------------\n",
            " 62% 1246210/2000000 [2:43:51<1:35:32, 131.50it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.105       |\n",
            "| elapsed time            | 03:03:27    |\n",
            "| episodes                | 3960        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.00219984  |\n",
            "| loss_margin             | 0.002770882 |\n",
            "| loss_n_td               | 0.003921388 |\n",
            "| loss_td                 | 0.013054756 |\n",
            "| losses_all              | 0.004763171 |\n",
            "| max 100 episode reward  | 31          |\n",
            "| mean 100 episode reward | 9.7         |\n",
            "| min 100 episode reward  | 1           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1246212     |\n",
            "-----------------------------------------\n",
            " 63% 1250647/2000000 [2:44:26<1:36:13, 129.78it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.105        |\n",
            "| elapsed time            | 03:04:02     |\n",
            "| episodes                | 3970         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021933329 |\n",
            "| loss_margin             | 0.010203578  |\n",
            "| loss_n_td               | 0.0023141513 |\n",
            "| loss_td                 | 0.004617767  |\n",
            "| losses_all              | 0.0041651796 |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 9.47         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1250659      |\n",
            "------------------------------------------\n",
            " 63% 1254959/2000000 [2:45:00<1:32:40, 134.00it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.105        |\n",
            "| elapsed time            | 03:04:36     |\n",
            "| episodes                | 3980         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0022416613 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0003162283 |\n",
            "| loss_td                 | 0.008042525  |\n",
            "| losses_all              | 0.0039012884 |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 9.19         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1254960      |\n",
            "------------------------------------------\n",
            " 63% 1259345/2000000 [2:45:34<1:34:19, 130.87it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.105        |\n",
            "| elapsed time            | 03:05:10     |\n",
            "| episodes                | 3990         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021973308 |\n",
            "| loss_margin             | 0.012787936  |\n",
            "| loss_n_td               | 0.0011576484 |\n",
            "| loss_td                 | 0.13991064   |\n",
            "| losses_all              | 0.010631032  |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 9.66         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1259345      |\n",
            "------------------------------------------\n",
            " 63% 1263460/2000000 [2:46:06<1:31:16, 134.49it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.105        |\n",
            "| elapsed time            | 03:05:42     |\n",
            "| episodes                | 4000         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002165732  |\n",
            "| loss_margin             | 0.027673082  |\n",
            "| loss_n_td               | 0.0013412354 |\n",
            "| loss_td                 | 0.010812474  |\n",
            "| losses_all              | 0.00619923   |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 10           |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1263472      |\n",
            "------------------------------------------\n",
            " 63% 1268447/2000000 [2:46:45<1:32:47, 131.39it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.105        |\n",
            "| elapsed time            | 03:06:21     |\n",
            "| episodes                | 4010         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002166401  |\n",
            "| loss_margin             | 0.02704285   |\n",
            "| loss_n_td               | 0.0029681898 |\n",
            "| loss_td                 | 0.009863585  |\n",
            "| losses_all              | 0.0056459596 |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 9.95         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1268449      |\n",
            "------------------------------------------\n",
            " 64% 1273398/2000000 [2:47:24<1:32:30, 130.92it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.105       |\n",
            "| elapsed time            | 03:07:00    |\n",
            "| episodes                | 4020        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.002110101 |\n",
            "| loss_margin             | 0.025390558 |\n",
            "| loss_n_td               | 0.000712135 |\n",
            "| loss_td                 | 0.005221489 |\n",
            "| losses_all              | 0.004875227 |\n",
            "| max 100 episode reward  | 31          |\n",
            "| mean 100 episode reward | 10.2        |\n",
            "| min 100 episode reward  | 2           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1273407     |\n",
            "-----------------------------------------\n",
            " 64% 1277800/2000000 [2:47:58<1:28:09, 136.54it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.104        |\n",
            "| elapsed time            | 03:07:34     |\n",
            "| episodes                | 4030         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021718403 |\n",
            "| loss_margin             | 0.009922441  |\n",
            "| loss_n_td               | 0.0009947001 |\n",
            "| loss_td                 | 0.010399836  |\n",
            "| losses_all              | 0.004934185  |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 9.93         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1277802      |\n",
            "------------------------------------------\n",
            " 64% 1281936/2000000 [2:48:31<1:31:00, 131.50it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.104         |\n",
            "| elapsed time            | 03:08:07      |\n",
            "| episodes                | 4040          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0021261033  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00031612863 |\n",
            "| loss_td                 | 0.008421878   |\n",
            "| losses_all              | 0.0036703546  |\n",
            "| max 100 episode reward  | 31            |\n",
            "| mean 100 episode reward | 9.48          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1281946       |\n",
            "-------------------------------------------\n",
            " 64% 1286089/2000000 [2:49:04<1:32:26, 128.71it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.104        |\n",
            "| elapsed time            | 03:08:39     |\n",
            "| episodes                | 4050         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021312768 |\n",
            "| loss_margin             | 0.040907178  |\n",
            "| loss_n_td               | 0.016840408  |\n",
            "| loss_td                 | 0.024915269  |\n",
            "| losses_all              | 0.00879861   |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 9.38         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1286098      |\n",
            "------------------------------------------\n",
            " 65% 1290739/2000000 [2:49:41<1:31:55, 128.58it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.104         |\n",
            "| elapsed time            | 03:09:16      |\n",
            "| episodes                | 4060          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0020871675  |\n",
            "| loss_margin             | 0.005511334   |\n",
            "| loss_n_td               | 0.00087307347 |\n",
            "| loss_td                 | 0.0077053513  |\n",
            "| losses_all              | 0.0037904687  |\n",
            "| max 100 episode reward  | 31            |\n",
            "| mean 100 episode reward | 9.26          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1290742       |\n",
            "-------------------------------------------\n",
            " 65% 1295303/2000000 [2:50:17<1:27:17, 134.54it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.104        |\n",
            "| elapsed time            | 03:09:52     |\n",
            "| episodes                | 4070         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002063984  |\n",
            "| loss_margin             | 0.030080441  |\n",
            "| loss_n_td               | 0.0048901006 |\n",
            "| loss_td                 | 0.0074586817 |\n",
            "| losses_all              | 0.005927357  |\n",
            "| max 100 episode reward  | 35           |\n",
            "| mean 100 episode reward | 9.63         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1295314      |\n",
            "------------------------------------------\n",
            " 65% 1299334/2000000 [2:50:48<1:30:45, 128.67it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.104        |\n",
            "| elapsed time            | 03:10:24     |\n",
            "| episodes                | 4080         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0020829323 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.0049214177 |\n",
            "| losses_all              | 0.0032421132 |\n",
            "| max 100 episode reward  | 35           |\n",
            "| mean 100 episode reward | 9.76         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1299346      |\n",
            "------------------------------------------\n",
            " 65% 1299987/2000000 [2:50:55<1:28:40, 131.56it/s]saved checkpoint\n",
            " 65% 1303686/2000000 [2:51:23<1:33:36, 123.98it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.104         |\n",
            "| elapsed time            | 03:10:59      |\n",
            "| episodes                | 4090          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0021593291  |\n",
            "| loss_margin             | 0.00075151026 |\n",
            "| loss_n_td               | 0.0011079473  |\n",
            "| loss_td                 | 0.0063744877  |\n",
            "| losses_all              | 0.0034201941  |\n",
            "| max 100 episode reward  | 35            |\n",
            "| mean 100 episode reward | 9.78          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1303688       |\n",
            "-------------------------------------------\n",
            " 65% 1307785/2000000 [2:51:56<1:27:59, 131.13it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.103         |\n",
            "| elapsed time            | 03:11:31      |\n",
            "| episodes                | 4100          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0020637384  |\n",
            "| loss_margin             | 3.0685216e-05 |\n",
            "| loss_n_td               | 0.0013719352  |\n",
            "| loss_td                 | 0.009361358   |\n",
            "| losses_all              | 0.0036752438  |\n",
            "| max 100 episode reward  | 35            |\n",
            "| mean 100 episode reward | 9.67          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1307795       |\n",
            "-------------------------------------------\n",
            " 66% 1312273/2000000 [2:52:31<1:27:50, 130.48it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.103        |\n",
            "| elapsed time            | 03:12:07     |\n",
            "| episodes                | 4110         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0020666046 |\n",
            "| loss_margin             | 0.027220463  |\n",
            "| loss_n_td               | 0.0012621526 |\n",
            "| loss_td                 | 0.00831025   |\n",
            "| losses_all              | 0.005733287  |\n",
            "| max 100 episode reward  | 35           |\n",
            "| mean 100 episode reward | 9.8          |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1312282      |\n",
            "------------------------------------------\n",
            " 66% 1316982/2000000 [2:53:08<1:26:25, 131.72it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.103        |\n",
            "| elapsed time            | 03:12:44     |\n",
            "| episodes                | 4120         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021307364 |\n",
            "| loss_margin             | 0.023833536  |\n",
            "| loss_n_td               | 0.0046907878 |\n",
            "| loss_td                 | 0.0037687933 |\n",
            "| losses_all              | 0.0052198516 |\n",
            "| max 100 episode reward  | 35           |\n",
            "| mean 100 episode reward | 9.74         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1316996      |\n",
            "------------------------------------------\n",
            " 66% 1321087/2000000 [2:53:40<1:25:05, 132.97it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.103        |\n",
            "| elapsed time            | 03:13:16     |\n",
            "| episodes                | 4130         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021319315 |\n",
            "| loss_margin             | 0.012890443  |\n",
            "| loss_n_td               | 0.0037029246 |\n",
            "| loss_td                 | 0.025865464  |\n",
            "| losses_all              | 0.006089274  |\n",
            "| max 100 episode reward  | 35           |\n",
            "| mean 100 episode reward | 10.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1321093      |\n",
            "------------------------------------------\n",
            " 66% 1324567/2000000 [2:54:08<1:25:11, 132.13it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.103        |\n",
            "| elapsed time            | 03:13:43     |\n",
            "| episodes                | 4140         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0020260497 |\n",
            "| loss_margin             | 0.027466673  |\n",
            "| loss_n_td               | 0.002304745  |\n",
            "| loss_td                 | 0.017965663  |\n",
            "| losses_all              | 0.0067973463 |\n",
            "| max 100 episode reward  | 35           |\n",
            "| mean 100 episode reward | 9.81         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1324578      |\n",
            "------------------------------------------\n",
            " 66% 1328905/2000000 [2:54:42<1:24:44, 132.00it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.103        |\n",
            "| elapsed time            | 03:14:17     |\n",
            "| episodes                | 4150         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021644332 |\n",
            "| loss_margin             | 0.027904486  |\n",
            "| loss_n_td               | 0.0015049479 |\n",
            "| loss_td                 | 0.009313138  |\n",
            "| losses_all              | 0.0060581043 |\n",
            "| max 100 episode reward  | 35           |\n",
            "| mean 100 episode reward | 9.65         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1328907      |\n",
            "------------------------------------------\n",
            " 67% 1332893/2000000 [2:55:14<1:23:27, 133.23it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.103        |\n",
            "| elapsed time            | 03:14:49     |\n",
            "| episodes                | 4160         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0020692837 |\n",
            "| loss_margin             | 0.0015048757 |\n",
            "| loss_n_td               | 0.0006179662 |\n",
            "| loss_td                 | 0.00607326   |\n",
            "| losses_all              | 0.0033703756 |\n",
            "| max 100 episode reward  | 42           |\n",
            "| mean 100 episode reward | 9.99         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1332900      |\n",
            "------------------------------------------\n",
            " 67% 1337226/2000000 [2:55:47<1:24:37, 130.53it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 03:15:23     |\n",
            "| episodes                | 4170         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0020782056 |\n",
            "| loss_margin             | 0.005624857  |\n",
            "| loss_n_td               | 0.0036734645 |\n",
            "| loss_td                 | 0.0059244893 |\n",
            "| losses_all              | 0.0038200046 |\n",
            "| max 100 episode reward  | 42           |\n",
            "| mean 100 episode reward | 9.66         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1337234      |\n",
            "------------------------------------------\n",
            " 67% 1341897/2000000 [2:56:24<1:23:31, 131.31it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 03:16:00     |\n",
            "| episodes                | 4180         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021155796 |\n",
            "| loss_margin             | 0.0047295503 |\n",
            "| loss_n_td               | 0.008737627  |\n",
            "| loss_td                 | 0.010013263  |\n",
            "| losses_all              | 0.0044900514 |\n",
            "| max 100 episode reward  | 42           |\n",
            "| mean 100 episode reward | 10.3         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1341909      |\n",
            "------------------------------------------\n",
            " 67% 1345621/2000000 [2:56:54<1:23:18, 130.92it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 03:16:29     |\n",
            "| episodes                | 4190         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0020574378 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.004696916  |\n",
            "| loss_td                 | 0.0054753977 |\n",
            "| losses_all              | 0.0035956162 |\n",
            "| max 100 episode reward  | 42           |\n",
            "| mean 100 episode reward | 9.82         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1345624      |\n",
            "------------------------------------------\n",
            " 67% 1349866/2000000 [2:57:27<1:20:59, 133.79it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 03:17:03     |\n",
            "| episodes                | 4200         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021237023 |\n",
            "| loss_margin             | 0.009075467  |\n",
            "| loss_n_td               | 0.0012421975 |\n",
            "| loss_td                 | 0.0098109245 |\n",
            "| losses_all              | 0.004384592  |\n",
            "| max 100 episode reward  | 42           |\n",
            "| mean 100 episode reward | 9.82         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1349879      |\n",
            "------------------------------------------\n",
            " 68% 1353312/2000000 [2:57:55<1:19:37, 135.35it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 03:17:30     |\n",
            "| episodes                | 4210         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0020839153 |\n",
            "| loss_margin             | 0.0025668591 |\n",
            "| loss_n_td               | 0.0008263286 |\n",
            "| loss_td                 | 0.008495454  |\n",
            "| losses_all              | 0.0037430716 |\n",
            "| max 100 episode reward  | 42           |\n",
            "| mean 100 episode reward | 9.36         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1353317      |\n",
            "------------------------------------------\n",
            " 68% 1357122/2000000 [2:58:25<1:21:36, 131.29it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 03:18:00     |\n",
            "| episodes                | 4220         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0021313832 |\n",
            "| loss_margin             | 0.020635787  |\n",
            "| loss_n_td               | 0.0067293546 |\n",
            "| loss_td                 | 0.015810505  |\n",
            "| losses_all              | 0.0068063578 |\n",
            "| max 100 episode reward  | 42           |\n",
            "| mean 100 episode reward | 9.23         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1357128      |\n",
            "------------------------------------------\n",
            " 68% 1360482/2000000 [2:58:51<1:22:58, 128.45it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.102         |\n",
            "| elapsed time            | 03:18:27      |\n",
            "| episodes                | 4230          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0020455716  |\n",
            "| loss_margin             | 0.00071403757 |\n",
            "| loss_n_td               | 0.0020467301  |\n",
            "| loss_td                 | 0.005398173   |\n",
            "| losses_all              | 0.0033195221  |\n",
            "| max 100 episode reward  | 42            |\n",
            "| mean 100 episode reward | 8.75          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1360486       |\n",
            "-------------------------------------------\n",
            " 68% 1363570/2000000 [2:59:16<1:21:14, 130.56it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 03:18:51     |\n",
            "| episodes                | 4240         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002016987  |\n",
            "| loss_margin             | 0.011553356  |\n",
            "| loss_n_td               | 0.0006770047 |\n",
            "| loss_td                 | 0.008269653  |\n",
            "| losses_all              | 0.0040735165 |\n",
            "| max 100 episode reward  | 42           |\n",
            "| mean 100 episode reward | 8.75         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1363576      |\n",
            "------------------------------------------\n",
            " 68% 1367385/2000000 [2:59:46<1:18:51, 133.70it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 03:19:21     |\n",
            "| episodes                | 4250         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0020464705 |\n",
            "| loss_margin             | 0.0010344721 |\n",
            "| loss_n_td               | 0.0029446373 |\n",
            "| loss_td                 | 0.004815265  |\n",
            "| losses_all              | 0.0031037347 |\n",
            "| max 100 episode reward  | 42           |\n",
            "| mean 100 episode reward | 8.96         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1367387      |\n",
            "------------------------------------------\n",
            " 69% 1370885/2000000 [3:00:14<1:18:56, 132.83it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 03:19:50     |\n",
            "| episodes                | 4260         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0020119594 |\n",
            "| loss_margin             | 0.0132416785 |\n",
            "| loss_n_td               | 0.0041609537 |\n",
            "| loss_td                 | 0.018706148  |\n",
            "| losses_all              | 0.005691459  |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 9.95         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1370885      |\n",
            "------------------------------------------\n",
            " 69% 1374469/2000000 [3:00:42<1:19:03, 131.87it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 03:20:18     |\n",
            "| episodes                | 4270         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0020435748 |\n",
            "| loss_margin             | 0.030899271  |\n",
            "| loss_n_td               | 0.0054515656 |\n",
            "| loss_td                 | 0.009178075  |\n",
            "| losses_all              | 0.0060346453 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 9.91         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1374476      |\n",
            "------------------------------------------\n",
            " 69% 1378897/2000000 [3:01:17<1:20:04, 129.28it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 03:20:53     |\n",
            "| episodes                | 4280         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002024095  |\n",
            "| loss_margin             | 0.0063471124 |\n",
            "| loss_n_td               | 0.0016172112 |\n",
            "| loss_td                 | 0.007700397  |\n",
            "| losses_all              | 0.0038547616 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 9.31         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1378910      |\n",
            "------------------------------------------\n",
            " 69% 1381565/2000000 [3:01:39<1:19:39, 129.38it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 03:21:15     |\n",
            "| episodes                | 4290         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0039730305 |\n",
            "| loss_margin             | 0.025812965  |\n",
            "| loss_n_td               | 0.03922455   |\n",
            "| loss_td                 | 0.12222235   |\n",
            "| losses_all              | 0.02988235   |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 8.81         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1381577      |\n",
            "------------------------------------------\n",
            " 69% 1384624/2000000 [3:02:03<1:16:35, 133.92it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 03:21:39     |\n",
            "| episodes                | 4300         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0035066705 |\n",
            "| loss_margin             | 0.042043004  |\n",
            "| loss_n_td               | 0.05675884   |\n",
            "| loss_td                 | 0.102610156  |\n",
            "| losses_all              | 0.023142558  |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 7.99         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1384631      |\n",
            "------------------------------------------\n",
            " 69% 1388150/2000000 [3:02:31<1:18:10, 130.44it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 03:22:07     |\n",
            "| episodes                | 4310         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030940026 |\n",
            "| loss_margin             | 0.053480282  |\n",
            "| loss_n_td               | 0.020830527  |\n",
            "| loss_td                 | 0.05371502   |\n",
            "| losses_all              | 0.015157234  |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 7.65         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1388152      |\n",
            "------------------------------------------\n",
            " 70% 1391452/2000000 [3:02:57<1:14:59, 135.25it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 03:22:33     |\n",
            "| episodes                | 4320         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0027793478 |\n",
            "| loss_margin             | 0.0013545789 |\n",
            "| loss_n_td               | 0.0010130091 |\n",
            "| loss_td                 | 0.00485732   |\n",
            "| losses_all              | 0.0041204263 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 7.02         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1391462      |\n",
            "------------------------------------------\n",
            " 70% 1394361/2000000 [3:03:21<1:16:46, 131.46it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 03:22:56     |\n",
            "| episodes                | 4330         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029915408 |\n",
            "| loss_margin             | 0.083374724  |\n",
            "| loss_n_td               | 0.03263615   |\n",
            "| loss_td                 | 0.100308836  |\n",
            "| losses_all              | 0.03312075   |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 6.33         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1394371      |\n",
            "------------------------------------------\n",
            " 70% 1397041/2000000 [3:03:42<1:16:40, 131.08it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 03:23:18     |\n",
            "| episodes                | 4340         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0034852808 |\n",
            "| loss_margin             | 0.0040030703 |\n",
            "| loss_n_td               | 0.021002239  |\n",
            "| loss_td                 | 0.042183988  |\n",
            "| losses_all              | 0.010502155  |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 5.93         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1397053      |\n",
            "------------------------------------------\n",
            " 70% 1400000/2000000 [3:04:06<1:15:32, 132.38it/s]saved checkpoint\n",
            " 70% 1400056/2000000 [3:04:07<1:31:40, 109.08it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 03:23:42     |\n",
            "| episodes                | 4350         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030545031 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0002443978 |\n",
            "| loss_td                 | 0.009987442  |\n",
            "| losses_all              | 0.0051220497 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 5.01         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1400060      |\n",
            "------------------------------------------\n",
            " 70% 1402942/2000000 [3:04:30<1:15:59, 130.96it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 03:24:05     |\n",
            "| episodes                | 4360         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0026693593 |\n",
            "| loss_margin             | 0.038282685  |\n",
            "| loss_n_td               | 0.011784073  |\n",
            "| loss_td                 | 0.022487715  |\n",
            "| losses_all              | 0.008682064  |\n",
            "| max 100 episode reward  | 33           |\n",
            "| mean 100 episode reward | 3.08         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1402955      |\n",
            "------------------------------------------\n",
            " 70% 1405917/2000000 [3:04:53<1:14:48, 132.35it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.1          |\n",
            "| elapsed time            | 03:24:29     |\n",
            "| episodes                | 4370         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0023552785 |\n",
            "| loss_margin             | 0.04291123   |\n",
            "| loss_n_td               | 0.0085587315 |\n",
            "| loss_td                 | 0.030290581  |\n",
            "| losses_all              | 0.008811201  |\n",
            "| max 100 episode reward  | 16           |\n",
            "| mean 100 episode reward | 2.36         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1405929      |\n",
            "------------------------------------------\n",
            " 70% 1408713/2000000 [3:05:16<1:20:52, 121.84it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.1          |\n",
            "| elapsed time            | 03:24:52     |\n",
            "| episodes                | 4380         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0020995885 |\n",
            "| loss_margin             | 0.0013455674 |\n",
            "| loss_n_td               | 0.0036586332 |\n",
            "| loss_td                 | 0.031260304  |\n",
            "| losses_all              | 0.0056744884 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.55         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1408722      |\n",
            "------------------------------------------\n",
            " 71% 1411277/2000000 [3:05:37<1:15:57, 129.18it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.1          |\n",
            "| elapsed time            | 03:25:13     |\n",
            "| episodes                | 4390         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0018963608 |\n",
            "| loss_margin             | 0.02429996   |\n",
            "| loss_n_td               | 0.0018580084 |\n",
            "| loss_td                 | 0.024419978  |\n",
            "| losses_all              | 0.006072156  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.43         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1411278      |\n",
            "------------------------------------------\n",
            " 71% 1414561/2000000 [3:06:03<1:14:10, 131.54it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.1           |\n",
            "| elapsed time            | 03:25:39      |\n",
            "| episodes                | 4400          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0016707719  |\n",
            "| loss_margin             | 0.017641202   |\n",
            "| loss_n_td               | 0.00056133245 |\n",
            "| loss_td                 | 0.015291205   |\n",
            "| losses_all              | 0.005024094   |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 1.47          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1414563       |\n",
            "-------------------------------------------\n",
            " 71% 1417450/2000000 [3:06:26<1:13:29, 132.11it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.1          |\n",
            "| elapsed time            | 03:26:02     |\n",
            "| episodes                | 4410         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0015077628 |\n",
            "| loss_margin             | 0.035303462  |\n",
            "| loss_n_td               | 0.0116025815 |\n",
            "| loss_td                 | 0.027201632  |\n",
            "| losses_all              | 0.0072720135 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.34         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1417463      |\n",
            "------------------------------------------\n",
            " 71% 1420442/2000000 [3:06:50<1:13:34, 131.29it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.1           |\n",
            "| elapsed time            | 03:26:26      |\n",
            "| episodes                | 4420          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0013806184  |\n",
            "| loss_margin             | 0.00062933564 |\n",
            "| loss_n_td               | 0.0009171655  |\n",
            "| loss_td                 | 0.03090676    |\n",
            "| losses_all              | 0.0046363836  |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 1.33          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1420452       |\n",
            "-------------------------------------------\n",
            " 71% 1423768/2000000 [3:07:16<1:12:20, 132.75it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0999       |\n",
            "| elapsed time            | 03:26:52     |\n",
            "| episodes                | 4430         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0012701657 |\n",
            "| loss_margin             | 0.01214163   |\n",
            "| loss_n_td               | 0.0032692621 |\n",
            "| loss_td                 | 0.037740644  |\n",
            "| losses_all              | 0.005681024  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.45         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1423780      |\n",
            "------------------------------------------\n",
            " 71% 1426758/2000000 [3:07:40<1:13:30, 129.98it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0998        |\n",
            "| elapsed time            | 03:27:16      |\n",
            "| episodes                | 4440          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0011845669  |\n",
            "| loss_margin             | 3.5572797e-05 |\n",
            "| loss_n_td               | 0.0040544076  |\n",
            "| loss_td                 | 0.031058794   |\n",
            "| losses_all              | 0.0042790053  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.37          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1426769       |\n",
            "-------------------------------------------\n",
            " 71% 1429297/2000000 [3:08:00<1:12:11, 131.76it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0998       |\n",
            "| elapsed time            | 03:27:36     |\n",
            "| episodes                | 4450         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0011287233 |\n",
            "| loss_margin             | 0.013218613  |\n",
            "| loss_n_td               | 0.01462857   |\n",
            "| loss_td                 | 0.020348296  |\n",
            "| losses_all              | 0.0050713387 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.37         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1429302      |\n",
            "------------------------------------------\n",
            " 72% 1432120/2000000 [3:08:23<1:08:29, 138.18it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0997       |\n",
            "| elapsed time            | 03:27:58     |\n",
            "| episodes                | 4460         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0011072602 |\n",
            "| loss_margin             | 0.0047385506 |\n",
            "| loss_n_td               | 0.0014115104 |\n",
            "| loss_td                 | 0.018345498  |\n",
            "| losses_all              | 0.0036433963 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.26         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1432122      |\n",
            "------------------------------------------\n",
            " 72% 1435060/2000000 [3:08:46<1:10:04, 134.37it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0996       |\n",
            "| elapsed time            | 03:28:22     |\n",
            "| episodes                | 4470         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010679833 |\n",
            "| loss_margin             | 0.058476463  |\n",
            "| loss_n_td               | 0.0076160254 |\n",
            "| loss_td                 | 0.017046344  |\n",
            "| losses_all              | 0.007480976  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.23         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1435061      |\n",
            "------------------------------------------\n",
            " 72% 1437890/2000000 [3:09:09<1:11:03, 131.83it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0996       |\n",
            "| elapsed time            | 03:28:44     |\n",
            "| episodes                | 4480         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010274521 |\n",
            "| loss_margin             | 0.010668714  |\n",
            "| loss_n_td               | 0.0023382204 |\n",
            "| loss_td                 | 0.011587929  |\n",
            "| losses_all              | 0.0032401304 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.17         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1437902      |\n",
            "------------------------------------------\n",
            " 72% 1440258/2000000 [3:09:28<1:11:25, 130.62it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0995       |\n",
            "| elapsed time            | 03:29:04     |\n",
            "| episodes                | 4490         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010159397 |\n",
            "| loss_margin             | 0.082915604  |\n",
            "| loss_n_td               | 0.025685305  |\n",
            "| loss_td                 | 0.015831431  |\n",
            "| losses_all              | 0.009558766  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.11         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1440272      |\n",
            "------------------------------------------\n",
            " 72% 1443224/2000000 [3:09:52<1:09:27, 133.60it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0995       |\n",
            "| elapsed time            | 03:29:28     |\n",
            "| episodes                | 4500         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010174381 |\n",
            "| loss_margin             | 0.004169967  |\n",
            "| loss_n_td               | 0.004041753  |\n",
            "| loss_td                 | 0.0064447764 |\n",
            "| losses_all              | 0.0025835834 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 0.96         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1443231      |\n",
            "------------------------------------------\n",
            " 72% 1446272/2000000 [3:10:17<1:08:38, 134.43it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0994       |\n",
            "| elapsed time            | 03:29:52     |\n",
            "| episodes                | 4510         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.000973654  |\n",
            "| loss_margin             | 0.02139831   |\n",
            "| loss_n_td               | 0.028080387  |\n",
            "| loss_td                 | 0.0051497463 |\n",
            "| losses_all              | 0.005071188  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 0.9          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1446278      |\n",
            "------------------------------------------\n",
            " 72% 1449424/2000000 [3:10:43<1:07:40, 135.60it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0993        |\n",
            "| elapsed time            | 03:30:18      |\n",
            "| episodes                | 4520          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00094827847 |\n",
            "| loss_margin             | 0.017101403   |\n",
            "| loss_n_td               | 0.004433941   |\n",
            "| loss_td                 | 0.004247765   |\n",
            "| losses_all              | 0.0031599388  |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 0.94          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1449425       |\n",
            "-------------------------------------------\n",
            " 73% 1452458/2000000 [3:11:07<1:09:09, 131.95it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0993       |\n",
            "| elapsed time            | 03:30:43     |\n",
            "| episodes                | 4530         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0014565776 |\n",
            "| loss_margin             | 0.04638934   |\n",
            "| loss_n_td               | 0.0052770567 |\n",
            "| loss_td                 | 0.035289936  |\n",
            "| losses_all              | 0.01089501   |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 0.99         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1452459      |\n",
            "------------------------------------------\n",
            " 73% 1455916/2000000 [3:11:35<1:08:50, 131.71it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0992       |\n",
            "| elapsed time            | 03:31:10     |\n",
            "| episodes                | 4540         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.001321438  |\n",
            "| loss_margin             | 0.032869454  |\n",
            "| loss_n_td               | 0.0002686527 |\n",
            "| loss_td                 | 0.039937288  |\n",
            "| losses_all              | 0.008847195  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.02         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1455919      |\n",
            "------------------------------------------\n",
            " 73% 1459336/2000000 [3:12:02<1:05:53, 136.74it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0991       |\n",
            "| elapsed time            | 03:31:38     |\n",
            "| episodes                | 4550         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.001252254  |\n",
            "| loss_margin             | 0.028441483  |\n",
            "| loss_n_td               | 0.0065278574 |\n",
            "| loss_td                 | 0.018060481  |\n",
            "| losses_all              | 0.006274758  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.11         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1459349      |\n",
            "------------------------------------------\n",
            " 73% 1462258/2000000 [3:12:26<1:07:09, 133.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.099        |\n",
            "| elapsed time            | 03:32:01     |\n",
            "| episodes                | 4560         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0011571562 |\n",
            "| loss_margin             | 0.0012940466 |\n",
            "| loss_n_td               | 0.004393868  |\n",
            "| loss_td                 | 0.026961979  |\n",
            "| losses_all              | 0.0048121386 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.14         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1462265      |\n",
            "------------------------------------------\n",
            " 73% 1465157/2000000 [3:12:49<1:08:55, 129.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.099        |\n",
            "| elapsed time            | 03:32:25     |\n",
            "| episodes                | 4570         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0011031693 |\n",
            "| loss_margin             | 0.042098477  |\n",
            "| loss_n_td               | 0.0139744915 |\n",
            "| loss_td                 | 0.012064066  |\n",
            "| losses_all              | 0.006701934  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.1          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1465166      |\n",
            "------------------------------------------\n",
            " 73% 1468518/2000000 [3:13:16<1:07:28, 131.29it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0989       |\n",
            "| elapsed time            | 03:32:52     |\n",
            "| episodes                | 4580         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010200049 |\n",
            "| loss_margin             | 0.048390627  |\n",
            "| loss_n_td               | 0.0030370262 |\n",
            "| loss_td                 | 0.028629094  |\n",
            "| losses_all              | 0.0072670686 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.22         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1468519      |\n",
            "------------------------------------------\n",
            " 74% 1471944/2000000 [3:13:43<1:06:24, 132.52it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0988       |\n",
            "| elapsed time            | 03:33:19     |\n",
            "| episodes                | 4590         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0009808386 |\n",
            "| loss_margin             | 0.03672736   |\n",
            "| loss_n_td               | 0.015018393  |\n",
            "| loss_td                 | 0.01467061   |\n",
            "| losses_all              | 0.0056638573 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.35         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1471949      |\n",
            "------------------------------------------\n",
            " 74% 1475758/2000000 [3:14:14<1:06:55, 130.56it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0987       |\n",
            "| elapsed time            | 03:33:49     |\n",
            "| episodes                | 4600         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0009058119 |\n",
            "| loss_margin             | 0.025057543  |\n",
            "| loss_n_td               | 0.009167759  |\n",
            "| loss_td                 | 0.026761426  |\n",
            "| losses_all              | 0.005230689  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.53         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1475765      |\n",
            "------------------------------------------\n",
            " 74% 1478716/2000000 [3:14:38<1:06:03, 131.53it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0987        |\n",
            "| elapsed time            | 03:34:13      |\n",
            "| episodes                | 4610          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00085766066 |\n",
            "| loss_margin             | 0.01171617    |\n",
            "| loss_n_td               | 0.0006149356  |\n",
            "| loss_td                 | 0.022559663   |\n",
            "| losses_all              | 0.0036599864  |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 1.5           |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1478727       |\n",
            "-------------------------------------------\n",
            " 74% 1482034/2000000 [3:15:04<1:06:53, 129.05it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0986        |\n",
            "| elapsed time            | 03:34:40      |\n",
            "| episodes                | 4620          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0008339941  |\n",
            "| loss_margin             | 0.00031813234 |\n",
            "| loss_n_td               | 0.006281733   |\n",
            "| loss_td                 | 0.01704104    |\n",
            "| losses_all              | 0.0029373602  |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 1.48          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1482041       |\n",
            "-------------------------------------------\n",
            " 74% 1484925/2000000 [3:15:27<1:05:06, 131.86it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0986       |\n",
            "| elapsed time            | 03:35:03     |\n",
            "| episodes                | 4630         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0008014874 |\n",
            "| loss_margin             | 0.04215712   |\n",
            "| loss_n_td               | 0.013191871  |\n",
            "| loss_td                 | 0.010428267  |\n",
            "| losses_all              | 0.0067235758 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.29         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1484930      |\n",
            "------------------------------------------\n",
            " 74% 1488385/2000000 [3:15:56<1:05:42, 129.78it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0985       |\n",
            "| elapsed time            | 03:35:31     |\n",
            "| episodes                | 4640         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007808418 |\n",
            "| loss_margin             | 0.06650086   |\n",
            "| loss_n_td               | 0.010859337  |\n",
            "| loss_td                 | 0.025297727  |\n",
            "| losses_all              | 0.007846974  |\n",
            "| max 100 episode reward  | 6            |\n",
            "| mean 100 episode reward | 1.35         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1488399      |\n",
            "------------------------------------------\n",
            " 75% 1492169/2000000 [3:16:26<1:05:23, 129.45it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0984        |\n",
            "| elapsed time            | 03:36:01      |\n",
            "| episodes                | 4650          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00077708036 |\n",
            "| loss_margin             | 0.044408806   |\n",
            "| loss_n_td               | 0.038025077   |\n",
            "| loss_td                 | 0.037074313   |\n",
            "| losses_all              | 0.00730516    |\n",
            "| max 100 episode reward  | 6             |\n",
            "| mean 100 episode reward | 1.27          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1492181       |\n",
            "-------------------------------------------\n",
            " 75% 1495315/2000000 [3:16:51<1:07:45, 124.15it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0984       |\n",
            "| elapsed time            | 03:36:27     |\n",
            "| episodes                | 4660         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007655884 |\n",
            "| loss_margin             | 0.014544694  |\n",
            "| loss_n_td               | 0.0076003796 |\n",
            "| loss_td                 | 0.004472117  |\n",
            "| losses_all              | 0.0029954386 |\n",
            "| max 100 episode reward  | 6            |\n",
            "| mean 100 episode reward | 1.28         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1495324      |\n",
            "------------------------------------------\n",
            " 75% 1498983/2000000 [3:17:21<1:05:10, 128.12it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0983        |\n",
            "| elapsed time            | 03:36:56      |\n",
            "| episodes                | 4670          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00075788354 |\n",
            "| loss_margin             | 0.057132367   |\n",
            "| loss_n_td               | 0.015415929   |\n",
            "| loss_td                 | 0.016526626   |\n",
            "| losses_all              | 0.006953826   |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 1.44          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1498984       |\n",
            "-------------------------------------------\n",
            " 75% 1499992/2000000 [3:17:29<1:02:53, 132.51it/s]saved checkpoint\n",
            " 75% 1502294/2000000 [3:17:47<1:04:21, 128.90it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0982        |\n",
            "| elapsed time            | 03:37:23      |\n",
            "| episodes                | 4680          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00078767457 |\n",
            "| loss_margin             | 0.02815577    |\n",
            "| loss_n_td               | 0.029143684   |\n",
            "| loss_td                 | 0.016499989   |\n",
            "| losses_all              | 0.0057790857  |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 1.36          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1502306       |\n",
            "-------------------------------------------\n",
            " 75% 1505026/2000000 [3:18:09<1:04:04, 128.75it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0982       |\n",
            "| elapsed time            | 03:37:45     |\n",
            "| episodes                | 4690         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0014101978 |\n",
            "| loss_margin             | 0.026009765  |\n",
            "| loss_n_td               | 0.016509393  |\n",
            "| loss_td                 | 0.037473567  |\n",
            "| losses_all              | 0.008893875  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.25         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1505027      |\n",
            "------------------------------------------\n",
            " 75% 1507784/2000000 [3:18:32<1:00:32, 135.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0981       |\n",
            "| elapsed time            | 03:38:07     |\n",
            "| episodes                | 4700         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0013743386 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.000577425  |\n",
            "| loss_td                 | 0.0141118    |\n",
            "| losses_all              | 0.0038858163 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.14         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1507785      |\n",
            "------------------------------------------\n",
            " 76% 1510804/2000000 [3:18:56<1:00:33, 134.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0981       |\n",
            "| elapsed time            | 03:38:32     |\n",
            "| episodes                | 4710         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0012725376 |\n",
            "| loss_margin             | 0.0038075037 |\n",
            "| loss_n_td               | 0.007172727  |\n",
            "| loss_td                 | 0.026315203  |\n",
            "| losses_all              | 0.0046192193 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.32         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1510806      |\n",
            "------------------------------------------\n",
            " 76% 1513834/2000000 [3:19:21<1:01:31, 131.69it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.098        |\n",
            "| elapsed time            | 03:38:57     |\n",
            "| episodes                | 4720         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0011794594 |\n",
            "| loss_margin             | 0.0074683093 |\n",
            "| loss_n_td               | 0.010690177  |\n",
            "| loss_td                 | 0.026560571  |\n",
            "| losses_all              | 0.0050909165 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.31         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1513845      |\n",
            "------------------------------------------\n",
            " 76% 1517091/2000000 [3:19:47<1:01:50, 130.16it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0979       |\n",
            "| elapsed time            | 03:39:22     |\n",
            "| episodes                | 4730         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0011030666 |\n",
            "| loss_margin             | 0.002372779  |\n",
            "| loss_n_td               | 0.0031601274 |\n",
            "| loss_td                 | 0.0293154    |\n",
            "| losses_all              | 0.004233467  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.36         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1517093      |\n",
            "------------------------------------------\n",
            " 76% 1519728/2000000 [3:20:08<59:13, 135.14it/s]  ------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0979       |\n",
            "| elapsed time            | 03:39:44     |\n",
            "| episodes                | 4740         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010491062 |\n",
            "| loss_margin             | 0.0017550439 |\n",
            "| loss_n_td               | 0.010070372  |\n",
            "| loss_td                 | 0.038151253  |\n",
            "| losses_all              | 0.0052299667 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.23         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1519734      |\n",
            "------------------------------------------\n",
            " 76% 1523082/2000000 [3:20:35<1:03:05, 125.97it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0978       |\n",
            "| elapsed time            | 03:40:11     |\n",
            "| episodes                | 4750         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0009905793 |\n",
            "| loss_margin             | 0.02847268   |\n",
            "| loss_n_td               | 0.008859757  |\n",
            "| loss_td                 | 0.026313463  |\n",
            "| losses_all              | 0.0055817473 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.29         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1523094      |\n",
            "------------------------------------------\n",
            " 76% 1525586/2000000 [3:20:56<1:00:27, 130.78it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0978        |\n",
            "| elapsed time            | 03:40:32      |\n",
            "| episodes                | 4760          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0009392086  |\n",
            "| loss_margin             | 3.1661242e-05 |\n",
            "| loss_n_td               | 0.025282972   |\n",
            "| loss_td                 | 0.024185594   |\n",
            "| losses_all              | 0.004541228   |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 1.25          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1525595       |\n",
            "-------------------------------------------\n",
            " 76% 1528849/2000000 [3:21:22<59:37, 131.70it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0977       |\n",
            "| elapsed time            | 03:40:58     |\n",
            "| episodes                | 4770         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0008860304 |\n",
            "| loss_margin             | 0.040690605  |\n",
            "| loss_n_td               | 0.0062766653 |\n",
            "| loss_td                 | 0.03963106   |\n",
            "| losses_all              | 0.0072472272 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.16         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1528860      |\n",
            "------------------------------------------\n",
            " 77% 1531949/2000000 [3:21:47<59:00, 132.19it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0977        |\n",
            "| elapsed time            | 03:41:22      |\n",
            "| episodes                | 4780          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00085033255 |\n",
            "| loss_margin             | 0.034005903   |\n",
            "| loss_n_td               | 0.017409995   |\n",
            "| loss_td                 | 0.020487763   |\n",
            "| losses_all              | 0.0062524206  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.19          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1531960       |\n",
            "-------------------------------------------\n",
            " 77% 1535173/2000000 [3:22:13<59:12, 130.84it/s]  -------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0976        |\n",
            "| elapsed time            | 03:41:48      |\n",
            "| episodes                | 4790          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00081766094 |\n",
            "| loss_margin             | 0.034761082   |\n",
            "| loss_n_td               | 0.0044689826  |\n",
            "| loss_td                 | 0.020635644   |\n",
            "| losses_all              | 0.0057979366  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.24          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1535174       |\n",
            "-------------------------------------------\n",
            " 77% 1538190/2000000 [3:22:37<58:25, 131.73it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0975        |\n",
            "| elapsed time            | 03:42:13      |\n",
            "| episodes                | 4800          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00078635773 |\n",
            "| loss_margin             | 0.05146117    |\n",
            "| loss_n_td               | 0.011033694   |\n",
            "| loss_td                 | 0.023829393   |\n",
            "| losses_all              | 0.006805083   |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.26          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1538200       |\n",
            "-------------------------------------------\n",
            " 77% 1541510/2000000 [3:23:04<58:02, 131.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0975       |\n",
            "| elapsed time            | 03:42:39     |\n",
            "| episodes                | 4810         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.000780399  |\n",
            "| loss_margin             | 0.0002056472 |\n",
            "| loss_n_td               | 0.0028688821 |\n",
            "| loss_td                 | 0.0131825665 |\n",
            "| losses_all              | 0.0023247832 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.12         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1541520      |\n",
            "------------------------------------------\n",
            " 77% 1544069/2000000 [3:23:24<57:45, 131.57it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0974       |\n",
            "| elapsed time            | 03:43:00     |\n",
            "| episodes                | 4820         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007570623 |\n",
            "| loss_margin             | 0.036875516  |\n",
            "| loss_n_td               | 0.0013811934 |\n",
            "| loss_td                 | 0.037144527  |\n",
            "| losses_all              | 0.006389015  |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.06         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1544077      |\n",
            "------------------------------------------\n",
            " 77% 1547057/2000000 [3:23:48<58:21, 129.37it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0974       |\n",
            "| elapsed time            | 03:43:24     |\n",
            "| episodes                | 4830         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.000739563  |\n",
            "| loss_margin             | 0.064658     |\n",
            "| loss_n_td               | 0.026522908  |\n",
            "| loss_td                 | 0.016729802  |\n",
            "| losses_all              | 0.0076649496 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.02         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1547069      |\n",
            "------------------------------------------\n",
            " 78% 1550465/2000000 [3:24:16<57:05, 131.24it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0973        |\n",
            "| elapsed time            | 03:43:51      |\n",
            "| episodes                | 4840          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00071834796 |\n",
            "| loss_margin             | 0.026355173   |\n",
            "| loss_n_td               | 0.017278954   |\n",
            "| loss_td                 | 0.007404971   |\n",
            "| losses_all              | 0.004221296   |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.04          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1550478       |\n",
            "-------------------------------------------\n",
            " 78% 1553157/2000000 [3:24:37<57:47, 128.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0973       |\n",
            "| elapsed time            | 03:44:13     |\n",
            "| episodes                | 4850         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007129231 |\n",
            "| loss_margin             | 0.047133125  |\n",
            "| loss_n_td               | 0.009615444  |\n",
            "| loss_td                 | 0.03165499   |\n",
            "| losses_all              | 0.007290347  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 0.97         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1553170      |\n",
            "------------------------------------------\n",
            " 78% 1556251/2000000 [3:25:02<55:51, 132.41it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0972       |\n",
            "| elapsed time            | 03:44:38     |\n",
            "| episodes                | 4860         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007167487 |\n",
            "| loss_margin             | 0.025477592  |\n",
            "| loss_n_td               | 0.009769272  |\n",
            "| loss_td                 | 0.035526887  |\n",
            "| losses_all              | 0.0062594633 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.08         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1556264      |\n",
            "------------------------------------------\n",
            " 78% 1559527/2000000 [3:25:28<55:38, 131.95it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0972        |\n",
            "| elapsed time            | 03:45:04      |\n",
            "| episodes                | 4870          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00069934403 |\n",
            "| loss_margin             | 0.0058443956  |\n",
            "| loss_n_td               | 0.002015816   |\n",
            "| loss_td                 | 0.0065518073  |\n",
            "| losses_all              | 0.0020679196  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.14          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1559529       |\n",
            "-------------------------------------------\n",
            " 78% 1563653/2000000 [3:26:01<55:17, 131.54it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0971        |\n",
            "| elapsed time            | 03:45:37      |\n",
            "| episodes                | 4880          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00091543834 |\n",
            "| loss_margin             | 0.012514435   |\n",
            "| loss_n_td               | 0.0012322941  |\n",
            "| loss_td                 | 0.0655187     |\n",
            "| losses_all              | 0.007858951   |\n",
            "| max 100 episode reward  | 10            |\n",
            "| mean 100 episode reward | 1.3           |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1563666       |\n",
            "-------------------------------------------\n",
            " 78% 1566721/2000000 [3:26:26<55:39, 129.74it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0971       |\n",
            "| elapsed time            | 03:46:01     |\n",
            "| episodes                | 4890         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0009288211 |\n",
            "| loss_margin             | 0.025552215  |\n",
            "| loss_n_td               | 0.0075285905 |\n",
            "| loss_td                 | 0.023022648  |\n",
            "| losses_all              | 0.0049300855 |\n",
            "| max 100 episode reward  | 10           |\n",
            "| mean 100 episode reward | 1.29         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1566731      |\n",
            "------------------------------------------\n",
            " 78% 1569595/2000000 [3:26:49<53:37, 133.77it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.097         |\n",
            "| elapsed time            | 03:46:24      |\n",
            "| episodes                | 4900          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00086794415 |\n",
            "| loss_margin             | 0.00030623004 |\n",
            "| loss_n_td               | 0.0046516564  |\n",
            "| loss_td                 | 0.0047144527  |\n",
            "| losses_all              | 0.0020281035  |\n",
            "| max 100 episode reward  | 10            |\n",
            "| mean 100 episode reward | 1.29          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1569596       |\n",
            "-------------------------------------------\n",
            " 79% 1572797/2000000 [3:27:14<53:16, 133.65it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.097         |\n",
            "| elapsed time            | 03:46:50      |\n",
            "| episodes                | 4910          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00084095786 |\n",
            "| loss_margin             | 0.00017854199 |\n",
            "| loss_n_td               | 0.013819504   |\n",
            "| loss_td                 | 0.03345782    |\n",
            "| losses_all              | 0.0044508385  |\n",
            "| max 100 episode reward  | 10            |\n",
            "| mean 100 episode reward | 1.33          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1572800       |\n",
            "-------------------------------------------\n",
            " 79% 1575741/2000000 [3:27:38<52:46, 133.97it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0969       |\n",
            "| elapsed time            | 03:47:13     |\n",
            "| episodes                | 4920         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0008404739 |\n",
            "| loss_margin             | 0.009202503  |\n",
            "| loss_n_td               | 0.008273677  |\n",
            "| loss_td                 | 0.0033554346 |\n",
            "| losses_all              | 0.0025456408 |\n",
            "| max 100 episode reward  | 10           |\n",
            "| mean 100 episode reward | 1.29         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1575747      |\n",
            "------------------------------------------\n",
            " 79% 1578557/2000000 [3:28:00<53:12, 132.00it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0969        |\n",
            "| elapsed time            | 03:47:36      |\n",
            "| episodes                | 4930          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0007898266  |\n",
            "| loss_margin             | 0.0005743988  |\n",
            "| loss_n_td               | 0.00069214206 |\n",
            "| loss_td                 | 0.009124938   |\n",
            "| losses_all              | 0.0019216681  |\n",
            "| max 100 episode reward  | 10            |\n",
            "| mean 100 episode reward | 1.28          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1578563       |\n",
            "-------------------------------------------\n",
            " 79% 1582016/2000000 [3:28:27<52:42, 132.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0968       |\n",
            "| elapsed time            | 03:48:03     |\n",
            "| episodes                | 4940         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007948238 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0007374338 |\n",
            "| loss_td                 | 0.015015189  |\n",
            "| losses_all              | 0.0022116962 |\n",
            "| max 100 episode reward  | 10           |\n",
            "| mean 100 episode reward | 1.3          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1582029      |\n",
            "------------------------------------------\n",
            " 79% 1585580/2000000 [3:28:55<50:09, 137.70it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0967       |\n",
            "| elapsed time            | 03:48:31     |\n",
            "| episodes                | 4950         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007633647 |\n",
            "| loss_margin             | 0.047194347  |\n",
            "| loss_n_td               | 0.014126101  |\n",
            "| loss_td                 | 0.016943224  |\n",
            "| losses_all              | 0.0059567746 |\n",
            "| max 100 episode reward  | 10           |\n",
            "| mean 100 episode reward | 1.4          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1585584      |\n",
            "------------------------------------------\n",
            " 79% 1589197/2000000 [3:29:24<52:04, 131.48it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0967       |\n",
            "| elapsed time            | 03:49:00     |\n",
            "| episodes                | 4960         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007473326 |\n",
            "| loss_margin             | 0.018351749  |\n",
            "| loss_n_td               | 0.0054273936 |\n",
            "| loss_td                 | 0.0034150318 |\n",
            "| losses_all              | 0.002688425  |\n",
            "| max 100 episode reward  | 10           |\n",
            "| mean 100 episode reward | 1.27         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1589206      |\n",
            "------------------------------------------\n",
            " 80% 1592308/2000000 [3:29:49<51:10, 132.80it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0966        |\n",
            "| elapsed time            | 03:49:24      |\n",
            "| episodes                | 4970          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00075210835 |\n",
            "| loss_margin             | 0.043027043   |\n",
            "| loss_n_td               | 0.006047499   |\n",
            "| loss_td                 | 0.0126281455  |\n",
            "| losses_all              | 0.00526893    |\n",
            "| max 100 episode reward  | 10            |\n",
            "| mean 100 episode reward | 1.2           |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1592310       |\n",
            "-------------------------------------------\n",
            " 80% 1595270/2000000 [3:30:12<50:49, 132.70it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0966       |\n",
            "| elapsed time            | 03:49:48     |\n",
            "| episodes                | 4980         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007619255 |\n",
            "| loss_margin             | 0.02785429   |\n",
            "| loss_n_td               | 0.0039128577 |\n",
            "| loss_td                 | 0.014490137  |\n",
            "| losses_all              | 0.004545357  |\n",
            "| max 100 episode reward  | 8            |\n",
            "| mean 100 episode reward | 0.99         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1595271      |\n",
            "------------------------------------------\n",
            " 80% 1598766/2000000 [3:30:40<51:33, 129.72it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0965        |\n",
            "| elapsed time            | 03:50:16      |\n",
            "| episodes                | 4990          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0007516732  |\n",
            "| loss_margin             | 0.027057607   |\n",
            "| loss_n_td               | 0.00051532715 |\n",
            "| loss_td                 | 0.005464849   |\n",
            "| losses_all              | 0.0036412715  |\n",
            "| max 100 episode reward  | 8             |\n",
            "| mean 100 episode reward | 1.11          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1598772       |\n",
            "-------------------------------------------\n",
            " 80% 1599999/2000000 [3:30:51<50:42, 131.46it/s]saved checkpoint\n",
            " 80% 1602044/2000000 [3:31:07<51:49, 127.96it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0965       |\n",
            "| elapsed time            | 03:50:43     |\n",
            "| episodes                | 5000         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007688896 |\n",
            "| loss_margin             | 0.06017408   |\n",
            "| loss_n_td               | 0.02846286   |\n",
            "| loss_td                 | 0.007419317  |\n",
            "| losses_all              | 0.007212653  |\n",
            "| max 100 episode reward  | 8            |\n",
            "| mean 100 episode reward | 1.16         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1602051      |\n",
            "------------------------------------------\n",
            " 80% 1605788/2000000 [3:31:36<47:35, 138.07it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0964        |\n",
            "| elapsed time            | 03:51:12      |\n",
            "| episodes                | 5010          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00075733213 |\n",
            "| loss_margin             | 0.0029525869  |\n",
            "| loss_n_td               | 0.002784145   |\n",
            "| loss_td                 | 0.0074642426  |\n",
            "| losses_all              | 0.002132067   |\n",
            "| max 100 episode reward  | 8             |\n",
            "| mean 100 episode reward | 1.22          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1605798       |\n",
            "-------------------------------------------\n",
            " 80% 1608652/2000000 [3:31:59<48:50, 133.52it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0964       |\n",
            "| elapsed time            | 03:51:35     |\n",
            "| episodes                | 5020         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0017428889 |\n",
            "| loss_margin             | 0.031824682  |\n",
            "| loss_n_td               | 0.048605405  |\n",
            "| loss_td                 | 0.2076047    |\n",
            "| losses_all              | 0.046887454  |\n",
            "| max 100 episode reward  | 8            |\n",
            "| mean 100 episode reward | 1.31         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1608655      |\n",
            "------------------------------------------\n",
            " 81% 1611221/2000000 [3:32:20<48:37, 133.26it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0964       |\n",
            "| elapsed time            | 03:51:56     |\n",
            "| episodes                | 5030         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0013959641 |\n",
            "| loss_margin             | 0.03462385   |\n",
            "| loss_n_td               | 0.009548705  |\n",
            "| loss_td                 | 0.011952847  |\n",
            "| losses_all              | 0.0054755835 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.4          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1611234      |\n",
            "------------------------------------------\n",
            " 81% 1614144/2000000 [3:32:44<47:23, 135.68it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0963       |\n",
            "| elapsed time            | 03:52:19     |\n",
            "| episodes                | 5040         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0012048138 |\n",
            "| loss_margin             | 0.069660135  |\n",
            "| loss_n_td               | 0.031836756  |\n",
            "| loss_td                 | 0.03524807   |\n",
            "| losses_all              | 0.008922548  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.41         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1614145      |\n",
            "------------------------------------------\n",
            " 81% 1617213/2000000 [3:33:08<48:37, 131.21it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0963       |\n",
            "| elapsed time            | 03:52:44     |\n",
            "| episodes                | 5050         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010723562 |\n",
            "| loss_margin             | 0.06184704   |\n",
            "| loss_n_td               | 0.021726318  |\n",
            "| loss_td                 | 0.029976068  |\n",
            "| losses_all              | 0.008815508  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.28         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1617213      |\n",
            "------------------------------------------\n",
            " 81% 1619760/2000000 [3:33:29<46:43, 135.65it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.0962      |\n",
            "| elapsed time            | 03:53:04    |\n",
            "| episodes                | 5060        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.001000522 |\n",
            "| loss_margin             | 0.033201076 |\n",
            "| loss_n_td               | 0.017153958 |\n",
            "| loss_td                 | 0.011087358 |\n",
            "| losses_all              | 0.005206333 |\n",
            "| max 100 episode reward  | 9           |\n",
            "| mean 100 episode reward | 1.27        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1619766     |\n",
            "-----------------------------------------\n",
            " 81% 1622932/2000000 [3:33:54<45:59, 136.62it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0962       |\n",
            "| elapsed time            | 03:53:29     |\n",
            "| episodes                | 5070         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0009213913 |\n",
            "| loss_margin             | 0.05881771   |\n",
            "| loss_n_td               | 0.03511373   |\n",
            "| loss_td                 | 0.038821228  |\n",
            "| losses_all              | 0.010454183  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.23         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1622934      |\n",
            "------------------------------------------\n",
            " 81% 1625584/2000000 [3:34:15<45:29, 137.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0962       |\n",
            "| elapsed time            | 03:53:51     |\n",
            "| episodes                | 5080         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0008681236 |\n",
            "| loss_margin             | 0.06301752   |\n",
            "| loss_n_td               | 0.031438857  |\n",
            "| loss_td                 | 0.031630035  |\n",
            "| losses_all              | 0.008376252  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.26         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1625595      |\n",
            "------------------------------------------\n",
            " 81% 1629152/2000000 [3:34:43<44:49, 137.90it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0961       |\n",
            "| elapsed time            | 03:54:18     |\n",
            "| episodes                | 5090         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0008010545 |\n",
            "| loss_margin             | 0.026555598  |\n",
            "| loss_n_td               | 0.003696362  |\n",
            "| loss_td                 | 0.0103723    |\n",
            "| losses_all              | 0.004233783  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.23         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1629157      |\n",
            "------------------------------------------\n",
            " 82% 1632133/2000000 [3:35:07<46:34, 131.65it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0961        |\n",
            "| elapsed time            | 03:54:42      |\n",
            "| episodes                | 5100          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00076918944 |\n",
            "| loss_margin             | 0.0280323     |\n",
            "| loss_n_td               | 0.012697538   |\n",
            "| loss_td                 | 0.010597495   |\n",
            "| losses_all              | 0.0044324067  |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 1.19          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1632141       |\n",
            "-------------------------------------------\n",
            " 82% 1635031/2000000 [3:35:30<45:16, 134.37it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.096         |\n",
            "| elapsed time            | 03:55:05      |\n",
            "| episodes                | 5110          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00072814064 |\n",
            "| loss_margin             | 0.019861363   |\n",
            "| loss_n_td               | 0.00995653    |\n",
            "| loss_td                 | 0.016551726   |\n",
            "| losses_all              | 0.0044030137  |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 1.12          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1635036       |\n",
            "-------------------------------------------\n",
            " 82% 1638321/2000000 [3:35:56<45:55, 131.25it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.096        |\n",
            "| elapsed time            | 03:55:32     |\n",
            "| episodes                | 5120         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006890325 |\n",
            "| loss_margin             | 0.048138954  |\n",
            "| loss_n_td               | 0.0073564397 |\n",
            "| loss_td                 | 0.03218046   |\n",
            "| losses_all              | 0.0066195093 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.16         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1638327      |\n",
            "------------------------------------------\n",
            " 82% 1642054/2000000 [3:36:26<45:03, 132.42it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0959       |\n",
            "| elapsed time            | 03:56:02     |\n",
            "| episodes                | 5130         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006587843 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.004459804  |\n",
            "| loss_td                 | 0.012040285  |\n",
            "| losses_all              | 0.0022612708 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.12         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1642065      |\n",
            "------------------------------------------\n",
            " 82% 1644925/2000000 [3:36:49<45:34, 129.87it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0959        |\n",
            "| elapsed time            | 03:56:24      |\n",
            "| episodes                | 5140          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00063729053 |\n",
            "| loss_margin             | 0.035072777   |\n",
            "| loss_n_td               | 0.0011932711  |\n",
            "| loss_td                 | 0.025803952   |\n",
            "| losses_all              | 0.0050812704  |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 1.06          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1644931       |\n",
            "-------------------------------------------\n",
            " 82% 1648242/2000000 [3:37:15<47:46, 122.72it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0959       |\n",
            "| elapsed time            | 03:56:51     |\n",
            "| episodes                | 5150         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006142415 |\n",
            "| loss_margin             | 0.04259858   |\n",
            "| loss_n_td               | 0.012102747  |\n",
            "| loss_td                 | 0.02435032   |\n",
            "| losses_all              | 0.0057556555 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.07         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1648255      |\n",
            "------------------------------------------\n",
            " 83% 1651665/2000000 [3:37:42<44:17, 131.08it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0958       |\n",
            "| elapsed time            | 03:57:18     |\n",
            "| episodes                | 5160         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006033305 |\n",
            "| loss_margin             | 0.011768945  |\n",
            "| loss_n_td               | 0.0043281554 |\n",
            "| loss_td                 | 0.026954714  |\n",
            "| losses_all              | 0.0039858734 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.13         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1651671      |\n",
            "------------------------------------------\n",
            " 83% 1654371/2000000 [3:38:04<43:03, 133.76it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0958        |\n",
            "| elapsed time            | 03:57:40      |\n",
            "| episodes                | 5170          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00060356903 |\n",
            "| loss_margin             | 0.027495302   |\n",
            "| loss_n_td               | 0.0027791322  |\n",
            "| loss_td                 | 0.0149633745  |\n",
            "| losses_all              | 0.0038925053  |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 1.11          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1654383       |\n",
            "-------------------------------------------\n",
            " 83% 1657287/2000000 [3:38:28<42:53, 133.16it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0957       |\n",
            "| elapsed time            | 03:58:03     |\n",
            "| episodes                | 5180         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005888433 |\n",
            "| loss_margin             | 0.027873624  |\n",
            "| loss_n_td               | 0.006395812  |\n",
            "| loss_td                 | 0.0065811034 |\n",
            "| losses_all              | 0.0037055004 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.13         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1657289      |\n",
            "------------------------------------------\n",
            " 83% 1660244/2000000 [3:38:51<41:56, 134.99it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0957       |\n",
            "| elapsed time            | 03:58:27     |\n",
            "| episodes                | 5190         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005816636 |\n",
            "| loss_margin             | 0.019016169  |\n",
            "| loss_n_td               | 0.00572508   |\n",
            "| loss_td                 | 0.01524765   |\n",
            "| losses_all              | 0.0037044445 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.01         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1660255      |\n",
            "------------------------------------------\n",
            " 83% 1663359/2000000 [3:39:16<43:07, 130.11it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0957       |\n",
            "| elapsed time            | 03:58:52     |\n",
            "| episodes                | 5200         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005825639 |\n",
            "| loss_margin             | 0.03999887   |\n",
            "| loss_n_td               | 0.014229035  |\n",
            "| loss_td                 | 0.014829773  |\n",
            "| losses_all              | 0.0051155696 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.02         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1663362      |\n",
            "------------------------------------------\n",
            " 83% 1666381/2000000 [3:39:40<41:56, 132.58it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0956       |\n",
            "| elapsed time            | 03:59:16     |\n",
            "| episodes                | 5210         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005978759 |\n",
            "| loss_margin             | 0.025829542  |\n",
            "| loss_n_td               | 0.003549075  |\n",
            "| loss_td                 | 0.015033628  |\n",
            "| losses_all              | 0.0039909477 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1            |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1666393      |\n",
            "------------------------------------------\n",
            " 83% 1669746/2000000 [3:40:07<41:55, 131.31it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0956        |\n",
            "| elapsed time            | 03:59:43      |\n",
            "| episodes                | 5220          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00058283226 |\n",
            "| loss_margin             | 0.052345853   |\n",
            "| loss_n_td               | 0.004277045   |\n",
            "| loss_td                 | 0.011246306   |\n",
            "| losses_all              | 0.0049708677  |\n",
            "| max 100 episode reward  | 4             |\n",
            "| mean 100 episode reward | 0.97          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1669758       |\n",
            "-------------------------------------------\n",
            " 84% 1672849/2000000 [3:40:31<41:22, 131.79it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0956       |\n",
            "| elapsed time            | 04:00:07     |\n",
            "| episodes                | 5230         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005822225 |\n",
            "| loss_margin             | 0.028853714  |\n",
            "| loss_n_td               | 0.021405758  |\n",
            "| loss_td                 | 0.005902416  |\n",
            "| losses_all              | 0.004156658  |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 0.97         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1672863      |\n",
            "------------------------------------------\n",
            " 84% 1675434/2000000 [3:40:52<40:55, 132.18it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0955        |\n",
            "| elapsed time            | 04:00:28      |\n",
            "| episodes                | 5240          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00058515614 |\n",
            "| loss_margin             | 0.02485485    |\n",
            "| loss_n_td               | 0.017004242   |\n",
            "| loss_td                 | 0.012650752   |\n",
            "| losses_all              | 0.003943297   |\n",
            "| max 100 episode reward  | 4             |\n",
            "| mean 100 episode reward | 0.95          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1675439       |\n",
            "-------------------------------------------\n",
            " 84% 1678454/2000000 [3:41:16<41:29, 129.16it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0955        |\n",
            "| elapsed time            | 04:00:52      |\n",
            "| episodes                | 5250          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00058840535 |\n",
            "| loss_margin             | 0.004782319   |\n",
            "| loss_n_td               | 0.021425126   |\n",
            "| loss_td                 | 0.00550895    |\n",
            "| losses_all              | 0.0028435672  |\n",
            "| max 100 episode reward  | 8             |\n",
            "| mean 100 episode reward | 1.03          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1678465       |\n",
            "-------------------------------------------\n",
            " 84% 1681344/2000000 [3:41:40<38:56, 136.41it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0955       |\n",
            "| elapsed time            | 04:01:16     |\n",
            "| episodes                | 5260         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006213729 |\n",
            "| loss_margin             | 0.06704896   |\n",
            "| loss_n_td               | 0.007608558  |\n",
            "| loss_td                 | 0.015397597  |\n",
            "| losses_all              | 0.006675781  |\n",
            "| max 100 episode reward  | 8            |\n",
            "| mean 100 episode reward | 1.03         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1681355      |\n",
            "------------------------------------------\n",
            " 84% 1683811/2000000 [3:42:00<39:39, 132.86it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0954       |\n",
            "| elapsed time            | 04:01:35     |\n",
            "| episodes                | 5270         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006114712 |\n",
            "| loss_margin             | 0.050476428  |\n",
            "| loss_n_td               | 0.011096917  |\n",
            "| loss_td                 | 0.0025720266 |\n",
            "| losses_all              | 0.0047011003 |\n",
            "| max 100 episode reward  | 8            |\n",
            "| mean 100 episode reward | 1.01         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1683820      |\n",
            "------------------------------------------\n",
            " 84% 1686857/2000000 [3:42:24<40:03, 130.27it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0954       |\n",
            "| elapsed time            | 04:02:00     |\n",
            "| episodes                | 5280         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006215433 |\n",
            "| loss_margin             | 0.037942782  |\n",
            "| loss_n_td               | 0.017841537  |\n",
            "| loss_td                 | 0.013088274  |\n",
            "| losses_all              | 0.0051790015 |\n",
            "| max 100 episode reward  | 8            |\n",
            "| mean 100 episode reward | 0.96         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1686862      |\n",
            "------------------------------------------\n",
            " 85% 1690433/2000000 [3:42:53<39:15, 131.40it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0954       |\n",
            "| elapsed time            | 04:02:28     |\n",
            "| episodes                | 5290         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006219527 |\n",
            "| loss_margin             | 0.063339785  |\n",
            "| loss_n_td               | 0.010032037  |\n",
            "| loss_td                 | 0.0147758145 |\n",
            "| losses_all              | 0.0060527953 |\n",
            "| max 100 episode reward  | 8            |\n",
            "| mean 100 episode reward | 1.01         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1690440      |\n",
            "------------------------------------------\n",
            " 85% 1693819/2000000 [3:43:19<38:34, 132.28it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0953       |\n",
            "| elapsed time            | 04:02:55     |\n",
            "| episodes                | 5300         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006281315 |\n",
            "| loss_margin             | 0.0031268857 |\n",
            "| loss_n_td               | 0.0041615125 |\n",
            "| loss_td                 | 0.0046680695 |\n",
            "| losses_all              | 0.001694113  |\n",
            "| max 100 episode reward  | 8            |\n",
            "| mean 100 episode reward | 1.05         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1693829      |\n",
            "------------------------------------------\n",
            " 85% 1697668/2000000 [3:43:50<37:35, 134.07it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0953        |\n",
            "| elapsed time            | 04:03:26      |\n",
            "| episodes                | 5310          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00063842296 |\n",
            "| loss_margin             | 0.01430868    |\n",
            "| loss_n_td               | 0.0011788416  |\n",
            "| loss_td                 | 0.022676574   |\n",
            "| losses_all              | 0.0038374618  |\n",
            "| max 100 episode reward  | 8             |\n",
            "| mean 100 episode reward | 1.15          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1697679       |\n",
            "-------------------------------------------\n",
            " 85% 1699996/2000000 [3:44:09<36:27, 137.17it/s]saved checkpoint\n",
            " 85% 1700489/2000000 [3:44:13<37:57, 131.51it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0952        |\n",
            "| elapsed time            | 04:03:48      |\n",
            "| episodes                | 5320          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00063857535 |\n",
            "| loss_margin             | 0.00020967424 |\n",
            "| loss_n_td               | 0.0027159492  |\n",
            "| loss_td                 | 0.017701767   |\n",
            "| losses_all              | 0.0028918749  |\n",
            "| max 100 episode reward  | 8             |\n",
            "| mean 100 episode reward | 1.09          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1700501       |\n",
            "-------------------------------------------\n",
            " 85% 1703193/2000000 [3:44:34<37:41, 131.26it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0952       |\n",
            "| elapsed time            | 04:04:10     |\n",
            "| episodes                | 5330         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010298364 |\n",
            "| loss_margin             | 0.024665013  |\n",
            "| loss_n_td               | 0.004441465  |\n",
            "| loss_td                 | 0.010742103  |\n",
            "| losses_all              | 0.004245179  |\n",
            "| max 100 episode reward  | 8            |\n",
            "| mean 100 episode reward | 1.06         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1703193      |\n",
            "------------------------------------------\n",
            " 85% 1705441/2000000 [3:44:53<37:07, 132.23it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0952        |\n",
            "| elapsed time            | 04:04:28      |\n",
            "| episodes                | 5340          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00092916813 |\n",
            "| loss_margin             | 0.0011265688  |\n",
            "| loss_n_td               | 0.004548819   |\n",
            "| loss_td                 | 0.012642106   |\n",
            "| losses_all              | 0.0029157356  |\n",
            "| max 100 episode reward  | 8             |\n",
            "| mean 100 episode reward | 1.06          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1705441       |\n",
            "-------------------------------------------\n",
            " 85% 1707537/2000000 [3:45:10<37:28, 130.09it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0952        |\n",
            "| elapsed time            | 04:04:46      |\n",
            "| episodes                | 5350          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00088387815 |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.0021294362  |\n",
            "| loss_td                 | 0.0074353092  |\n",
            "| losses_all              | 0.0020638972  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 0.95          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1707548       |\n",
            "-------------------------------------------\n",
            " 86% 1710343/2000000 [3:45:32<36:24, 132.61it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0951        |\n",
            "| elapsed time            | 04:05:08      |\n",
            "| episodes                | 5360          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00084376294 |\n",
            "| loss_margin             | 0.026563108   |\n",
            "| loss_n_td               | 0.0065418873  |\n",
            "| loss_td                 | 0.020420067   |\n",
            "| losses_all              | 0.004129949   |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 0.96          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1710355       |\n",
            "-------------------------------------------\n",
            " 86% 1713131/2000000 [3:45:55<36:02, 132.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0951       |\n",
            "| elapsed time            | 04:05:30     |\n",
            "| episodes                | 5370         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.000817114  |\n",
            "| loss_margin             | 0.013439719  |\n",
            "| loss_n_td               | 0.012683542  |\n",
            "| loss_td                 | 0.0053578224 |\n",
            "| losses_all              | 0.0029990734 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.08         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1713141      |\n",
            "------------------------------------------\n",
            " 86% 1715760/2000000 [3:46:16<34:16, 138.18it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0951        |\n",
            "| elapsed time            | 04:05:51      |\n",
            "| episodes                | 5380          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00077603344 |\n",
            "| loss_margin             | 0.00014941767 |\n",
            "| loss_n_td               | 0.013764352   |\n",
            "| loss_td                 | 0.012507296   |\n",
            "| losses_all              | 0.0028236583  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.07          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1715761       |\n",
            "-------------------------------------------\n",
            " 86% 1718434/2000000 [3:46:37<37:52, 123.90it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.095         |\n",
            "| elapsed time            | 04:06:13      |\n",
            "| episodes                | 5390          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00075238995 |\n",
            "| loss_margin             | 0.010432072   |\n",
            "| loss_n_td               | 0.004189416   |\n",
            "| loss_td                 | 0.01600891    |\n",
            "| losses_all              | 0.0033789657  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.04          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1718438       |\n",
            "-------------------------------------------\n",
            " 86% 1721640/2000000 [3:47:03<35:01, 132.45it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.095         |\n",
            "| elapsed time            | 04:06:39      |\n",
            "| episodes                | 5400          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00073202956 |\n",
            "| loss_margin             | 0.026645198   |\n",
            "| loss_n_td               | 0.0024495558  |\n",
            "| loss_td                 | 0.01291638    |\n",
            "| losses_all              | 0.0038989065  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 0.98          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1721653       |\n",
            "-------------------------------------------\n",
            " 86% 1724437/2000000 [3:47:26<37:34, 122.21it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.095         |\n",
            "| elapsed time            | 04:07:01      |\n",
            "| episodes                | 5410          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00071944215 |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.0008130076  |\n",
            "| loss_td                 | 0.010159717   |\n",
            "| losses_all              | 0.0018670501  |\n",
            "| max 100 episode reward  | 20            |\n",
            "| mean 100 episode reward | 1.12          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1724441       |\n",
            "-------------------------------------------\n",
            " 86% 1727911/2000000 [3:47:53<34:28, 131.55it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0949       |\n",
            "| elapsed time            | 04:07:29     |\n",
            "| episodes                | 5420         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007003317 |\n",
            "| loss_margin             | 0.008070793  |\n",
            "| loss_n_td               | 0.007979269  |\n",
            "| loss_td                 | 0.0021376917 |\n",
            "| losses_all              | 0.0020536673 |\n",
            "| max 100 episode reward  | 20           |\n",
            "| mean 100 episode reward | 1.28         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1727920      |\n",
            "------------------------------------------\n",
            " 87% 1730404/2000000 [3:48:13<34:12, 131.33it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0949        |\n",
            "| elapsed time            | 04:07:49      |\n",
            "| episodes                | 5430          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0006874079  |\n",
            "| loss_margin             | 0.00065728277 |\n",
            "| loss_n_td               | 0.0033578565  |\n",
            "| loss_td                 | 0.007995534   |\n",
            "| losses_all              | 0.0017091471  |\n",
            "| max 100 episode reward  | 20            |\n",
            "| mean 100 episode reward | 1.34          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1730410       |\n",
            "-------------------------------------------\n",
            " 87% 1733070/2000000 [3:48:35<33:49, 131.54it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0949        |\n",
            "| elapsed time            | 04:08:10      |\n",
            "| episodes                | 5440          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00068526744 |\n",
            "| loss_margin             | 0.02969407    |\n",
            "| loss_n_td               | 0.024345923   |\n",
            "| loss_td                 | 0.010502352   |\n",
            "| losses_all              | 0.0050665312  |\n",
            "| max 100 episode reward  | 20            |\n",
            "| mean 100 episode reward | 1.47          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1733081       |\n",
            "-------------------------------------------\n",
            " 87% 1735558/2000000 [3:48:55<33:54, 129.96it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0948        |\n",
            "| elapsed time            | 04:08:30      |\n",
            "| episodes                | 5450          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00067788403 |\n",
            "| loss_margin             | 0.0024322234  |\n",
            "| loss_n_td               | 0.0009215374  |\n",
            "| loss_td                 | 0.0061329585  |\n",
            "| losses_all              | 0.0017149956  |\n",
            "| max 100 episode reward  | 20            |\n",
            "| mean 100 episode reward | 1.51          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1735568       |\n",
            "-------------------------------------------\n",
            " 87% 1738513/2000000 [3:49:19<33:15, 131.05it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0948        |\n",
            "| elapsed time            | 04:08:54      |\n",
            "| episodes                | 5460          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00067082717 |\n",
            "| loss_margin             | 0.011249829   |\n",
            "| loss_n_td               | 0.023504518   |\n",
            "| loss_td                 | 0.006289064   |\n",
            "| losses_all              | 0.0035577186  |\n",
            "| max 100 episode reward  | 20            |\n",
            "| mean 100 episode reward | 1.49          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1738518       |\n",
            "-------------------------------------------\n",
            " 87% 1741391/2000000 [3:49:41<32:13, 133.75it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0948       |\n",
            "| elapsed time            | 04:09:17     |\n",
            "| episodes                | 5470         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006794078 |\n",
            "| loss_margin             | 0.013216123  |\n",
            "| loss_n_td               | 0.0016311663 |\n",
            "| loss_td                 | 0.009545423  |\n",
            "| losses_all              | 0.002440425  |\n",
            "| max 100 episode reward  | 20           |\n",
            "| mean 100 episode reward | 1.57         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1741392      |\n",
            "------------------------------------------\n",
            " 87% 1743863/2000000 [3:50:01<31:55, 133.71it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0947       |\n",
            "| elapsed time            | 04:09:37     |\n",
            "| episodes                | 5480         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006785039 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.009653509  |\n",
            "| loss_td                 | 0.024931462  |\n",
            "| losses_all              | 0.0034815697 |\n",
            "| max 100 episode reward  | 20           |\n",
            "| mean 100 episode reward | 1.6          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1743870      |\n",
            "------------------------------------------\n",
            " 87% 1746228/2000000 [3:50:21<31:07, 135.86it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0947        |\n",
            "| elapsed time            | 04:09:56      |\n",
            "| episodes                | 5490          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00067645276 |\n",
            "| loss_margin             | 0.013521802   |\n",
            "| loss_n_td               | 0.0033370475  |\n",
            "| loss_td                 | 0.008646352   |\n",
            "| losses_all              | 0.0027995822  |\n",
            "| max 100 episode reward  | 20            |\n",
            "| mean 100 episode reward | 1.68          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1746237       |\n",
            "-------------------------------------------\n",
            " 87% 1748863/2000000 [3:50:42<31:33, 132.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0947       |\n",
            "| elapsed time            | 04:10:18     |\n",
            "| episodes                | 5500         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006787892 |\n",
            "| loss_margin             | 0.035885833  |\n",
            "| loss_n_td               | 0.008888811  |\n",
            "| loss_td                 | 0.01447955   |\n",
            "| losses_all              | 0.004682056  |\n",
            "| max 100 episode reward  | 20           |\n",
            "| mean 100 episode reward | 1.67         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1748872      |\n",
            "------------------------------------------\n",
            " 88% 1750958/2000000 [3:50:59<32:22, 128.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0947       |\n",
            "| elapsed time            | 04:10:35     |\n",
            "| episodes                | 5510         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0011327965 |\n",
            "| loss_margin             | 0.029190093  |\n",
            "| loss_n_td               | 0.023510704  |\n",
            "| loss_td                 | 0.2284978    |\n",
            "| losses_all              | 0.06122195   |\n",
            "| max 100 episode reward  | 11           |\n",
            "| mean 100 episode reward | 1.47         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1750959      |\n",
            "------------------------------------------\n",
            " 88% 1753193/2000000 [3:51:18<32:21, 127.12it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.0946      |\n",
            "| elapsed time            | 04:10:53    |\n",
            "| episodes                | 5520        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.00107132  |\n",
            "| loss_margin             | 0.009394661 |\n",
            "| loss_n_td               | 0.009678577 |\n",
            "| loss_td                 | 0.008955548 |\n",
            "| losses_all              | 0.003969229 |\n",
            "| max 100 episode reward  | 11          |\n",
            "| mean 100 episode reward | 1.31        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1753200     |\n",
            "-----------------------------------------\n",
            " 88% 1755253/2000000 [3:51:34<30:41, 132.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0946       |\n",
            "| elapsed time            | 04:11:10     |\n",
            "| episodes                | 5530         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.000980475  |\n",
            "| loss_margin             | 0.017869763  |\n",
            "| loss_n_td               | 0.0122948885 |\n",
            "| loss_td                 | 0.00704365   |\n",
            "| losses_all              | 0.0033655355 |\n",
            "| max 100 episode reward  | 11           |\n",
            "| mean 100 episode reward | 1.32         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1755265      |\n",
            "------------------------------------------\n",
            " 88% 1757276/2000000 [3:51:51<31:48, 127.16it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0946        |\n",
            "| elapsed time            | 04:11:27      |\n",
            "| episodes                | 5540          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0009272367  |\n",
            "| loss_margin             | 5.0775707e-05 |\n",
            "| loss_n_td               | 0.02269528    |\n",
            "| loss_td                 | 0.030323232   |\n",
            "| losses_all              | 0.0039538667  |\n",
            "| max 100 episode reward  | 11            |\n",
            "| mean 100 episode reward | 1.22          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1757280       |\n",
            "-------------------------------------------\n",
            " 88% 1759297/2000000 [3:52:08<30:41, 130.74it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0946        |\n",
            "| elapsed time            | 04:11:44      |\n",
            "| episodes                | 5550          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00089849724 |\n",
            "| loss_margin             | 0.039792992   |\n",
            "| loss_n_td               | 0.008720933   |\n",
            "| loss_td                 | 0.02792402    |\n",
            "| losses_all              | 0.005781619   |\n",
            "| max 100 episode reward  | 11            |\n",
            "| mean 100 episode reward | 1.25          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1759302       |\n",
            "-------------------------------------------\n",
            " 88% 1761037/2000000 [3:52:22<30:46, 129.44it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0946        |\n",
            "| elapsed time            | 04:11:58      |\n",
            "| episodes                | 5560          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00087456626 |\n",
            "| loss_margin             | 0.013209268   |\n",
            "| loss_n_td               | 0.021446401   |\n",
            "| loss_td                 | 0.0299415     |\n",
            "| losses_all              | 0.0045321686  |\n",
            "| max 100 episode reward  | 11            |\n",
            "| mean 100 episode reward | 1.28          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1761038       |\n",
            "-------------------------------------------\n",
            " 88% 1763510/2000000 [3:52:43<29:34, 133.30it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0945        |\n",
            "| elapsed time            | 04:12:18      |\n",
            "| episodes                | 5570          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00084098167 |\n",
            "| loss_margin             | 0.026726365   |\n",
            "| loss_n_td               | 0.015401153   |\n",
            "| loss_td                 | 0.0102475565  |\n",
            "| losses_all              | 0.0039484994  |\n",
            "| max 100 episode reward  | 11            |\n",
            "| mean 100 episode reward | 1.25          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1763518       |\n",
            "-------------------------------------------\n",
            " 88% 1765697/2000000 [3:53:00<29:56, 130.44it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0945        |\n",
            "| elapsed time            | 04:12:36      |\n",
            "| episodes                | 5580          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00081953825 |\n",
            "| loss_margin             | 0.014845226   |\n",
            "| loss_n_td               | 0.0028332993  |\n",
            "| loss_td                 | 0.005030603   |\n",
            "| losses_all              | 0.0025890213  |\n",
            "| max 100 episode reward  | 11            |\n",
            "| mean 100 episode reward | 1.27          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1765704       |\n",
            "-------------------------------------------\n",
            " 88% 1768148/2000000 [3:53:20<28:41, 134.65it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0945        |\n",
            "| elapsed time            | 04:12:56      |\n",
            "| episodes                | 5590          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00080724625 |\n",
            "| loss_margin             | 0.018884163   |\n",
            "| loss_n_td               | 0.0017233784  |\n",
            "| loss_td                 | 0.008691887   |\n",
            "| losses_all              | 0.00307914    |\n",
            "| max 100 episode reward  | 6             |\n",
            "| mean 100 episode reward | 1.24          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1768149       |\n",
            "-------------------------------------------\n",
            " 89% 1770196/2000000 [3:53:37<28:44, 133.23it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0945       |\n",
            "| elapsed time            | 04:13:12     |\n",
            "| episodes                | 5600         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007808482 |\n",
            "| loss_margin             | 0.025736183  |\n",
            "| loss_n_td               | 0.003342673  |\n",
            "| loss_td                 | 0.00931701   |\n",
            "| losses_all              | 0.0032049087 |\n",
            "| max 100 episode reward  | 6            |\n",
            "| mean 100 episode reward | 1.29         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1770197      |\n",
            "------------------------------------------\n",
            " 89% 1772080/2000000 [3:53:52<28:01, 135.54it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0944        |\n",
            "| elapsed time            | 04:13:28      |\n",
            "| episodes                | 5610          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00076517806 |\n",
            "| loss_margin             | 0.017593887   |\n",
            "| loss_n_td               | 0.0047657546  |\n",
            "| loss_td                 | 0.007864283   |\n",
            "| losses_all              | 0.0028349068  |\n",
            "| max 100 episode reward  | 6             |\n",
            "| mean 100 episode reward | 1.29          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1772087       |\n",
            "-------------------------------------------\n",
            " 89% 1774178/2000000 [3:54:09<29:08, 129.18it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0944       |\n",
            "| elapsed time            | 04:13:45     |\n",
            "| episodes                | 5620         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007601758 |\n",
            "| loss_margin             | 0.013039362  |\n",
            "| loss_n_td               | 0.004111519  |\n",
            "| loss_td                 | 0.007936539  |\n",
            "| losses_all              | 0.0026350275 |\n",
            "| max 100 episode reward  | 6            |\n",
            "| mean 100 episode reward | 1.37         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1774184      |\n",
            "------------------------------------------\n",
            " 89% 1776029/2000000 [3:54:25<28:56, 128.98it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0944        |\n",
            "| elapsed time            | 04:14:00      |\n",
            "| episodes                | 5630          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0007579289  |\n",
            "| loss_margin             | 4.4692308e-05 |\n",
            "| loss_n_td               | 0.0034784856  |\n",
            "| loss_td                 | 0.00918687    |\n",
            "| losses_all              | 0.0020274024  |\n",
            "| max 100 episode reward  | 6             |\n",
            "| mean 100 episode reward | 1.34          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1776034       |\n",
            "-------------------------------------------\n",
            " 89% 1778157/2000000 [3:54:42<29:07, 126.98it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0944        |\n",
            "| elapsed time            | 04:14:18      |\n",
            "| episodes                | 5640          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00073613843 |\n",
            "| loss_margin             | 0.017792717   |\n",
            "| loss_n_td               | 0.00042436944 |\n",
            "| loss_td                 | 0.005882386   |\n",
            "| losses_all              | 0.0026592403  |\n",
            "| max 100 episode reward  | 6             |\n",
            "| mean 100 episode reward | 1.38          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1778161       |\n",
            "-------------------------------------------\n",
            " 89% 1780142/2000000 [3:54:58<27:35, 132.82it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0944       |\n",
            "| elapsed time            | 04:14:34     |\n",
            "| episodes                | 5650         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007252713 |\n",
            "| loss_margin             | 0.0037097335 |\n",
            "| loss_n_td               | 0.0013678474 |\n",
            "| loss_td                 | 0.005250756  |\n",
            "| losses_all              | 0.0018034562 |\n",
            "| max 100 episode reward  | 6            |\n",
            "| mean 100 episode reward | 1.43         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1780146      |\n",
            "------------------------------------------\n",
            " 89% 1781857/2000000 [3:55:12<28:33, 127.34it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0943        |\n",
            "| elapsed time            | 04:14:48      |\n",
            "| episodes                | 5660          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00071835885 |\n",
            "| loss_margin             | 0.025129661   |\n",
            "| loss_n_td               | 0.0019858263  |\n",
            "| loss_td                 | 0.01729893    |\n",
            "| losses_all              | 0.0037361414  |\n",
            "| max 100 episode reward  | 6             |\n",
            "| mean 100 episode reward | 1.42          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1781861       |\n",
            "-------------------------------------------\n",
            " 89% 1783961/2000000 [3:55:30<27:33, 130.67it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0943        |\n",
            "| elapsed time            | 04:15:05      |\n",
            "| episodes                | 5670          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00071740727 |\n",
            "| loss_margin             | 0.016534489   |\n",
            "| loss_n_td               | 0.020555224   |\n",
            "| loss_td                 | 0.0031156694  |\n",
            "| losses_all              | 0.0031926155  |\n",
            "| max 100 episode reward  | 4             |\n",
            "| mean 100 episode reward | 1.31          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1783975       |\n",
            "-------------------------------------------\n",
            " 89% 1786456/2000000 [3:55:50<26:40, 133.46it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0943       |\n",
            "| elapsed time            | 04:15:25     |\n",
            "| episodes                | 5680         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007133238 |\n",
            "| loss_margin             | 0.01383055   |\n",
            "| loss_n_td               | 0.0006537589 |\n",
            "| loss_td                 | 0.012982753  |\n",
            "| losses_all              | 0.002812685  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.39         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1786465      |\n",
            "------------------------------------------\n",
            " 89% 1788522/2000000 [3:56:06<26:59, 130.56it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.0943      |\n",
            "| elapsed time            | 04:15:42    |\n",
            "| episodes                | 5690        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.000727819 |\n",
            "| loss_margin             | 0.041678347 |\n",
            "| loss_n_td               | 0.009811884 |\n",
            "| loss_td                 | 0.004447637 |\n",
            "| losses_all              | 0.004322453 |\n",
            "| max 100 episode reward  | 5           |\n",
            "| mean 100 episode reward | 1.38        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1788531     |\n",
            "-----------------------------------------\n",
            " 90% 1790410/2000000 [3:56:22<26:01, 134.20it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0942        |\n",
            "| elapsed time            | 04:15:57      |\n",
            "| episodes                | 5700          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00071765814 |\n",
            "| loss_margin             | 0.038232673   |\n",
            "| loss_n_td               | 0.004159659   |\n",
            "| loss_td                 | 0.008921871   |\n",
            "| losses_all              | 0.0041654767  |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 1.32          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1790412       |\n",
            "-------------------------------------------\n",
            " 90% 1792669/2000000 [3:56:40<25:57, 133.15it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0942        |\n",
            "| elapsed time            | 04:16:16      |\n",
            "| episodes                | 5710          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00070308376 |\n",
            "| loss_margin             | 0.025222987   |\n",
            "| loss_n_td               | 0.011413735   |\n",
            "| loss_td                 | 0.018901374   |\n",
            "| losses_all              | 0.0044037     |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 1.31          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1792678       |\n",
            "-------------------------------------------\n",
            " 90% 1794720/2000000 [3:56:57<27:22, 124.94it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0942        |\n",
            "| elapsed time            | 04:16:33      |\n",
            "| episodes                | 5720          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00069591537 |\n",
            "| loss_margin             | 0.015386894   |\n",
            "| loss_n_td               | 0.0025161132  |\n",
            "| loss_td                 | 0.004817113   |\n",
            "| losses_all              | 0.0023397582  |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 1.28          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1794722       |\n",
            "-------------------------------------------\n",
            " 90% 1796694/2000000 [3:57:14<25:52, 130.99it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0942       |\n",
            "| elapsed time            | 04:16:49     |\n",
            "| episodes                | 5730         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007065294 |\n",
            "| loss_margin             | 5.055219e-05 |\n",
            "| loss_n_td               | 0.0028166885 |\n",
            "| loss_td                 | 0.014020517  |\n",
            "| losses_all              | 0.0022760804 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.29         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1796704      |\n",
            "------------------------------------------\n",
            " 90% 1798336/2000000 [3:57:27<25:09, 133.60it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0942       |\n",
            "| elapsed time            | 04:17:03     |\n",
            "| episodes                | 5740         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007013874 |\n",
            "| loss_margin             | 0.008995496  |\n",
            "| loss_n_td               | 0.0014422473 |\n",
            "| loss_td                 | 0.0054760645 |\n",
            "| losses_all              | 0.0019416056 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.26         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1798346      |\n",
            "------------------------------------------\n",
            " 90% 1799994/2000000 [3:57:41<26:49, 124.26it/s]saved checkpoint\n",
            " 90% 1800694/2000000 [3:57:47<25:34, 129.87it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0941       |\n",
            "| elapsed time            | 04:17:23     |\n",
            "| episodes                | 5750         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007163139 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.001735038  |\n",
            "| loss_td                 | 0.010923372  |\n",
            "| losses_all              | 0.002132269  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.29         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1800694      |\n",
            "------------------------------------------\n",
            " 90% 1802677/2000000 [3:58:03<24:58, 131.70it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0941        |\n",
            "| elapsed time            | 04:17:39      |\n",
            "| episodes                | 5760          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00071434025 |\n",
            "| loss_margin             | 0.03789924    |\n",
            "| loss_n_td               | 0.003469464   |\n",
            "| loss_td                 | 0.012806578   |\n",
            "| losses_all              | 0.0040993057  |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 1.29          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1802686       |\n",
            "-------------------------------------------\n",
            " 90% 1804409/2000000 [3:58:18<24:54, 130.88it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0941        |\n",
            "| elapsed time            | 04:17:54      |\n",
            "| episodes                | 5770          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00071286893 |\n",
            "| loss_margin             | 0.044541888   |\n",
            "| loss_n_td               | 0.034264117   |\n",
            "| loss_td                 | 0.016039183   |\n",
            "| losses_all              | 0.0059282095  |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 1.28          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1804414       |\n",
            "-------------------------------------------\n",
            " 90% 1806566/2000000 [3:58:35<24:46, 130.11it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0941       |\n",
            "| elapsed time            | 04:18:11     |\n",
            "| episodes                | 5780         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0011407487 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0061087045 |\n",
            "| loss_td                 | 0.037716556  |\n",
            "| losses_all              | 0.006757742  |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.29         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1806580      |\n",
            "------------------------------------------\n",
            " 90% 1808405/2000000 [3:58:51<24:39, 129.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0941       |\n",
            "| elapsed time            | 04:18:26     |\n",
            "| episodes                | 5790         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010781983 |\n",
            "| loss_margin             | 0.0817768    |\n",
            "| loss_n_td               | 0.010949814  |\n",
            "| loss_td                 | 0.031468127  |\n",
            "| losses_all              | 0.009331113  |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.22         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1808410      |\n",
            "------------------------------------------\n",
            " 90% 1809937/2000000 [3:59:04<23:48, 133.09it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0941       |\n",
            "| elapsed time            | 04:18:39     |\n",
            "| episodes                | 5800         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010343966 |\n",
            "| loss_margin             | 0.02768435   |\n",
            "| loss_n_td               | 0.029929938  |\n",
            "| loss_td                 | 0.026929706  |\n",
            "| losses_all              | 0.0068677086 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.18         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1809940      |\n",
            "------------------------------------------\n",
            " 91% 1812084/2000000 [3:59:21<23:03, 135.82it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.094       |\n",
            "| elapsed time            | 04:18:57    |\n",
            "| episodes                | 5810        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.000990826 |\n",
            "| loss_margin             | 0.04164747  |\n",
            "| loss_n_td               | 0.012553473 |\n",
            "| loss_td                 | 0.0391787   |\n",
            "| losses_all              | 0.007012832 |\n",
            "| max 100 episode reward  | 7           |\n",
            "| mean 100 episode reward | 1.09        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1812097     |\n",
            "-----------------------------------------\n",
            " 91% 1814635/2000000 [3:59:42<23:09, 133.41it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.094         |\n",
            "| elapsed time            | 04:19:17      |\n",
            "| episodes                | 5820          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0009401994  |\n",
            "| loss_margin             | 0.00052282587 |\n",
            "| loss_n_td               | 0.0038288496  |\n",
            "| loss_td                 | 0.001888194   |\n",
            "| losses_all              | 0.0014274041  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.08          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1814646       |\n",
            "-------------------------------------------\n",
            " 91% 1817502/2000000 [4:00:05<23:03, 131.91it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.094        |\n",
            "| elapsed time            | 04:19:40     |\n",
            "| episodes                | 5830         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0008905828 |\n",
            "| loss_margin             | 0.024993185  |\n",
            "| loss_n_td               | 0.002163046  |\n",
            "| loss_td                 | 0.023742514  |\n",
            "| losses_all              | 0.0042556226 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.05         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1817514      |\n",
            "------------------------------------------\n",
            " 91% 1820460/2000000 [4:00:28<22:04, 135.53it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.094         |\n",
            "| elapsed time            | 04:20:04      |\n",
            "| episodes                | 5840          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00085202034 |\n",
            "| loss_margin             | 0.010490928   |\n",
            "| loss_n_td               | 0.001719862   |\n",
            "| loss_td                 | 0.017993256   |\n",
            "| losses_all              | 0.0033839066  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.04          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1820464       |\n",
            "-------------------------------------------\n",
            " 91% 1823299/2000000 [4:00:51<22:17, 132.09it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0939        |\n",
            "| elapsed time            | 04:20:27      |\n",
            "| episodes                | 5850          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00080929435 |\n",
            "| loss_margin             | 0.0029945672  |\n",
            "| loss_n_td               | 0.030263066   |\n",
            "| loss_td                 | 0.020484416   |\n",
            "| losses_all              | 0.003938965   |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1823307       |\n",
            "-------------------------------------------\n",
            " 91% 1826094/2000000 [4:01:13<22:27, 129.06it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0939        |\n",
            "| elapsed time            | 04:20:49      |\n",
            "| episodes                | 5860          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00077532843 |\n",
            "| loss_margin             | 0.05020642    |\n",
            "| loss_n_td               | 0.008086833   |\n",
            "| loss_td                 | 0.010007834   |\n",
            "| losses_all              | 0.004856987   |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 0.82          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1826107       |\n",
            "-------------------------------------------\n",
            " 91% 1828780/2000000 [4:01:35<21:08, 134.97it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0939       |\n",
            "| elapsed time            | 04:21:11     |\n",
            "| episodes                | 5870         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007466844 |\n",
            "| loss_margin             | 0.006609857  |\n",
            "| loss_n_td               | 0.002316851  |\n",
            "| loss_td                 | 0.0020212468 |\n",
            "| losses_all              | 0.0016167664 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 0.79         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1828781      |\n",
            "------------------------------------------\n",
            " 92% 1831932/2000000 [4:02:00<20:59, 133.43it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0939       |\n",
            "| elapsed time            | 04:21:36     |\n",
            "| episodes                | 5880         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007084099 |\n",
            "| loss_margin             | 0.023836706  |\n",
            "| loss_n_td               | 0.016124425  |\n",
            "| loss_td                 | 0.013407975  |\n",
            "| losses_all              | 0.004273449  |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 0.66         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1831934      |\n",
            "------------------------------------------\n",
            " 92% 1834732/2000000 [4:02:23<20:15, 136.00it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0938       |\n",
            "| elapsed time            | 04:21:59     |\n",
            "| episodes                | 5890         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006815116 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.010923866  |\n",
            "| loss_td                 | 0.011778459  |\n",
            "| losses_all              | 0.0023693875 |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 0.62         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1834732      |\n",
            "------------------------------------------\n",
            " 92% 1837405/2000000 [4:02:45<21:03, 128.73it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0938        |\n",
            "| elapsed time            | 04:22:21      |\n",
            "| episodes                | 5900          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00066014973 |\n",
            "| loss_margin             | 0.0034636222  |\n",
            "| loss_n_td               | 0.017276252   |\n",
            "| loss_td                 | 0.024741754   |\n",
            "| losses_all              | 0.0032762536  |\n",
            "| max 100 episode reward  | 4             |\n",
            "| mean 100 episode reward | 0.59          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1837413       |\n",
            "-------------------------------------------\n",
            " 92% 1840811/2000000 [4:03:12<20:05, 132.09it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0938       |\n",
            "| elapsed time            | 04:22:48     |\n",
            "| episodes                | 5910         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006378702 |\n",
            "| loss_margin             | 0.051022932  |\n",
            "| loss_n_td               | 0.011478941  |\n",
            "| loss_td                 | 0.025985094  |\n",
            "| losses_all              | 0.0056888694 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 0.88         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1840821      |\n",
            "------------------------------------------\n",
            " 92% 1843806/2000000 [4:03:37<20:00, 130.12it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0938       |\n",
            "| elapsed time            | 04:23:12     |\n",
            "| episodes                | 5920         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006286555 |\n",
            "| loss_margin             | 0.0024888068 |\n",
            "| loss_n_td               | 0.0026971088 |\n",
            "| loss_td                 | 0.048558526  |\n",
            "| losses_all              | 0.0042420537 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 0.81         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1843818      |\n",
            "------------------------------------------\n",
            " 92% 1846729/2000000 [4:04:00<19:37, 130.20it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0938       |\n",
            "| elapsed time            | 04:23:36     |\n",
            "| episodes                | 5930         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006125588 |\n",
            "| loss_margin             | 0.025400605  |\n",
            "| loss_n_td               | 0.0149979405 |\n",
            "| loss_td                 | 0.007966216  |\n",
            "| losses_all              | 0.0031665761 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 0.8          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1846742      |\n",
            "------------------------------------------\n",
            " 93% 1850074/2000000 [4:04:27<18:36, 134.23it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0938        |\n",
            "| elapsed time            | 04:24:02      |\n",
            "| episodes                | 5940          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00060089206 |\n",
            "| loss_margin             | 0.026896007   |\n",
            "| loss_n_td               | 0.0050022556  |\n",
            "| loss_td                 | 0.042175576   |\n",
            "| losses_all              | 0.004943067   |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 0.93          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1850085       |\n",
            "-------------------------------------------\n",
            " 93% 1853084/2000000 [4:04:51<18:17, 133.90it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0937       |\n",
            "| elapsed time            | 04:24:26     |\n",
            "| episodes                | 5950         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006042338 |\n",
            "| loss_margin             | 0.008714702  |\n",
            "| loss_n_td               | 0.007988403  |\n",
            "| loss_td                 | 0.009868426  |\n",
            "| losses_all              | 0.0029590433 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.05         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1853096      |\n",
            "------------------------------------------\n",
            " 93% 1856069/2000000 [4:05:15<18:09, 132.08it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0937       |\n",
            "| elapsed time            | 04:24:50     |\n",
            "| episodes                | 5960         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006027245 |\n",
            "| loss_margin             | 0.023836084  |\n",
            "| loss_n_td               | 0.0036265436 |\n",
            "| loss_td                 | 0.005142016  |\n",
            "| losses_all              | 0.0026957726 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.19         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1856084      |\n",
            "------------------------------------------\n",
            " 93% 1859208/2000000 [4:05:40<17:28, 134.33it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0937        |\n",
            "| elapsed time            | 04:25:15      |\n",
            "| episodes                | 5970          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00059855735 |\n",
            "| loss_margin             | 0.00045560673 |\n",
            "| loss_n_td               | 0.023531267   |\n",
            "| loss_td                 | 0.019723864   |\n",
            "| losses_all              | 0.0032015545  |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 1.37          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1859211       |\n",
            "-------------------------------------------\n",
            " 93% 1862089/2000000 [4:06:03<17:48, 129.08it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0937       |\n",
            "| elapsed time            | 04:25:38     |\n",
            "| episodes                | 5980         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0013326101 |\n",
            "| loss_margin             | 0.0135467425 |\n",
            "| loss_n_td               | 0.039555702  |\n",
            "| loss_td                 | 0.039782204  |\n",
            "| losses_all              | 0.006317296  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.36         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1862097      |\n",
            "------------------------------------------\n",
            " 93% 1864761/2000000 [4:06:24<17:13, 130.85it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0937       |\n",
            "| elapsed time            | 04:26:00     |\n",
            "| episodes                | 5990         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0011465173 |\n",
            "| loss_margin             | 0.00873208   |\n",
            "| loss_n_td               | 0.0017721944 |\n",
            "| loss_td                 | 0.005057894  |\n",
            "| losses_all              | 0.0024170456 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.39         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1864768      |\n",
            "------------------------------------------\n",
            " 93% 1868024/2000000 [4:06:50<16:44, 131.37it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0937       |\n",
            "| elapsed time            | 04:26:26     |\n",
            "| episodes                | 6000         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010096375 |\n",
            "| loss_margin             | 0.05963134   |\n",
            "| loss_n_td               | 0.0055761817 |\n",
            "| loss_td                 | 0.017546747  |\n",
            "| losses_all              | 0.006185014  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.47         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1868031      |\n",
            "------------------------------------------\n",
            " 94% 1870897/2000000 [4:07:13<16:22, 131.35it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0936       |\n",
            "| elapsed time            | 04:26:49     |\n",
            "| episodes                | 6010         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0009172405 |\n",
            "| loss_margin             | 0.020204632  |\n",
            "| loss_n_td               | 0.017612081  |\n",
            "| loss_td                 | 0.009323312  |\n",
            "| losses_all              | 0.0034621432 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.24         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1870898      |\n",
            "------------------------------------------\n",
            " 94% 1874201/2000000 [4:07:40<16:04, 130.38it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0936       |\n",
            "| elapsed time            | 04:27:16     |\n",
            "| episodes                | 6020         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.000836864  |\n",
            "| loss_margin             | 0.03293231   |\n",
            "| loss_n_td               | 0.004252211  |\n",
            "| loss_td                 | 0.0027287412 |\n",
            "| losses_all              | 0.003233049  |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.33         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1874209      |\n",
            "------------------------------------------\n",
            " 94% 1876610/2000000 [4:08:00<15:51, 129.65it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0936        |\n",
            "| elapsed time            | 04:27:36      |\n",
            "| episodes                | 6030          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00079106586 |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.010872328   |\n",
            "| loss_td                 | 0.0023392655  |\n",
            "| losses_all              | 0.0016051342  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.31          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1876620       |\n",
            "-------------------------------------------\n",
            " 94% 1879744/2000000 [4:08:25<14:54, 134.38it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0936       |\n",
            "| elapsed time            | 04:28:00     |\n",
            "| episodes                | 6040         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007447188 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.018435352  |\n",
            "| loss_td                 | 0.009036788  |\n",
            "| losses_all              | 0.002317417  |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.27         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1879750      |\n",
            "------------------------------------------\n",
            " 94% 1882669/2000000 [4:08:48<15:02, 130.01it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0936        |\n",
            "| elapsed time            | 04:28:24      |\n",
            "| episodes                | 6050          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00072051754 |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.017654942   |\n",
            "| loss_td                 | 0.0040144892  |\n",
            "| losses_all              | 0.002006785   |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.13          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1882681       |\n",
            "-------------------------------------------\n",
            " 94% 1885597/2000000 [4:09:12<14:29, 131.57it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0936        |\n",
            "| elapsed time            | 04:28:47      |\n",
            "| episodes                | 6060          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00068120786 |\n",
            "| loss_margin             | 0.017894294   |\n",
            "| loss_n_td               | 0.0042461185  |\n",
            "| loss_td                 | 0.0051107546  |\n",
            "| losses_all              | 0.002618136   |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.05          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1885603       |\n",
            "-------------------------------------------\n",
            " 94% 1888252/2000000 [4:09:33<13:48, 134.81it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0936       |\n",
            "| elapsed time            | 04:29:09     |\n",
            "| episodes                | 6070         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006553248 |\n",
            "| loss_margin             | 0.021110427  |\n",
            "| loss_n_td               | 0.0056937267 |\n",
            "| loss_td                 | 0.0050241603 |\n",
            "| losses_all              | 0.0025145458 |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 0.91         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1888253      |\n",
            "------------------------------------------\n",
            " 95% 1891090/2000000 [4:09:56<13:55, 130.42it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 04:29:32     |\n",
            "| episodes                | 6080         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006304055 |\n",
            "| loss_margin             | 0.021633612  |\n",
            "| loss_n_td               | 0.016506897  |\n",
            "| loss_td                 | 0.018719992  |\n",
            "| losses_all              | 0.0032145216 |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 0.93         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1891101      |\n",
            "------------------------------------------\n",
            " 95% 1894372/2000000 [4:10:22<13:10, 133.67it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 04:29:58     |\n",
            "| episodes                | 6090         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006107099 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0024108668 |\n",
            "| loss_td                 | 0.0046530897 |\n",
            "| losses_all              | 0.0014302074 |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 1.04         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1894384      |\n",
            "------------------------------------------\n",
            " 95% 1897476/2000000 [4:10:47<12:40, 134.83it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0935        |\n",
            "| elapsed time            | 04:30:23      |\n",
            "| episodes                | 6100          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00059055665 |\n",
            "| loss_margin             | 0.009586036   |\n",
            "| loss_n_td               | 0.012023969   |\n",
            "| loss_td                 | 0.015214303   |\n",
            "| losses_all              | 0.00260873    |\n",
            "| max 100 episode reward  | 4             |\n",
            "| mean 100 episode reward | 1.09          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1897485       |\n",
            "-------------------------------------------\n",
            " 95% 1899995/2000000 [4:11:08<12:31, 133.04it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 04:30:43     |\n",
            "| episodes                | 6110         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005751195 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010301508 |\n",
            "| loss_td                 | 0.0038667158 |\n",
            "| losses_all              | 0.0010597322 |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 1.08         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1899997      |\n",
            "------------------------------------------\n",
            "saved checkpoint\n",
            " 95% 1903270/2000000 [4:11:34<12:26, 129.60it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 04:31:10     |\n",
            "| episodes                | 6120         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005848688 |\n",
            "| loss_margin             | 0.01878214   |\n",
            "| loss_n_td               | 0.0057852245 |\n",
            "| loss_td                 | 0.01009411   |\n",
            "| losses_all              | 0.0030027241 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.14         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1903278      |\n",
            "------------------------------------------\n",
            " 95% 1907079/2000000 [4:12:04<11:35, 133.52it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 04:31:40     |\n",
            "| episodes                | 6130         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005775296 |\n",
            "| loss_margin             | 0.01266114   |\n",
            "| loss_n_td               | 0.0029069758 |\n",
            "| loss_td                 | 0.0030755512 |\n",
            "| losses_all              | 0.0019442979 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.23         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1907081      |\n",
            "------------------------------------------\n",
            " 95% 1909825/2000000 [4:12:27<12:14, 122.69it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 04:32:02     |\n",
            "| episodes                | 6140         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005729877 |\n",
            "| loss_margin             | 0.034293603  |\n",
            "| loss_n_td               | 0.015426958  |\n",
            "| loss_td                 | 0.011910766  |\n",
            "| losses_all              | 0.004262182  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.15         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1909833      |\n",
            "------------------------------------------\n",
            " 96% 1912489/2000000 [4:12:48<11:18, 128.93it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 04:32:24     |\n",
            "| episodes                | 6150         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0017794099 |\n",
            "| loss_margin             | 0.054547846  |\n",
            "| loss_n_td               | 0.10346318   |\n",
            "| loss_td                 | 0.259478     |\n",
            "| losses_all              | 0.05798052   |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.23         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1912489      |\n",
            "------------------------------------------\n",
            " 96% 1914684/2000000 [4:13:07<10:35, 134.34it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 04:32:42     |\n",
            "| episodes                | 6160         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0013282083 |\n",
            "| loss_margin             | 0.0005564131 |\n",
            "| loss_n_td               | 0.0032349885 |\n",
            "| loss_td                 | 0.01029402   |\n",
            "| losses_all              | 0.0038861523 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.24         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1914686      |\n",
            "------------------------------------------\n",
            " 96% 1917149/2000000 [4:13:27<10:30, 131.42it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 04:33:02     |\n",
            "| episodes                | 6170         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0011671081 |\n",
            "| loss_margin             | 0.052874364  |\n",
            "| loss_n_td               | 0.043663625  |\n",
            "| loss_td                 | 0.020294918  |\n",
            "| losses_all              | 0.006858358  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.26         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1917159      |\n",
            "------------------------------------------\n",
            " 96% 1919330/2000000 [4:13:44<10:16, 130.91it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 04:33:20     |\n",
            "| episodes                | 6180         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010809168 |\n",
            "| loss_margin             | 0.09466892   |\n",
            "| loss_n_td               | 0.03006658   |\n",
            "| loss_td                 | 0.020378198  |\n",
            "| losses_all              | 0.008061329  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.28         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1919330      |\n",
            "------------------------------------------\n",
            " 96% 1921662/2000000 [4:14:03<09:39, 135.21it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.0935      |\n",
            "| elapsed time            | 04:33:39    |\n",
            "| episodes                | 6190        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.00099824  |\n",
            "| loss_margin             | 0.031310372 |\n",
            "| loss_n_td               | 0.016565584 |\n",
            "| loss_td                 | 0.017687928 |\n",
            "| losses_all              | 0.004780751 |\n",
            "| max 100 episode reward  | 9           |\n",
            "| mean 100 episode reward | 1.19        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1921662     |\n",
            "-----------------------------------------\n",
            " 96% 1924574/2000000 [4:14:26<09:21, 134.27it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0934        |\n",
            "| elapsed time            | 04:34:02      |\n",
            "| episodes                | 6200          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00090997334 |\n",
            "| loss_margin             | 0.008659322   |\n",
            "| loss_n_td               | 0.0019142216  |\n",
            "| loss_td                 | 0.0038876664  |\n",
            "| losses_all              | 0.00207647    |\n",
            "| max 100 episode reward  | 9             |\n",
            "| mean 100 episode reward | 1.1           |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1924577       |\n",
            "-------------------------------------------\n",
            " 96% 1927250/2000000 [4:14:48<09:27, 128.09it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0934       |\n",
            "| elapsed time            | 04:34:24     |\n",
            "| episodes                | 6210         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0008463887 |\n",
            "| loss_margin             | 0.01722415   |\n",
            "| loss_n_td               | 0.009171268  |\n",
            "| loss_td                 | 0.010017956  |\n",
            "| losses_all              | 0.003280806  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.09         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1927256      |\n",
            "------------------------------------------\n",
            " 97% 1930933/2000000 [4:15:17<08:45, 131.44it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0934        |\n",
            "| elapsed time            | 04:34:53      |\n",
            "| episodes                | 6220          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00078438636 |\n",
            "| loss_margin             | 0.0029968359  |\n",
            "| loss_n_td               | 0.004240394   |\n",
            "| loss_td                 | 0.004224918   |\n",
            "| losses_all              | 0.001761321   |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 1.06          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1930939       |\n",
            "-------------------------------------------\n",
            " 97% 1934013/2000000 [4:15:42<08:25, 130.45it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0934        |\n",
            "| elapsed time            | 04:35:17      |\n",
            "| episodes                | 6230          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00073212927 |\n",
            "| loss_margin             | 0.06191867    |\n",
            "| loss_n_td               | 0.021125674   |\n",
            "| loss_td                 | 0.010344173   |\n",
            "| losses_all              | 0.00567648    |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 1.06          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1934024       |\n",
            "-------------------------------------------\n",
            " 97% 1937053/2000000 [4:16:06<08:07, 129.17it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0934       |\n",
            "| elapsed time            | 04:35:42     |\n",
            "| episodes                | 6240         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006941898 |\n",
            "| loss_margin             | 0.054654952  |\n",
            "| loss_n_td               | 0.002554795  |\n",
            "| loss_td                 | 0.013236038  |\n",
            "| losses_all              | 0.0045150905 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.1          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1937064      |\n",
            "------------------------------------------\n",
            " 97% 1940473/2000000 [4:16:33<07:32, 131.66it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0934       |\n",
            "| elapsed time            | 04:36:09     |\n",
            "| episodes                | 6250         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006678324 |\n",
            "| loss_margin             | 0.006547436  |\n",
            "| loss_n_td               | 0.005889867  |\n",
            "| loss_td                 | 0.009247568  |\n",
            "| losses_all              | 0.0022535126 |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 1.16         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1940479      |\n",
            "------------------------------------------\n",
            " 97% 1943873/2000000 [4:17:00<07:10, 130.26it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0934        |\n",
            "| elapsed time            | 04:36:36      |\n",
            "| episodes                | 6260          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00063942955 |\n",
            "| loss_margin             | 0.038359106   |\n",
            "| loss_n_td               | 0.039948817   |\n",
            "| loss_td                 | 0.013615966   |\n",
            "| losses_all              | 0.0053077675  |\n",
            "| max 100 episode reward  | 7             |\n",
            "| mean 100 episode reward | 1.31          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1943880       |\n",
            "-------------------------------------------\n",
            " 97% 1946920/2000000 [4:17:25<06:28, 136.48it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0933        |\n",
            "| elapsed time            | 04:37:00      |\n",
            "| episodes                | 6270          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00062083977 |\n",
            "| loss_margin             | 0.025056776   |\n",
            "| loss_n_td               | 0.007481741   |\n",
            "| loss_td                 | 0.009193882   |\n",
            "| losses_all              | 0.002689674   |\n",
            "| max 100 episode reward  | 11            |\n",
            "| mean 100 episode reward | 1.34          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1946933       |\n",
            "-------------------------------------------\n",
            " 98% 1950512/2000000 [4:17:54<06:05, 135.37it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0933       |\n",
            "| elapsed time            | 04:37:29     |\n",
            "| episodes                | 6280         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.000604895  |\n",
            "| loss_margin             | 0.02853489   |\n",
            "| loss_n_td               | 0.015673049  |\n",
            "| loss_td                 | 0.0062984726 |\n",
            "| losses_all              | 0.0032381106 |\n",
            "| max 100 episode reward  | 11           |\n",
            "| mean 100 episode reward | 1.4          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1950518      |\n",
            "------------------------------------------\n",
            " 98% 1954650/2000000 [4:18:27<05:44, 131.65it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0933       |\n",
            "| elapsed time            | 04:38:02     |\n",
            "| episodes                | 6290         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005767485 |\n",
            "| loss_margin             | 0.024817131  |\n",
            "| loss_n_td               | 0.01300477   |\n",
            "| loss_td                 | 0.012274069  |\n",
            "| losses_all              | 0.0029945457 |\n",
            "| max 100 episode reward  | 11           |\n",
            "| mean 100 episode reward | 1.6          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1954657      |\n",
            "------------------------------------------\n",
            " 98% 1958406/2000000 [4:18:56<05:16, 131.35it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0933        |\n",
            "| elapsed time            | 04:38:32      |\n",
            "| episodes                | 6300          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00056178396 |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.0052694157  |\n",
            "| loss_td                 | 0.005865584   |\n",
            "| losses_all              | 0.0014012302  |\n",
            "| max 100 episode reward  | 11            |\n",
            "| mean 100 episode reward | 1.72          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1958418       |\n",
            "-------------------------------------------\n",
            " 98% 1961644/2000000 [4:19:22<04:45, 134.49it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0933       |\n",
            "| elapsed time            | 04:38:58     |\n",
            "| episodes                | 6310         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005658959 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.007881314  |\n",
            "| losses_all              | 0.0013302217 |\n",
            "| max 100 episode reward  | 11           |\n",
            "| mean 100 episode reward | 1.83         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1961644      |\n",
            "------------------------------------------\n",
            " 98% 1964708/2000000 [4:19:47<04:19, 135.92it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0933        |\n",
            "| elapsed time            | 04:39:22      |\n",
            "| episodes                | 6320          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00056651246 |\n",
            "| loss_margin             | 0.03761879    |\n",
            "| loss_n_td               | 0.040953398   |\n",
            "| loss_td                 | 0.007030236   |\n",
            "| losses_all              | 0.0050147893  |\n",
            "| max 100 episode reward  | 11            |\n",
            "| mean 100 episode reward | 1.82          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1964714       |\n",
            "-------------------------------------------\n",
            " 98% 1967958/2000000 [4:20:12<04:05, 130.72it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0933       |\n",
            "| elapsed time            | 04:39:48     |\n",
            "| episodes                | 6330         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005686804 |\n",
            "| loss_margin             | 0.030373108  |\n",
            "| loss_n_td               | 0.01826493   |\n",
            "| loss_td                 | 0.0023354397 |\n",
            "| losses_all              | 0.0034025018 |\n",
            "| max 100 episode reward  | 11           |\n",
            "| mean 100 episode reward | 1.84         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1967961      |\n",
            "------------------------------------------\n",
            " 99% 1971360/2000000 [4:20:39<03:29, 136.81it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0933       |\n",
            "| elapsed time            | 04:40:15     |\n",
            "| episodes                | 6340         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0005675717 |\n",
            "| loss_margin             | 0.012999481  |\n",
            "| loss_n_td               | 0.011316169  |\n",
            "| loss_td                 | 0.004952144  |\n",
            "| losses_all              | 0.0023966625 |\n",
            "| max 100 episode reward  | 11           |\n",
            "| mean 100 episode reward | 1.9          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1971363      |\n",
            "------------------------------------------\n",
            " 99% 1974696/2000000 [4:21:06<03:10, 132.96it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0933        |\n",
            "| elapsed time            | 04:40:42      |\n",
            "| episodes                | 6350          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00057028484 |\n",
            "| loss_margin             | 0.0015311241  |\n",
            "| loss_n_td               | 0.022748616   |\n",
            "| loss_td                 | 0.007042782   |\n",
            "| losses_all              | 0.00226773    |\n",
            "| max 100 episode reward  | 11            |\n",
            "| mean 100 episode reward | 1.92          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1974705       |\n",
            "-------------------------------------------\n",
            " 99% 1977256/2000000 [4:21:27<02:46, 136.25it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0933       |\n",
            "| elapsed time            | 04:41:02     |\n",
            "| episodes                | 6360         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0013135774 |\n",
            "| loss_margin             | 0.02801324   |\n",
            "| loss_n_td               | 0.006509085  |\n",
            "| loss_td                 | 0.0136225745 |\n",
            "| losses_all              | 0.0038256543 |\n",
            "| max 100 episode reward  | 11           |\n",
            "| mean 100 episode reward | 1.75         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1977259      |\n",
            "------------------------------------------\n",
            " 99% 1979817/2000000 [4:21:47<02:36, 129.00it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0933        |\n",
            "| elapsed time            | 04:41:23      |\n",
            "| episodes                | 6370          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0011631694  |\n",
            "| loss_margin             | 0.00094295293 |\n",
            "| loss_n_td               | 5.1825875e-05 |\n",
            "| loss_td                 | 0.0073027587  |\n",
            "| losses_all              | 0.0023087533  |\n",
            "| max 100 episode reward  | 6             |\n",
            "| mean 100 episode reward | 1.68          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1979831       |\n",
            "-------------------------------------------\n",
            " 99% 1982190/2000000 [4:22:06<02:16, 130.53it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0932       |\n",
            "| elapsed time            | 04:41:42     |\n",
            "| episodes                | 6380         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0010340544 |\n",
            "| loss_margin             | 0.03498052   |\n",
            "| loss_n_td               | 0.033620268  |\n",
            "| loss_td                 | 0.011762663  |\n",
            "| losses_all              | 0.0045866836 |\n",
            "| max 100 episode reward  | 6            |\n",
            "| mean 100 episode reward | 1.63         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1982198      |\n",
            "------------------------------------------\n",
            " 99% 1985138/2000000 [4:22:30<01:51, 133.21it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0932       |\n",
            "| elapsed time            | 04:42:06     |\n",
            "| episodes                | 6390         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0009402952 |\n",
            "| loss_margin             | 0.033532154  |\n",
            "| loss_n_td               | 0.004942105  |\n",
            "| loss_td                 | 0.010248356  |\n",
            "| losses_all              | 0.0038644888 |\n",
            "| max 100 episode reward  | 6            |\n",
            "| mean 100 episode reward | 1.44         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1985138      |\n",
            "------------------------------------------\n",
            " 99% 1988229/2000000 [4:22:55<01:38, 119.42it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0932       |\n",
            "| elapsed time            | 04:42:31     |\n",
            "| episodes                | 6400         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0008684678 |\n",
            "| loss_margin             | 0.061548255  |\n",
            "| loss_n_td               | 0.029587483  |\n",
            "| loss_td                 | 0.014266282  |\n",
            "| losses_all              | 0.0055440096 |\n",
            "| max 100 episode reward  | 6            |\n",
            "| mean 100 episode reward | 1.36         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1988241      |\n",
            "------------------------------------------\n",
            "100% 1991107/2000000 [4:23:19<01:08, 130.10it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0932       |\n",
            "| elapsed time            | 04:42:54     |\n",
            "| episodes                | 6410         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0008141855 |\n",
            "| loss_margin             | 0.034064826  |\n",
            "| loss_n_td               | 0.016157256  |\n",
            "| loss_td                 | 0.013932452  |\n",
            "| losses_all              | 0.0039233733 |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.29         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1991120      |\n",
            "------------------------------------------\n",
            "100% 1994829/2000000 [4:23:48<00:39, 129.44it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0932       |\n",
            "| elapsed time            | 04:43:24     |\n",
            "| episodes                | 6420         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0007436164 |\n",
            "| loss_margin             | 0.09259284   |\n",
            "| loss_n_td               | 0.029592969  |\n",
            "| loss_td                 | 0.01497789   |\n",
            "| losses_all              | 0.007276695  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.41         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1994838      |\n",
            "------------------------------------------\n",
            "100% 1998025/2000000 [4:24:14<00:14, 135.27it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0932       |\n",
            "| elapsed time            | 04:43:49     |\n",
            "| episodes                | 6430         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0006925734 |\n",
            "| loss_margin             | 0.049388148  |\n",
            "| loss_n_td               | 0.040398777  |\n",
            "| loss_td                 | 0.04286731   |\n",
            "| losses_all              | 0.0069713145 |\n",
            "| max 100 episode reward  | 10           |\n",
            "| mean 100 episode reward | 1.49         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1998030      |\n",
            "------------------------------------------\n",
            "100% 2000000/2000000 [4:24:30<00:00, 126.02it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u3ghxyr50fh",
        "colab_type": "code",
        "outputId": "ead79d37-cfc8-4761-e9a9-e79c1e703f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "!git status "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch master\n",
            "Your branch is up to date with 'origin/master'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
            "\n",
            "\t\u001b[31mmodified:   dqfd.py\u001b[m\n",
            "\t\u001b[31mmodified:   run_atari.py\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_9L_dwWbBoZ",
        "colab_type": "code",
        "outputId": "47f83db8-ff9c-4969-aa84-2f39485f5209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!git add . \n",
        "!git commit -m \"fix save video bug\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master b583877] fix save video bug\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A2hNQE_bMcN",
        "colab_type": "code",
        "outputId": "c14feaa6-d0d3-493c-b6a4-16d7c337fa5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "!git push"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 3, done.\n",
            "Delta compression using up to 4 threads.\n",
            "Compressing objects:  33% (1/3)   \rCompressing objects:  66% (2/3)   \rCompressing objects: 100% (3/3)   \rCompressing objects: 100% (3/3), done.\n",
            "Writing objects:  33% (1/3)   \rWriting objects:  66% (2/3)   \rWriting objects: 100% (3/3)   \rWriting objects: 100% (3/3), 304 bytes | 304.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/Kokkini/DQfD.git\n",
            "   f2ec658..b583877  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAZjuQCVbN-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}