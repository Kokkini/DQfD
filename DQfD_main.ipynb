{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQfD_main.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/Kokkini/DQfD/blob/master/DQfD_main.ipynb",
      "authorship_tag": "ABX9TyPgIk3l6ZqNkRe6EwXjVof6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kokkini/DQfD/blob/master/DQfD_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLKIVoRu16Fy",
        "colab_type": "code",
        "outputId": "61bff373-6c2c-4897-d339-8ba975ab53cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "# !pip install stable-baselines[mpi]==2.10.0\n",
        "!pip install gym\n",
        "!pip install pynput"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Collecting pynput\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/0a/ea13c055a90b1aff5945e7eb330584f15e5282aead15a8f3cdb977a1534e/pynput-1.6.8-py2.py3-none-any.whl (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 2.4MB/s \n",
            "\u001b[?25hCollecting python-xlib>=0.17; \"linux\" in sys_platform\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/10/2eb938852a9bdf6745808f141c9fede76b1bd5a9530859bacc71985d29d9/python_xlib-0.27-py2.py3-none-any.whl (174kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pynput) (1.12.0)\n",
            "Installing collected packages: python-xlib, pynput\n",
            "Successfully installed pynput-1.6.8 python-xlib-0.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99IlmkkQ7mcr",
        "colab_type": "code",
        "outputId": "28185000-4cfe-47f2-9439-edf49d15ac55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7VAg5r42H9q",
        "colab_type": "code",
        "outputId": "d4775f2f-920e-40e5-d002-62351c11c136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "from getpass import getpass\n",
        "\n",
        "def clone_with_token(repo_name, owner_name=\"Kokkini\", user_email=\"trannhatquang1104@gmail.com\", user_name=\"Kokkini\"):\n",
        "  GIT_TOKEN = getpass('insert token: ')\n",
        "  GIT_PATH = f\"https://{GIT_TOKEN}@github.com/{owner_name}/{repo_name}.git\"\n",
        "  !git config --global user.email \"{user_email}\"\n",
        "  !git config --global user.name \"{user_name}\"\n",
        "  !git clone \"{GIT_PATH}\"\n",
        "  GIT_TOKEN, GIT_PATH = \"\", \"\"\n",
        "clone_with_token(\"DQfD\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "insert token: ··········\n",
            "Cloning into 'DQfD'...\n",
            "remote: Enumerating objects: 229, done.\u001b[K\n",
            "remote: Counting objects: 100% (229/229), done.\u001b[K\n",
            "remote: Compressing objects: 100% (189/189), done.\u001b[K\n",
            "remote: Total 229 (delta 134), reused 86 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (229/229), 202.52 KiB | 515.00 KiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tBPFxBF55tf",
        "colab_type": "code",
        "outputId": "ccdd80bb-440b-4874-e267-1e35b92d29c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd DQfD/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DQfD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1mT261H2VMr",
        "colab_type": "code",
        "outputId": "f8c10e4a-31c0-49f8-cc8b-f3df9a892e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_atari.py --pre_train_timesteps=1e5 --num_timesteps=2e6 --save_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/models11\" --load_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/models11\" --demo_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/human.BreakoutNoFrameskip-v4.pkl\" --log_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/logs11\" "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0029926342 |\n",
            "| loss_margin             | 0.0019264296 |\n",
            "| loss_n_td               | 0.0006215902 |\n",
            "| loss_td                 | 0.0042505334 |\n",
            "| losses_all              | 0.004187087  |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 29           |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1824748      |\n",
            "------------------------------------------\n",
            " 46% 1832038/4000000 [8:57:16<9:35:58, 62.73it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 09:13:30     |\n",
            "| episodes                | 2160         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030031851 |\n",
            "| loss_margin             | 0.019884344  |\n",
            "| loss_n_td               | 0.0063885264 |\n",
            "| loss_td                 | 0.034497358  |\n",
            "| losses_all              | 0.009458492  |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 27.1         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1832044      |\n",
            "------------------------------------------\n",
            " 46% 1838316/4000000 [8:59:08<9:49:22, 61.13it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 09:15:22     |\n",
            "| episodes                | 2170         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003007457  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0019092975 |\n",
            "| loss_td                 | 0.012779002  |\n",
            "| losses_all              | 0.005690128  |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 26.9         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1838322      |\n",
            "------------------------------------------\n",
            " 46% 1844513/4000000 [9:00:58<9:33:34, 62.63it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.1           |\n",
            "| elapsed time            | 09:17:12      |\n",
            "| episodes                | 2180          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030201592  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 4.8577564e-05 |\n",
            "| loss_td                 | 0.0063238656  |\n",
            "| losses_all              | 0.0043643964  |\n",
            "| max 100 episode reward  | 354           |\n",
            "| mean 100 episode reward | 24.6          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1844519       |\n",
            "-------------------------------------------\n",
            " 46% 1849806/4000000 [9:02:35<9:36:38, 62.15it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.1          |\n",
            "| elapsed time            | 09:18:49     |\n",
            "| episodes                | 2190         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030231636 |\n",
            "| loss_margin             | 0.001823023  |\n",
            "| loss_n_td               | 0.0029422804 |\n",
            "| loss_td                 | 0.008230205  |\n",
            "| losses_all              | 0.0052174106 |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 24.6         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1849807      |\n",
            "------------------------------------------\n",
            " 46% 1857347/4000000 [9:04:48<9:41:23, 61.42it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.1           |\n",
            "| elapsed time            | 09:21:02      |\n",
            "| episodes                | 2200          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030235045  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00019419003 |\n",
            "| loss_td                 | 0.013983596   |\n",
            "| losses_all              | 0.0054903785  |\n",
            "| max 100 episode reward  | 354           |\n",
            "| mean 100 episode reward | 27.8          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1857351       |\n",
            "-------------------------------------------\n",
            " 47% 1863667/4000000 [9:06:41<10:17:14, 57.68it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.1           |\n",
            "| elapsed time            | 09:22:55      |\n",
            "| episodes                | 2210          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030364816  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 5.2428648e-05 |\n",
            "| loss_td                 | 0.020711273   |\n",
            "| losses_all              | 0.0063630333  |\n",
            "| max 100 episode reward  | 354           |\n",
            "| mean 100 episode reward | 29.2          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1863667       |\n",
            "-------------------------------------------\n",
            " 47% 1870415/4000000 [9:08:41<9:34:52, 61.74it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0999        |\n",
            "| elapsed time            | 09:24:55      |\n",
            "| episodes                | 2220          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030387393  |\n",
            "| loss_margin             | 0.0002894327  |\n",
            "| loss_n_td               | 1.2843528e-06 |\n",
            "| loss_td                 | 0.0052722306  |\n",
            "| losses_all              | 0.0042108623  |\n",
            "| max 100 episode reward  | 262           |\n",
            "| mean 100 episode reward | 27.4          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1870417       |\n",
            "-------------------------------------------\n",
            " 47% 1877551/4000000 [9:10:47<9:32:34, 61.78it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0997       |\n",
            "| elapsed time            | 09:27:01     |\n",
            "| episodes                | 2230         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030487913 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.001601205  |\n",
            "| loss_td                 | 0.016797997  |\n",
            "| losses_all              | 0.0070496583 |\n",
            "| max 100 episode reward  | 262          |\n",
            "| mean 100 episode reward | 25.3         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1877556      |\n",
            "------------------------------------------\n",
            " 47% 1883709/4000000 [9:12:39<9:27:46, 62.12it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0996       |\n",
            "| elapsed time            | 09:28:53     |\n",
            "| episodes                | 2240         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003063604  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0001050327 |\n",
            "| loss_td                 | 0.007009335  |\n",
            "| losses_all              | 0.004491983  |\n",
            "| max 100 episode reward  | 262          |\n",
            "| mean 100 episode reward | 26.5         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1883710      |\n",
            "------------------------------------------\n",
            " 47% 1890075/4000000 [9:14:33<9:23:58, 62.35it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0995        |\n",
            "| elapsed time            | 09:30:47      |\n",
            "| episodes                | 2250          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003072304   |\n",
            "| loss_margin             | 0.00370159    |\n",
            "| loss_n_td               | 6.0103062e-05 |\n",
            "| loss_td                 | 0.024538666   |\n",
            "| losses_all              | 0.0074126394  |\n",
            "| max 100 episode reward  | 262           |\n",
            "| mean 100 episode reward | 28.4          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1890075       |\n",
            "-------------------------------------------\n",
            " 47% 1898586/4000000 [9:17:02<10:20:18, 56.46it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0993       |\n",
            "| elapsed time            | 09:33:16     |\n",
            "| episodes                | 2260         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030759037 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0007104104 |\n",
            "| loss_td                 | 0.056888465  |\n",
            "| losses_all              | 0.011789292  |\n",
            "| max 100 episode reward  | 262          |\n",
            "| mean 100 episode reward | 29.1         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1898590      |\n",
            "------------------------------------------\n",
            " 47% 1899995/4000000 [9:17:29<9:31:13, 61.27it/s]saved checkpoint\n",
            " 48% 1905244/4000000 [9:19:02<9:21:19, 62.20it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0992        |\n",
            "| elapsed time            | 09:35:16      |\n",
            "| episodes                | 2270          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030842412  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 6.0941595e-05 |\n",
            "| loss_td                 | 0.017979523   |\n",
            "| losses_all              | 0.0085071735  |\n",
            "| max 100 episode reward  | 262           |\n",
            "| mean 100 episode reward | 30.2          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1905247       |\n",
            "-------------------------------------------\n",
            " 48% 1913645/4000000 [9:21:29<9:12:50, 62.90it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.099        |\n",
            "| elapsed time            | 09:37:43     |\n",
            "| episodes                | 2280         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003090576  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0014017937 |\n",
            "| loss_td                 | 0.011122009  |\n",
            "| losses_all              | 0.0049308175 |\n",
            "| max 100 episode reward  | 262          |\n",
            "| mean 100 episode reward | 32.6         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1913645      |\n",
            "------------------------------------------\n",
            " 48% 1919118/4000000 [9:23:08<9:25:33, 61.32it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0989       |\n",
            "| elapsed time            | 09:39:22     |\n",
            "| episodes                | 2290         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030894156 |\n",
            "| loss_margin             | 0.0014335215 |\n",
            "| loss_n_td               | 0.0021746538 |\n",
            "| loss_td                 | 0.013081908  |\n",
            "| losses_all              | 0.0062963404 |\n",
            "| max 100 episode reward  | 262          |\n",
            "| mean 100 episode reward | 32.3         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1919123      |\n",
            "------------------------------------------\n",
            " 48% 1926104/4000000 [9:25:12<9:13:06, 62.49it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0987       |\n",
            "| elapsed time            | 09:41:26     |\n",
            "| episodes                | 2300         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003088565  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0013208042 |\n",
            "| loss_td                 | 0.005910103  |\n",
            "| losses_all              | 0.0044403854 |\n",
            "| max 100 episode reward  | 213          |\n",
            "| mean 100 episode reward | 29.2         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1926109      |\n",
            "------------------------------------------\n",
            " 48% 1937908/4000000 [9:28:33<9:32:31, 60.03it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0985        |\n",
            "| elapsed time            | 09:44:47      |\n",
            "| episodes                | 2310          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030966217  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00041199324 |\n",
            "| loss_td                 | 0.010573891   |\n",
            "| losses_all              | 0.005360985   |\n",
            "| max 100 episode reward  | 213           |\n",
            "| mean 100 episode reward | 28.1          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1937911       |\n",
            "-------------------------------------------\n",
            " 49% 1946441/4000000 [9:31:03<9:03:57, 62.92it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0983       |\n",
            "| elapsed time            | 09:47:17     |\n",
            "| episodes                | 2320         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030918457 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010735836 |\n",
            "| loss_td                 | 0.0020578997 |\n",
            "| losses_all              | 0.0038124123 |\n",
            "| max 100 episode reward  | 197          |\n",
            "| mean 100 episode reward | 27           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1946442      |\n",
            "------------------------------------------\n",
            " 49% 1954010/4000000 [9:33:16<9:14:20, 61.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0982       |\n",
            "| elapsed time            | 09:49:30     |\n",
            "| episodes                | 2330         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030958578 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.013021806  |\n",
            "| losses_all              | 0.005197935  |\n",
            "| max 100 episode reward  | 197          |\n",
            "| mean 100 episode reward | 27.7         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1954014      |\n",
            "------------------------------------------\n",
            " 49% 1963924/4000000 [9:36:09<9:18:59, 60.71it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.098         |\n",
            "| elapsed time            | 09:52:23      |\n",
            "| episodes                | 2340          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.00309705    |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 5.8926093e-05 |\n",
            "| loss_td                 | 0.009039399   |\n",
            "| losses_all              | 0.00600323    |\n",
            "| max 100 episode reward  | 197           |\n",
            "| mean 100 episode reward | 27            |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1963925       |\n",
            "-------------------------------------------\n",
            " 49% 1971801/4000000 [9:38:30<9:07:35, 61.73it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0979        |\n",
            "| elapsed time            | 09:54:44      |\n",
            "| episodes                | 2350          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030972508  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00014790815 |\n",
            "| loss_td                 | 0.06255467    |\n",
            "| losses_all              | 0.009529093   |\n",
            "| max 100 episode reward  | 197           |\n",
            "| mean 100 episode reward | 26.3          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1971801       |\n",
            "-------------------------------------------\n",
            " 50% 1981222/4000000 [9:41:12<8:58:41, 62.46it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0977       |\n",
            "| elapsed time            | 09:57:26     |\n",
            "| episodes                | 2360         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003097405  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 6.714407e-05 |\n",
            "| loss_td                 | 0.006696048  |\n",
            "| losses_all              | 0.004481127  |\n",
            "| max 100 episode reward  | 197          |\n",
            "| mean 100 episode reward | 24.8         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1981228      |\n",
            "------------------------------------------\n",
            " 50% 1987848/4000000 [9:43:10<9:17:04, 60.20it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0976       |\n",
            "| elapsed time            | 09:59:24     |\n",
            "| episodes                | 2370         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030924114 |\n",
            "| loss_margin             | 0.013378017  |\n",
            "| loss_n_td               | 0.000939952  |\n",
            "| loss_td                 | 0.009992141  |\n",
            "| losses_all              | 0.005971271  |\n",
            "| max 100 episode reward  | 197          |\n",
            "| mean 100 episode reward | 23.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1987853      |\n",
            "------------------------------------------\n",
            " 50% 1993889/4000000 [9:44:58<8:52:15, 62.82it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0975       |\n",
            "| elapsed time            | 10:01:12     |\n",
            "| episodes                | 2380         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030951174 |\n",
            "| loss_margin             | 0.0022953972 |\n",
            "| loss_n_td               | 0.0008394491 |\n",
            "| loss_td                 | 0.07489448   |\n",
            "| losses_all              | 0.013206258  |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 20.8         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1993890      |\n",
            "------------------------------------------\n",
            " 50% 1999997/4000000 [9:46:42<8:45:11, 63.47it/s]saved checkpoint\n",
            " 50% 2002485/4000000 [9:47:27<8:47:45, 63.08it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0973       |\n",
            "| elapsed time            | 10:03:41     |\n",
            "| episodes                | 2390         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030976897 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.04731592   |\n",
            "| losses_all              | 0.011587812  |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 21.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2002490      |\n",
            "------------------------------------------\n",
            " 50% 2009765/4000000 [9:49:36<8:51:12, 62.44it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0972       |\n",
            "| elapsed time            | 10:05:49     |\n",
            "| episodes                | 2400         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003094157  |\n",
            "| loss_margin             | 0.02490095   |\n",
            "| loss_n_td               | 0.0073870323 |\n",
            "| loss_td                 | 0.029814541  |\n",
            "| losses_all              | 0.009204207  |\n",
            "| max 100 episode reward  | 213          |\n",
            "| mean 100 episode reward | 23.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2009768      |\n",
            "------------------------------------------\n",
            " 50% 2017498/4000000 [9:51:50<8:56:08, 61.63it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.097         |\n",
            "| elapsed time            | 10:08:04      |\n",
            "| episodes                | 2410          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031003137  |\n",
            "| loss_margin             | 0.0017489493  |\n",
            "| loss_n_td               | 0.00016017785 |\n",
            "| loss_td                 | 0.02001704    |\n",
            "| losses_all              | 0.005300157   |\n",
            "| max 100 episode reward  | 213           |\n",
            "| mean 100 episode reward | 24            |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2017503       |\n",
            "-------------------------------------------\n",
            " 51% 2023096/4000000 [9:53:32<8:50:55, 62.06it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.097        |\n",
            "| elapsed time            | 10:09:46     |\n",
            "| episodes                | 2420         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031103082 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.00599168   |\n",
            "| losses_all              | 0.004526795  |\n",
            "| max 100 episode reward  | 213          |\n",
            "| mean 100 episode reward | 23.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2023098      |\n",
            "------------------------------------------\n",
            " 51% 2030121/4000000 [9:55:36<8:35:23, 63.70it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0968       |\n",
            "| elapsed time            | 10:11:50     |\n",
            "| episodes                | 2430         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031073538 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 3.404475e-05 |\n",
            "| loss_td                 | 0.03293052   |\n",
            "| losses_all              | 0.0077779796 |\n",
            "| max 100 episode reward  | 213          |\n",
            "| mean 100 episode reward | 23.8         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2030121      |\n",
            "------------------------------------------\n",
            " 51% 2039326/4000000 [9:58:14<8:36:14, 63.30it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0967        |\n",
            "| elapsed time            | 10:14:28      |\n",
            "| episodes                | 2440          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031063294  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00031758787 |\n",
            "| loss_td                 | 0.0047901412  |\n",
            "| losses_all              | 0.004030861   |\n",
            "| max 100 episode reward  | 213           |\n",
            "| mean 100 episode reward | 24.9          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2039331       |\n",
            "-------------------------------------------\n",
            " 51% 2046179/4000000 [10:00:16<9:03:35, 59.90it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0966       |\n",
            "| elapsed time            | 10:16:30     |\n",
            "| episodes                | 2450         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031096942 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0031960248 |\n",
            "| loss_td                 | 0.0070452983 |\n",
            "| losses_all              | 0.0048024403 |\n",
            "| max 100 episode reward  | 213          |\n",
            "| mean 100 episode reward | 23.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2046182      |\n",
            "------------------------------------------\n",
            " 51% 2054193/4000000 [10:02:35<8:38:59, 62.49it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0964       |\n",
            "| elapsed time            | 10:18:49     |\n",
            "| episodes                | 2460         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030989063 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.11608701   |\n",
            "| losses_all              | 0.0182723    |\n",
            "| max 100 episode reward  | 213          |\n",
            "| mean 100 episode reward | 24.8         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2054196      |\n",
            "------------------------------------------\n",
            " 52% 2061624/4000000 [10:04:45<8:26:36, 63.77it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0963        |\n",
            "| elapsed time            | 10:20:59      |\n",
            "| episodes                | 2470          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.00309549    |\n",
            "| loss_margin             | 0.0022701994  |\n",
            "| loss_n_td               | 0.00066961447 |\n",
            "| loss_td                 | 0.0085572945  |\n",
            "| losses_all              | 0.006496792   |\n",
            "| max 100 episode reward  | 213           |\n",
            "| mean 100 episode reward | 25.8          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2061629       |\n",
            "-------------------------------------------\n",
            " 52% 2068261/4000000 [10:06:42<8:38:31, 62.09it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0962       |\n",
            "| elapsed time            | 10:22:56     |\n",
            "| episodes                | 2480         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030855334 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.015276121  |\n",
            "| losses_all              | 0.005251636  |\n",
            "| max 100 episode reward  | 213          |\n",
            "| mean 100 episode reward | 27.2         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2068261      |\n",
            "------------------------------------------\n",
            " 52% 2075860/4000000 [10:08:54<8:23:33, 63.69it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0961       |\n",
            "| elapsed time            | 10:25:08     |\n",
            "| episodes                | 2490         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030838905 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0012731791 |\n",
            "| loss_td                 | 0.00902391   |\n",
            "| losses_all              | 0.0049062595 |\n",
            "| max 100 episode reward  | 239          |\n",
            "| mean 100 episode reward | 29.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2075865      |\n",
            "------------------------------------------\n",
            " 52% 2083356/4000000 [10:11:04<8:33:00, 62.27it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0959        |\n",
            "| elapsed time            | 10:27:18      |\n",
            "| episodes                | 2500          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003089467   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 5.0032446e-05 |\n",
            "| loss_td                 | 0.0042981873  |\n",
            "| losses_all              | 0.004187849   |\n",
            "| max 100 episode reward  | 239           |\n",
            "| mean 100 episode reward | 27.8          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2083361       |\n",
            "-------------------------------------------\n",
            " 52% 2090156/4000000 [10:13:03<8:24:39, 63.07it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0958       |\n",
            "| elapsed time            | 10:29:17     |\n",
            "| episodes                | 2510         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030903844 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.00250624   |\n",
            "| loss_td                 | 0.012611881  |\n",
            "| losses_all              | 0.0058276076 |\n",
            "| max 100 episode reward  | 369          |\n",
            "| mean 100 episode reward | 30.9         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2090160      |\n",
            "------------------------------------------\n",
            " 52% 2098254/4000000 [10:15:23<8:21:03, 63.26it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0957       |\n",
            "| elapsed time            | 10:31:37     |\n",
            "| episodes                | 2520         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030941237 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0015049402 |\n",
            "| loss_td                 | 0.01676622   |\n",
            "| losses_all              | 0.0058737234 |\n",
            "| max 100 episode reward  | 369          |\n",
            "| mean 100 episode reward | 31.3         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2098260      |\n",
            "------------------------------------------\n",
            " 52% 2099994/4000000 [10:15:53<8:35:24, 61.44it/s]saved checkpoint\n",
            " 53% 2104526/4000000 [10:17:13<8:22:47, 62.83it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0956        |\n",
            "| elapsed time            | 10:33:27      |\n",
            "| episodes                | 2530          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003109764   |\n",
            "| loss_margin             | 0.00019992143 |\n",
            "| loss_n_td               | 0.0020231367  |\n",
            "| loss_td                 | 0.0056385407  |\n",
            "| losses_all              | 0.0043800483  |\n",
            "| max 100 episode reward  | 369           |\n",
            "| mean 100 episode reward | 30.5          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2104530       |\n",
            "-------------------------------------------\n",
            " 53% 2113394/4000000 [10:19:45<8:22:58, 62.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0955       |\n",
            "| elapsed time            | 10:35:59     |\n",
            "| episodes                | 2540         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003112656  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0008507943 |\n",
            "| loss_td                 | 0.022019286  |\n",
            "| losses_all              | 0.0071614482 |\n",
            "| max 100 episode reward  | 369          |\n",
            "| mean 100 episode reward | 31           |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2113397      |\n",
            "------------------------------------------\n",
            " 53% 2119274/4000000 [10:21:30<8:24:58, 62.07it/s]--------------------------------------------\n",
            "| % time spent exploring  | 1              |\n",
            "| demo sample rate        | 0.0954         |\n",
            "| elapsed time            | 10:37:44       |\n",
            "| episodes                | 2550           |\n",
            "| epsilon                 | 0.01           |\n",
            "| loss_l2                 | 0.0031158538   |\n",
            "| loss_margin             | 0.0            |\n",
            "| loss_n_td               | 0.000107061824 |\n",
            "| loss_td                 | 0.042383403    |\n",
            "| losses_all              | 0.009335447    |\n",
            "| max 100 episode reward  | 369            |\n",
            "| mean 100 episode reward | 31.3           |\n",
            "| min 100 episode reward  | 2              |\n",
            "| pre_train               | False          |\n",
            "| steps                   | 2119277        |\n",
            "--------------------------------------------\n",
            " 53% 2127672/4000000 [10:24:02<9:05:34, 57.20it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0952        |\n",
            "| elapsed time            | 10:40:16      |\n",
            "| episodes                | 2560          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031179418  |\n",
            "| loss_margin             | 0.0013169348  |\n",
            "| loss_n_td               | 2.5974262e-07 |\n",
            "| loss_td                 | 0.011558485   |\n",
            "| losses_all              | 0.004841837   |\n",
            "| max 100 episode reward  | 369           |\n",
            "| mean 100 episode reward | 34.4          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2127672       |\n",
            "-------------------------------------------\n",
            " 53% 2135953/4000000 [10:26:37<8:48:57, 58.73it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0951       |\n",
            "| elapsed time            | 10:42:51     |\n",
            "| episodes                | 2570         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031122784 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0008256302 |\n",
            "| loss_td                 | 0.0584625    |\n",
            "| losses_all              | 0.013897078  |\n",
            "| max 100 episode reward  | 369          |\n",
            "| mean 100 episode reward | 36.6         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2135954      |\n",
            "------------------------------------------\n",
            " 54% 2142160/4000000 [10:28:36<9:05:59, 56.71it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.095         |\n",
            "| elapsed time            | 10:44:50      |\n",
            "| episodes                | 2580          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031231616  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 2.3743007e-07 |\n",
            "| loss_td                 | 0.0025425649  |\n",
            "| losses_all              | 0.0037754464  |\n",
            "| max 100 episode reward  | 369           |\n",
            "| mean 100 episode reward | 35.3          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2142164       |\n",
            "-------------------------------------------\n",
            " 54% 2151707/4000000 [10:31:33<8:55:32, 57.52it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0949        |\n",
            "| elapsed time            | 10:47:47      |\n",
            "| episodes                | 2590          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031279055  |\n",
            "| loss_margin             | 0.006359145   |\n",
            "| loss_n_td               | 0.00030298566 |\n",
            "| loss_td                 | 0.007075142   |\n",
            "| losses_all              | 0.0050919913  |\n",
            "| max 100 episode reward  | 369           |\n",
            "| mean 100 episode reward | 33.4          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2151707       |\n",
            "-------------------------------------------\n",
            " 54% 2159278/4000000 [10:33:56<9:08:30, 55.93it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0947        |\n",
            "| elapsed time            | 10:50:10      |\n",
            "| episodes                | 2600          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003127014   |\n",
            "| loss_margin             | 0.0026782304  |\n",
            "| loss_n_td               | 0.00011603725 |\n",
            "| loss_td                 | 0.020459283   |\n",
            "| losses_all              | 0.00696049    |\n",
            "| max 100 episode reward  | 369           |\n",
            "| mean 100 episode reward | 33            |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2159283       |\n",
            "-------------------------------------------\n",
            " 54% 2167243/4000000 [10:36:27<8:58:18, 56.74it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0946       |\n",
            "| elapsed time            | 10:52:41     |\n",
            "| episodes                | 2610         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031313817 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.012808329  |\n",
            "| losses_all              | 0.0055355974 |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 29.3         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2167245      |\n",
            "------------------------------------------\n",
            " 54% 2174012/4000000 [10:38:35<8:34:39, 59.13it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0945       |\n",
            "| elapsed time            | 10:54:49     |\n",
            "| episodes                | 2620         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031432363 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.037699394  |\n",
            "| losses_all              | 0.007226565  |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 29.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2174017      |\n",
            "------------------------------------------\n",
            " 55% 2182866/4000000 [10:41:20<8:46:51, 57.48it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0944       |\n",
            "| elapsed time            | 10:57:34     |\n",
            "| episodes                | 2630         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031451113 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.000525148  |\n",
            "| loss_td                 | 0.023840277  |\n",
            "| losses_all              | 0.0062440764 |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 29.8         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2182871      |\n",
            "------------------------------------------\n",
            " 55% 2189234/4000000 [10:43:22<8:32:50, 58.85it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0943       |\n",
            "| elapsed time            | 10:59:36     |\n",
            "| episodes                | 2640         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031391054 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0019102548 |\n",
            "| loss_td                 | 0.0104602575 |\n",
            "| losses_all              | 0.005367465  |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 28.2         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2189236      |\n",
            "------------------------------------------\n",
            " 55% 2194033/4000000 [10:44:56<9:28:23, 52.96it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0942       |\n",
            "| elapsed time            | 11:01:10     |\n",
            "| episodes                | 2650         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003148909  |\n",
            "| loss_margin             | 0.0006552562 |\n",
            "| loss_n_td               | 0.0013547661 |\n",
            "| loss_td                 | 0.03683889   |\n",
            "| losses_all              | 0.011486395  |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 27.1         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2194034      |\n",
            "------------------------------------------\n",
            " 55% 2199999/4000000 [10:46:49<8:39:08, 57.79it/s]saved checkpoint\n",
            " 55% 2201674/4000000 [10:47:20<8:30:33, 58.70it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0941       |\n",
            "| elapsed time            | 11:03:34     |\n",
            "| episodes                | 2660         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031382535 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.025299743  |\n",
            "| losses_all              | 0.005077077  |\n",
            "| max 100 episode reward  | 351          |\n",
            "| mean 100 episode reward | 23.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2201678      |\n",
            "------------------------------------------\n",
            " 55% 2208571/4000000 [10:49:25<8:07:48, 61.21it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.094        |\n",
            "| elapsed time            | 11:05:38     |\n",
            "| episodes                | 2670         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003145109  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0002947538 |\n",
            "| loss_td                 | 0.00473243   |\n",
            "| losses_all              | 0.0041944613 |\n",
            "| max 100 episode reward  | 75           |\n",
            "| mean 100 episode reward | 21.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2208573      |\n",
            "------------------------------------------\n",
            " 55% 2216586/4000000 [10:51:44<7:40:38, 64.53it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0939       |\n",
            "| elapsed time            | 11:07:58     |\n",
            "| episodes                | 2680         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031541735 |\n",
            "| loss_margin             | 0.01036866   |\n",
            "| loss_n_td               | 0.0027075743 |\n",
            "| loss_td                 | 0.02726087   |\n",
            "| losses_all              | 0.0075184107 |\n",
            "| max 100 episode reward  | 75           |\n",
            "| mean 100 episode reward | 21.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2216586      |\n",
            "------------------------------------------\n",
            " 56% 2222752/4000000 [10:53:32<7:48:03, 63.29it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0938        |\n",
            "| elapsed time            | 11:09:46      |\n",
            "| episodes                | 2690          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031657587  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00037943642 |\n",
            "| loss_td                 | 0.004699941   |\n",
            "| losses_all              | 0.0039821463  |\n",
            "| max 100 episode reward  | 374           |\n",
            "| mean 100 episode reward | 24.5          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2222757       |\n",
            "-------------------------------------------\n",
            " 56% 2229479/4000000 [10:55:31<7:50:35, 62.70it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0937       |\n",
            "| elapsed time            | 11:11:45     |\n",
            "| episodes                | 2700         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031577672 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0030969009 |\n",
            "| loss_td                 | 0.040216066  |\n",
            "| losses_all              | 0.005483251  |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 25.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2229482      |\n",
            "------------------------------------------\n",
            " 56% 2239362/4000000 [10:58:19<7:47:19, 62.79it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0936        |\n",
            "| elapsed time            | 11:14:33      |\n",
            "| episodes                | 2710          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031625624  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00010639003 |\n",
            "| loss_td                 | 0.006355009   |\n",
            "| losses_all              | 0.005061171   |\n",
            "| max 100 episode reward  | 374           |\n",
            "| mean 100 episode reward | 25.1          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2239368       |\n",
            "-------------------------------------------\n",
            " 56% 2245296/4000000 [11:00:05<7:48:48, 62.38it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 11:16:19     |\n",
            "| episodes                | 2720         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031622595 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0001455204 |\n",
            "| loss_td                 | 0.03388287   |\n",
            "| losses_all              | 0.008441845  |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 25.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2245297      |\n",
            "------------------------------------------\n",
            " 56% 2251648/4000000 [11:02:00<7:51:57, 61.74it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0934       |\n",
            "| elapsed time            | 11:18:14     |\n",
            "| episodes                | 2730         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031669696 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.030823696  |\n",
            "| losses_all              | 0.00833099   |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 24.8         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2251650      |\n",
            "------------------------------------------\n",
            " 56% 2257843/4000000 [11:03:51<7:48:43, 61.95it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0933       |\n",
            "| elapsed time            | 11:20:05     |\n",
            "| episodes                | 2740         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031592797 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.07597512   |\n",
            "| losses_all              | 0.013526587  |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 25.1         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2257846      |\n",
            "------------------------------------------\n",
            " 57% 2265719/4000000 [11:06:08<7:39:38, 62.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0932       |\n",
            "| elapsed time            | 11:22:22     |\n",
            "| episodes                | 2750         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003154788  |\n",
            "| loss_margin             | 0.0030170754 |\n",
            "| loss_n_td               | 0.0012822379 |\n",
            "| loss_td                 | 0.011746599  |\n",
            "| losses_all              | 0.005514752  |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 27.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2265724      |\n",
            "------------------------------------------\n",
            " 57% 2273308/4000000 [11:08:20<7:50:23, 61.18it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0931        |\n",
            "| elapsed time            | 11:24:33      |\n",
            "| episodes                | 2760          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031465588  |\n",
            "| loss_margin             | 0.003870733   |\n",
            "| loss_n_td               | 0.00034923796 |\n",
            "| loss_td                 | 0.0036701371  |\n",
            "| losses_all              | 0.0043591214  |\n",
            "| max 100 episode reward  | 374           |\n",
            "| mean 100 episode reward | 28.5          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2273309       |\n",
            "-------------------------------------------\n",
            " 57% 2278812/4000000 [11:09:57<7:36:37, 62.82it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.093        |\n",
            "| elapsed time            | 11:26:11     |\n",
            "| episodes                | 2770         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031462153 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.009432752  |\n",
            "| losses_all              | 0.0053466572 |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 28.2         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2278812      |\n",
            "------------------------------------------\n",
            " 57% 2283639/4000000 [11:11:25<7:26:54, 64.01it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0929       |\n",
            "| elapsed time            | 11:27:39     |\n",
            "| episodes                | 2780         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031475213 |\n",
            "| loss_margin             | 0.009923514  |\n",
            "| loss_n_td               | 0.0019423057 |\n",
            "| loss_td                 | 0.020339038  |\n",
            "| losses_all              | 0.007260968  |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 27.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2283640      |\n",
            "------------------------------------------\n",
            " 57% 2290462/4000000 [11:13:24<7:33:06, 62.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0929       |\n",
            "| elapsed time            | 11:29:38     |\n",
            "| episodes                | 2790         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031395725 |\n",
            "| loss_margin             | 0.0012382418 |\n",
            "| loss_n_td               | 0.000606382  |\n",
            "| loss_td                 | 0.040191352  |\n",
            "| losses_all              | 0.009057973  |\n",
            "| max 100 episode reward  | 75           |\n",
            "| mean 100 episode reward | 24.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2290465      |\n",
            "------------------------------------------\n",
            " 57% 2298412/4000000 [11:15:40<7:34:52, 62.35it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0927        |\n",
            "| elapsed time            | 11:31:54      |\n",
            "| episodes                | 2800          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031335067  |\n",
            "| loss_margin             | 0.005859729   |\n",
            "| loss_n_td               | 3.4211367e-05 |\n",
            "| loss_td                 | 0.012340154   |\n",
            "| losses_all              | 0.0057667685  |\n",
            "| max 100 episode reward  | 75            |\n",
            "| mean 100 episode reward | 22.7          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2298415       |\n",
            "-------------------------------------------\n",
            " 57% 2299996/4000000 [11:16:08<7:52:38, 59.95it/s]saved checkpoint\n",
            " 58% 2305902/4000000 [11:17:50<7:08:38, 65.87it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0926       |\n",
            "| elapsed time            | 11:34:04     |\n",
            "| episodes                | 2810         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031352185 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.0043105246 |\n",
            "| losses_all              | 0.004356385  |\n",
            "| max 100 episode reward  | 75           |\n",
            "| mean 100 episode reward | 23.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2305904      |\n",
            "------------------------------------------\n",
            " 58% 2313231/4000000 [11:19:56<7:29:35, 62.53it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0925        |\n",
            "| elapsed time            | 11:36:10      |\n",
            "| episodes                | 2820          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031318304  |\n",
            "| loss_margin             | 0.0026582778  |\n",
            "| loss_n_td               | 0.00032960696 |\n",
            "| loss_td                 | 0.0072464766  |\n",
            "| losses_all              | 0.004661821   |\n",
            "| max 100 episode reward  | 74            |\n",
            "| mean 100 episode reward | 23.9          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2313231       |\n",
            "-------------------------------------------\n",
            " 58% 2321706/4000000 [11:22:22<7:18:20, 63.81it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0924        |\n",
            "| elapsed time            | 11:38:36      |\n",
            "| episodes                | 2830          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003122724   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00091446436 |\n",
            "| loss_td                 | 0.026533257   |\n",
            "| losses_all              | 0.0068099266  |\n",
            "| max 100 episode reward  | 74            |\n",
            "| mean 100 episode reward | 23.6          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2321709       |\n",
            "-------------------------------------------\n",
            " 58% 2329954/4000000 [11:24:43<7:15:31, 63.91it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0923       |\n",
            "| elapsed time            | 11:40:57     |\n",
            "| episodes                | 2840         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031155413 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.0038988919 |\n",
            "| losses_all              | 0.004134994  |\n",
            "| max 100 episode reward  | 74           |\n",
            "| mean 100 episode reward | 24.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2329958      |\n",
            "------------------------------------------\n",
            " 59% 2340529/4000000 [11:27:42<7:17:04, 63.28it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0922        |\n",
            "| elapsed time            | 11:43:56      |\n",
            "| episodes                | 2850          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031099084  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 3.7078848e-05 |\n",
            "| loss_td                 | 0.24149092    |\n",
            "| losses_all              | 0.01708132    |\n",
            "| max 100 episode reward  | 349           |\n",
            "| mean 100 episode reward | 26.8          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2340534       |\n",
            "-------------------------------------------\n",
            " 59% 2347338/4000000 [11:29:41<7:21:33, 62.38it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0921        |\n",
            "| elapsed time            | 11:45:54      |\n",
            "| episodes                | 2860          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031035345  |\n",
            "| loss_margin             | 0.024407811   |\n",
            "| loss_n_td               | 0.00059090386 |\n",
            "| loss_td                 | 0.25504243    |\n",
            "| losses_all              | 0.018339505   |\n",
            "| max 100 episode reward  | 349           |\n",
            "| mean 100 episode reward | 25.4          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2347338       |\n",
            "-------------------------------------------\n",
            " 59% 2354386/4000000 [11:31:44<7:03:55, 64.70it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.092         |\n",
            "| elapsed time            | 11:47:58      |\n",
            "| episodes                | 2870          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031000264  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00022284691 |\n",
            "| loss_td                 | 0.33796778    |\n",
            "| losses_all              | 0.021572106   |\n",
            "| max 100 episode reward  | 349           |\n",
            "| mean 100 episode reward | 26.5          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2354392       |\n",
            "-------------------------------------------\n",
            " 59% 2365835/4000000 [11:34:56<7:09:58, 63.34it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0919       |\n",
            "| elapsed time            | 11:51:10     |\n",
            "| episodes                | 2880         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003095954  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.0060864137 |\n",
            "| losses_all              | 0.0041335886 |\n",
            "| max 100 episode reward  | 349          |\n",
            "| mean 100 episode reward | 25.9         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2365840      |\n",
            "------------------------------------------\n",
            " 59% 2375029/4000000 [11:37:34<7:09:28, 63.06it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0917       |\n",
            "| elapsed time            | 11:53:48     |\n",
            "| episodes                | 2890         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003083763  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.01872733   |\n",
            "| losses_all              | 0.0055845017 |\n",
            "| max 100 episode reward  | 349          |\n",
            "| mean 100 episode reward | 24.8         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2375031      |\n",
            "------------------------------------------\n",
            " 60% 2381437/4000000 [11:39:27<7:07:12, 63.14it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0917      |\n",
            "| elapsed time            | 11:55:41    |\n",
            "| episodes                | 2900        |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.003076494 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.003897343 |\n",
            "| loss_td                 | 0.16206199  |\n",
            "| losses_all              | 0.014890472 |\n",
            "| max 100 episode reward  | 349         |\n",
            "| mean 100 episode reward | 26.6        |\n",
            "| min 100 episode reward  | 2           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 2381439     |\n",
            "-----------------------------------------\n",
            " 60% 2387859/4000000 [11:41:21<7:17:07, 61.47it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0916       |\n",
            "| elapsed time            | 11:57:35     |\n",
            "| episodes                | 2910         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030738595 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.009635148  |\n",
            "| losses_all              | 0.0047693537 |\n",
            "| max 100 episode reward  | 349          |\n",
            "| mean 100 episode reward | 26.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2387861      |\n",
            "------------------------------------------\n",
            " 60% 2395039/4000000 [11:43:27<7:06:18, 62.75it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0915        |\n",
            "| elapsed time            | 11:59:41      |\n",
            "| episodes                | 2920          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003070019   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00033435904 |\n",
            "| loss_td                 | 0.03531647    |\n",
            "| losses_all              | 0.008518086   |\n",
            "| max 100 episode reward  | 349           |\n",
            "| mean 100 episode reward | 25.4          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2395041       |\n",
            "-------------------------------------------\n",
            " 60% 2399998/4000000 [11:44:52<7:07:54, 62.32it/s]saved checkpoint\n",
            " 60% 2403285/4000000 [11:45:49<7:04:46, 62.65it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0914       |\n",
            "| elapsed time            | 12:02:02     |\n",
            "| episodes                | 2930         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030635735 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0002272421 |\n",
            "| loss_td                 | 0.027977075  |\n",
            "| losses_all              | 0.006582849  |\n",
            "| max 100 episode reward  | 349          |\n",
            "| mean 100 episode reward | 27.9         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2403290      |\n",
            "------------------------------------------\n",
            " 60% 2409683/4000000 [11:47:42<7:02:35, 62.72it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0913       |\n",
            "| elapsed time            | 12:03:56     |\n",
            "| episodes                | 2940         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030549304 |\n",
            "| loss_margin             | 0.018173374  |\n",
            "| loss_n_td               | 0.001565651  |\n",
            "| loss_td                 | 0.006882856  |\n",
            "| losses_all              | 0.006292465  |\n",
            "| max 100 episode reward  | 349          |\n",
            "| mean 100 episode reward | 30.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2409686      |\n",
            "------------------------------------------\n",
            " 60% 2415944/4000000 [11:49:32<6:45:47, 65.06it/s]--------------------------------------------\n",
            "| % time spent exploring  | 1              |\n",
            "| demo sample rate        | 0.0912         |\n",
            "| elapsed time            | 12:05:46       |\n",
            "| episodes                | 2950           |\n",
            "| epsilon                 | 0.01           |\n",
            "| loss_l2                 | 0.00305229     |\n",
            "| loss_margin             | 0.0            |\n",
            "| loss_n_td               | 0.000115063165 |\n",
            "| loss_td                 | 0.004317908    |\n",
            "| losses_all              | 0.0039851624   |\n",
            "| max 100 episode reward  | 349            |\n",
            "| mean 100 episode reward | 27.8           |\n",
            "| min 100 episode reward  | 2              |\n",
            "| pre_train               | False          |\n",
            "| steps                   | 2415944        |\n",
            "--------------------------------------------\n",
            " 61% 2422871/4000000 [11:51:33<6:51:57, 63.81it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0912       |\n",
            "| elapsed time            | 12:07:47     |\n",
            "| episodes                | 2960         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030576286 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0016480406 |\n",
            "| loss_td                 | 0.012591146  |\n",
            "| losses_all              | 0.0052020354 |\n",
            "| max 100 episode reward  | 349          |\n",
            "| mean 100 episode reward | 28.9         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2422871      |\n",
            "------------------------------------------\n",
            " 61% 2429234/4000000 [11:53:26<6:55:03, 63.07it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0911       |\n",
            "| elapsed time            | 12:09:39     |\n",
            "| episodes                | 2970         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003049613  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0004976392 |\n",
            "| loss_td                 | 0.018559314  |\n",
            "| losses_all              | 0.005594885  |\n",
            "| max 100 episode reward  | 349          |\n",
            "| mean 100 episode reward | 27.3         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2429239      |\n",
            "------------------------------------------\n",
            " 61% 2436847/4000000 [11:55:37<6:58:19, 62.28it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.091        |\n",
            "| elapsed time            | 12:11:51     |\n",
            "| episodes                | 2980         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030469121 |\n",
            "| loss_margin             | 0.0018028803 |\n",
            "| loss_n_td               | 0.0020936108 |\n",
            "| loss_td                 | 0.020706356  |\n",
            "| losses_all              | 0.0072561586 |\n",
            "| max 100 episode reward  | 349          |\n",
            "| mean 100 episode reward | 27.9         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2436853      |\n",
            "------------------------------------------\n",
            " 61% 2445029/4000000 [11:57:59<6:53:16, 62.71it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0909       |\n",
            "| elapsed time            | 12:14:13     |\n",
            "| episodes                | 2990         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030604687 |\n",
            "| loss_margin             | 0.009311527  |\n",
            "| loss_n_td               | 9.982586e-06 |\n",
            "| loss_td                 | 0.008671919  |\n",
            "| losses_all              | 0.0053807776 |\n",
            "| max 100 episode reward  | 349          |\n",
            "| mean 100 episode reward | 29.1         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2445034      |\n",
            "------------------------------------------\n",
            " 61% 2452046/4000000 [12:00:01<6:51:44, 62.66it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0908       |\n",
            "| elapsed time            | 12:16:15     |\n",
            "| episodes                | 3000         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030709326 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.05703632   |\n",
            "| losses_all              | 0.011377284  |\n",
            "| max 100 episode reward  | 349          |\n",
            "| mean 100 episode reward | 27.7         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2452052      |\n",
            "------------------------------------------\n",
            " 62% 2462780/4000000 [12:03:03<6:52:13, 62.15it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0907       |\n",
            "| elapsed time            | 12:19:17     |\n",
            "| episodes                | 3010         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030521457 |\n",
            "| loss_margin             | 0.010053314  |\n",
            "| loss_n_td               | 0.010229544  |\n",
            "| loss_td                 | 0.01169425   |\n",
            "| losses_all              | 0.0063695023 |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 30.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2462785      |\n",
            "------------------------------------------\n",
            " 62% 2470719/4000000 [12:05:21<6:50:58, 62.02it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0906       |\n",
            "| elapsed time            | 12:21:35     |\n",
            "| episodes                | 3020         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030483943 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0044409167 |\n",
            "| loss_td                 | 0.041792598  |\n",
            "| losses_all              | 0.008062188  |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 30.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2470725      |\n",
            "------------------------------------------\n",
            " 62% 2477699/4000000 [12:07:23<6:46:50, 62.36it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0905      |\n",
            "| elapsed time            | 12:23:37    |\n",
            "| episodes                | 3030        |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.003036905 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.0         |\n",
            "| loss_td                 | 0.043031164 |\n",
            "| losses_all              | 0.00766752  |\n",
            "| max 100 episode reward  | 374         |\n",
            "| mean 100 episode reward | 32.9        |\n",
            "| min 100 episode reward  | 1           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 2477702     |\n",
            "-----------------------------------------\n",
            " 62% 2484767/4000000 [12:09:26<6:35:45, 63.81it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0904        |\n",
            "| elapsed time            | 12:25:40      |\n",
            "| episodes                | 3040          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030403163  |\n",
            "| loss_margin             | 0.0051063374  |\n",
            "| loss_n_td               | 0.00094669766 |\n",
            "| loss_td                 | 0.004838842   |\n",
            "| losses_all              | 0.00448142    |\n",
            "| max 100 episode reward  | 374           |\n",
            "| mean 100 episode reward | 29.6          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2484772       |\n",
            "-------------------------------------------\n",
            " 62% 2485753/4000000 [12:09:43<6:35:27, 63.82it/s]saved best model\n",
            " 62% 2492077/4000000 [12:11:33<6:33:34, 63.86it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0904       |\n",
            "| elapsed time            | 12:27:47     |\n",
            "| episodes                | 3050         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030484088 |\n",
            "| loss_margin             | 0.0017043501 |\n",
            "| loss_n_td               | 0.0020138267 |\n",
            "| loss_td                 | 0.008193903  |\n",
            "| losses_all              | 0.004569183  |\n",
            "| max 100 episode reward  | 389          |\n",
            "| mean 100 episode reward | 34.6         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2492080      |\n",
            "------------------------------------------\n",
            " 62% 2499997/4000000 [12:13:47<6:38:18, 62.76it/s]saved checkpoint\n",
            " 63% 2502404/4000000 [12:14:29<6:41:40, 62.14it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0903        |\n",
            "| elapsed time            | 12:30:43      |\n",
            "| episodes                | 3060          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030501622  |\n",
            "| loss_margin             | 0.0018549114  |\n",
            "| loss_n_td               | 0.00030678348 |\n",
            "| loss_td                 | 0.018531382   |\n",
            "| losses_all              | 0.005880231   |\n",
            "| max 100 episode reward  | 389           |\n",
            "| mean 100 episode reward | 33.2          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2502408       |\n",
            "-------------------------------------------\n",
            " 63% 2508734/4000000 [12:16:20<6:29:13, 63.86it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0902       |\n",
            "| elapsed time            | 12:32:34     |\n",
            "| episodes                | 3070         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030501678 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0062855114 |\n",
            "| loss_td                 | 0.014267463  |\n",
            "| losses_all              | 0.0053772544 |\n",
            "| max 100 episode reward  | 389          |\n",
            "| mean 100 episode reward | 33.5         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2508735      |\n",
            "------------------------------------------\n",
            " 63% 2514322/4000000 [12:18:00<6:31:33, 63.24it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0901       |\n",
            "| elapsed time            | 12:34:14     |\n",
            "| episodes                | 3080         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030455305 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.005392976  |\n",
            "| loss_td                 | 0.05467117   |\n",
            "| losses_all              | 0.017663525  |\n",
            "| max 100 episode reward  | 389          |\n",
            "| mean 100 episode reward | 33.6         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2514325      |\n",
            "------------------------------------------\n",
            " 63% 2520043/4000000 [12:19:42<6:32:30, 62.84it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0901       |\n",
            "| elapsed time            | 12:35:56     |\n",
            "| episodes                | 3090         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030457678 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.023836434  |\n",
            "| losses_all              | 0.006240528  |\n",
            "| max 100 episode reward  | 389          |\n",
            "| mean 100 episode reward | 32.9         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2520045      |\n",
            "------------------------------------------\n",
            " 63% 2525547/4000000 [12:21:20<6:34:56, 62.22it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.09         |\n",
            "| elapsed time            | 12:37:34     |\n",
            "| episodes                | 3100         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030446672 |\n",
            "| loss_margin             | 0.0024126023 |\n",
            "| loss_n_td               | 8.357732e-06 |\n",
            "| loss_td                 | 0.013498384  |\n",
            "| losses_all              | 0.0063352045 |\n",
            "| max 100 episode reward  | 389          |\n",
            "| mean 100 episode reward | 33           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2525550      |\n",
            "------------------------------------------\n",
            " 63% 2532073/4000000 [12:23:15<6:39:05, 61.30it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0899       |\n",
            "| elapsed time            | 12:39:29     |\n",
            "| episodes                | 3110         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030524707 |\n",
            "| loss_margin             | 0.01221177   |\n",
            "| loss_n_td               | 0.0006321453 |\n",
            "| loss_td                 | 0.027318753  |\n",
            "| losses_all              | 0.007942155  |\n",
            "| max 100 episode reward  | 389          |\n",
            "| mean 100 episode reward | 30.5         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2532078      |\n",
            "------------------------------------------\n",
            " 63% 2539764/4000000 [12:25:29<6:29:42, 62.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0898       |\n",
            "| elapsed time            | 12:41:43     |\n",
            "| episodes                | 3120         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030479191 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010398217 |\n",
            "| loss_td                 | 0.013439622  |\n",
            "| losses_all              | 0.0046827113 |\n",
            "| max 100 episode reward  | 389          |\n",
            "| mean 100 episode reward | 34.6         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2539769      |\n",
            "------------------------------------------\n",
            " 64% 2547208/4000000 [12:27:38<6:15:46, 64.44it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0898        |\n",
            "| elapsed time            | 12:43:52      |\n",
            "| episodes                | 3130          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030554826  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 4.7499752e-06 |\n",
            "| loss_td                 | 0.00554099    |\n",
            "| losses_all              | 0.003840981   |\n",
            "| max 100 episode reward  | 389           |\n",
            "| mean 100 episode reward | 30.2          |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2547213       |\n",
            "-------------------------------------------\n",
            " 64% 2553500/4000000 [12:29:29<6:29:10, 61.95it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0897       |\n",
            "| elapsed time            | 12:45:43     |\n",
            "| episodes                | 3140         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030638098 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.022384232  |\n",
            "| losses_all              | 0.0058128396 |\n",
            "| max 100 episode reward  | 389          |\n",
            "| mean 100 episode reward | 30.2         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2553500      |\n",
            "------------------------------------------\n",
            " 64% 2563355/4000000 [12:32:17<6:20:44, 62.89it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0896        |\n",
            "| elapsed time            | 12:48:31      |\n",
            "| episodes                | 3150          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030603143  |\n",
            "| loss_margin             | 0.0018752217  |\n",
            "| loss_n_td               | 0.00031706385 |\n",
            "| loss_td                 | 0.018620662   |\n",
            "| losses_all              | 0.0053772274  |\n",
            "| max 100 episode reward  | 358           |\n",
            "| mean 100 episode reward | 27.7          |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2563358       |\n",
            "-------------------------------------------\n",
            " 64% 2573073/4000000 [12:35:02<6:28:43, 61.18it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0895        |\n",
            "| elapsed time            | 12:51:16      |\n",
            "| episodes                | 3160          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030680916  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00026889285 |\n",
            "| loss_td                 | 0.008797936   |\n",
            "| losses_all              | 0.004588483   |\n",
            "| max 100 episode reward  | 358           |\n",
            "| mean 100 episode reward | 32            |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2573078       |\n",
            "-------------------------------------------\n",
            " 64% 2578993/4000000 [12:36:47<6:11:50, 63.69it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0894       |\n",
            "| elapsed time            | 12:53:00     |\n",
            "| episodes                | 3170         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030642718 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0011794423 |\n",
            "| loss_td                 | 0.013597605  |\n",
            "| losses_all              | 0.0050462293 |\n",
            "| max 100 episode reward  | 358          |\n",
            "| mean 100 episode reward | 31.7         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2578993      |\n",
            "------------------------------------------\n",
            " 65% 2586460/4000000 [12:38:57<6:52:19, 57.14it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0893        |\n",
            "| elapsed time            | 12:55:11      |\n",
            "| episodes                | 3180          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030582482  |\n",
            "| loss_margin             | 0.005800277   |\n",
            "| loss_n_td               | 0.00091154216 |\n",
            "| loss_td                 | 0.0136413565  |\n",
            "| losses_all              | 0.00560149    |\n",
            "| max 100 episode reward  | 358           |\n",
            "| mean 100 episode reward | 32            |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2586461       |\n",
            "-------------------------------------------\n",
            " 65% 2595071/4000000 [12:41:24<6:10:34, 63.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0893       |\n",
            "| elapsed time            | 12:57:38     |\n",
            "| episodes                | 3190         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030539178 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 9.245002e-05 |\n",
            "| loss_td                 | 0.005920329  |\n",
            "| losses_all              | 0.0042378395 |\n",
            "| max 100 episode reward  | 358          |\n",
            "| mean 100 episode reward | 36.5         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2595072      |\n",
            "------------------------------------------\n",
            " 65% 2599994/4000000 [12:42:50<6:01:58, 64.46it/s]saved checkpoint\n",
            " 65% 2601555/4000000 [12:43:18<6:11:54, 62.67it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0892       |\n",
            "| elapsed time            | 12:59:32     |\n",
            "| episodes                | 3200         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030584699 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.021884799  |\n",
            "| losses_all              | 0.005959883  |\n",
            "| max 100 episode reward  | 358          |\n",
            "| mean 100 episode reward | 37.3         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2601559      |\n",
            "------------------------------------------\n",
            " 65% 2607055/4000000 [12:44:57<6:09:31, 62.83it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0891        |\n",
            "| elapsed time            | 13:01:11      |\n",
            "| episodes                | 3210          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030571679  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00011582305 |\n",
            "| loss_td                 | 0.00485125    |\n",
            "| losses_all              | 0.004086993   |\n",
            "| max 100 episode reward  | 358           |\n",
            "| mean 100 episode reward | 36.4          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2607061       |\n",
            "-------------------------------------------\n",
            " 65% 2613021/4000000 [12:46:42<6:04:18, 63.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0891       |\n",
            "| elapsed time            | 13:02:56     |\n",
            "| episodes                | 3220         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003057506  |\n",
            "| loss_margin             | 0.016270503  |\n",
            "| loss_n_td               | 0.0017315864 |\n",
            "| loss_td                 | 0.043096535  |\n",
            "| losses_all              | 0.015503394  |\n",
            "| max 100 episode reward  | 355          |\n",
            "| mean 100 episode reward | 34.6         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2613025      |\n",
            "------------------------------------------\n",
            " 66% 2620480/4000000 [12:48:52<5:55:03, 64.75it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.089         |\n",
            "| elapsed time            | 13:05:05      |\n",
            "| episodes                | 3230          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003054478   |\n",
            "| loss_margin             | 0.0021728426  |\n",
            "| loss_n_td               | 0.00010135741 |\n",
            "| loss_td                 | 0.004687643   |\n",
            "| losses_all              | 0.0042786435  |\n",
            "| max 100 episode reward  | 355           |\n",
            "| mean 100 episode reward | 38.3          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2620481       |\n",
            "-------------------------------------------\n",
            " 66% 2627835/4000000 [12:50:59<6:02:06, 63.16it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0889       |\n",
            "| elapsed time            | 13:07:13     |\n",
            "| episodes                | 3240         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030553844 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010129064 |\n",
            "| loss_td                 | 0.012160219  |\n",
            "| losses_all              | 0.004965258  |\n",
            "| max 100 episode reward  | 383          |\n",
            "| mean 100 episode reward | 44.2         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2627836      |\n",
            "------------------------------------------\n",
            " 66% 2637378/4000000 [12:53:42<6:01:23, 62.84it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0888       |\n",
            "| elapsed time            | 13:09:56     |\n",
            "| episodes                | 3250         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030622436 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.06795863   |\n",
            "| losses_all              | 0.009025201  |\n",
            "| max 100 episode reward  | 383          |\n",
            "| mean 100 episode reward | 41           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2637381      |\n",
            "------------------------------------------\n",
            " 66% 2644712/4000000 [12:55:49<5:55:00, 63.63it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0887       |\n",
            "| elapsed time            | 13:12:03     |\n",
            "| episodes                | 3260         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030567483 |\n",
            "| loss_margin             | 0.023843698  |\n",
            "| loss_n_td               | 0.0003515205 |\n",
            "| loss_td                 | 0.020200726  |\n",
            "| losses_all              | 0.0075682956 |\n",
            "| max 100 episode reward  | 383          |\n",
            "| mean 100 episode reward | 38.6         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2644713      |\n",
            "------------------------------------------\n",
            " 66% 2650694/4000000 [12:57:35<6:24:54, 58.43it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0887       |\n",
            "| elapsed time            | 13:13:49     |\n",
            "| episodes                | 3270         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030556251 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.024382537  |\n",
            "| loss_td                 | 0.2882348    |\n",
            "| losses_all              | 0.020072963  |\n",
            "| max 100 episode reward  | 383          |\n",
            "| mean 100 episode reward | 39.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2650695      |\n",
            "------------------------------------------\n",
            " 66% 2658930/4000000 [12:59:56<6:00:20, 62.03it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0886       |\n",
            "| elapsed time            | 13:16:10     |\n",
            "| episodes                | 3280         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030551688 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0008675823 |\n",
            "| loss_td                 | 0.023016658  |\n",
            "| losses_all              | 0.00564719   |\n",
            "| max 100 episode reward  | 383          |\n",
            "| mean 100 episode reward | 43.3         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2658932      |\n",
            "------------------------------------------\n",
            " 67% 2664299/4000000 [13:01:32<5:53:23, 62.99it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0885       |\n",
            "| elapsed time            | 13:17:46     |\n",
            "| episodes                | 3290         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030594254 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 9.134211e-05 |\n",
            "| loss_td                 | 0.20275004   |\n",
            "| losses_all              | 0.0189907    |\n",
            "| max 100 episode reward  | 383          |\n",
            "| mean 100 episode reward | 39.3         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2664304      |\n",
            "------------------------------------------\n",
            " 67% 2672201/4000000 [13:03:49<5:52:35, 62.76it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0885       |\n",
            "| elapsed time            | 13:20:02     |\n",
            "| episodes                | 3300         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030613146 |\n",
            "| loss_margin             | 0.0072583854 |\n",
            "| loss_n_td               | 0.0017884261 |\n",
            "| loss_td                 | 0.020910904  |\n",
            "| losses_all              | 0.006710101  |\n",
            "| max 100 episode reward  | 383          |\n",
            "| mean 100 episode reward | 44.5         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2672202      |\n",
            "------------------------------------------\n",
            " 67% 2679693/4000000 [13:05:58<5:41:14, 64.49it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0884        |\n",
            "| elapsed time            | 13:22:12      |\n",
            "| episodes                | 3310          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0030590224  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00017338307 |\n",
            "| loss_td                 | 0.03312178    |\n",
            "| losses_all              | 0.008743179   |\n",
            "| max 100 episode reward  | 383           |\n",
            "| mean 100 episode reward | 47.4          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2679695       |\n",
            "-------------------------------------------\n",
            " 67% 2686309/4000000 [13:07:54<5:55:36, 61.57it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0883       |\n",
            "| elapsed time            | 13:24:08     |\n",
            "| episodes                | 3320         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030695477 |\n",
            "| loss_margin             | 0.0012694672 |\n",
            "| loss_n_td               | 8.787199e-05 |\n",
            "| loss_td                 | 0.0049635596 |\n",
            "| losses_all              | 0.0042339605 |\n",
            "| max 100 episode reward  | 383          |\n",
            "| mean 100 episode reward | 45           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2686313      |\n",
            "------------------------------------------\n",
            " 67% 2694112/4000000 [13:10:09<5:46:13, 62.86it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0882        |\n",
            "| elapsed time            | 13:26:23      |\n",
            "| episodes                | 3330          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003083211   |\n",
            "| loss_margin             | 0.006797068   |\n",
            "| loss_n_td               | 0.00050271826 |\n",
            "| loss_td                 | 0.014917251   |\n",
            "| losses_all              | 0.0053422796  |\n",
            "| max 100 episode reward  | 383           |\n",
            "| mean 100 episode reward | 42.9          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2694114       |\n",
            "-------------------------------------------\n",
            " 67% 2699994/4000000 [13:11:49<5:42:27, 63.27it/s]saved checkpoint\n",
            " 68% 2701876/4000000 [13:12:23<5:49:35, 61.89it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0882       |\n",
            "| elapsed time            | 13:28:37     |\n",
            "| episodes                | 3340         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030906193 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0013657248 |\n",
            "| loss_td                 | 0.022085056  |\n",
            "| losses_all              | 0.007093614  |\n",
            "| max 100 episode reward  | 351          |\n",
            "| mean 100 episode reward | 40.5         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2701881      |\n",
            "------------------------------------------\n",
            " 68% 2709457/4000000 [13:14:34<5:40:35, 63.15it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0881      |\n",
            "| elapsed time            | 13:30:48    |\n",
            "| episodes                | 3350        |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.003089755 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.001175836 |\n",
            "| loss_td                 | 0.022581289 |\n",
            "| losses_all              | 0.005877732 |\n",
            "| max 100 episode reward  | 351         |\n",
            "| mean 100 episode reward | 39.7        |\n",
            "| min 100 episode reward  | 4           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 2709457     |\n",
            "-----------------------------------------\n",
            " 68% 2717184/4000000 [13:16:51<5:48:57, 61.27it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.088        |\n",
            "| elapsed time            | 13:33:04     |\n",
            "| episodes                | 3360         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0030986227 |\n",
            "| loss_margin             | 0.0036064237 |\n",
            "| loss_n_td               | 0.0022255834 |\n",
            "| loss_td                 | 0.005001588  |\n",
            "| losses_all              | 0.0043930025 |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 46.2         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2717188      |\n",
            "------------------------------------------\n",
            " 68% 2721676/4000000 [13:18:14<5:58:07, 59.49it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.088         |\n",
            "| elapsed time            | 13:34:28      |\n",
            "| episodes                | 3370          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031044947  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00083241815 |\n",
            "| loss_td                 | 0.020088268   |\n",
            "| losses_all              | 0.0053708637  |\n",
            "| max 100 episode reward  | 365           |\n",
            "| mean 100 episode reward | 45.2          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2721680       |\n",
            "-------------------------------------------\n",
            " 68% 2729032/4000000 [13:20:23<5:56:02, 59.49it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0879       |\n",
            "| elapsed time            | 13:36:37     |\n",
            "| episodes                | 3380         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003105067  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0047614584 |\n",
            "| loss_td                 | 0.013405796  |\n",
            "| losses_all              | 0.0056500537 |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 44.4         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2729035      |\n",
            "------------------------------------------\n",
            " 68% 2735268/4000000 [13:22:13<5:32:31, 63.39it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0878        |\n",
            "| elapsed time            | 13:38:26      |\n",
            "| episodes                | 3390          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031147741  |\n",
            "| loss_margin             | 0.009547986   |\n",
            "| loss_n_td               | 0.00079315546 |\n",
            "| loss_td                 | 0.020015895   |\n",
            "| losses_all              | 0.0072088223  |\n",
            "| max 100 episode reward  | 365           |\n",
            "| mean 100 episode reward | 45.9          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2735271       |\n",
            "-------------------------------------------\n",
            " 69% 2743213/4000000 [13:24:31<5:36:35, 62.23it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0877       |\n",
            "| elapsed time            | 13:40:44     |\n",
            "| episodes                | 3400         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031159506 |\n",
            "| loss_margin             | 0.048096985  |\n",
            "| loss_n_td               | 0.044886634  |\n",
            "| loss_td                 | 0.077054635  |\n",
            "| losses_all              | 0.013601856  |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 41.4         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2743214      |\n",
            "------------------------------------------\n",
            " 69% 2749513/4000000 [13:26:22<5:39:28, 61.39it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0877       |\n",
            "| elapsed time            | 13:42:36     |\n",
            "| episodes                | 3410         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003116361  |\n",
            "| loss_margin             | 0.0024171397 |\n",
            "| loss_n_td               | 0.0038536335 |\n",
            "| loss_td                 | 0.17517759   |\n",
            "| losses_all              | 0.016016366  |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 39.3         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2749513      |\n",
            "------------------------------------------\n",
            " 69% 2756011/4000000 [13:28:15<5:23:11, 64.15it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0876       |\n",
            "| elapsed time            | 13:44:29     |\n",
            "| episodes                | 3420         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031296972 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0013389797 |\n",
            "| loss_td                 | 0.009952063  |\n",
            "| losses_all              | 0.005149574  |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 39.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2756016      |\n",
            "------------------------------------------\n",
            " 69% 2762870/4000000 [13:30:14<5:23:16, 63.78it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0876       |\n",
            "| elapsed time            | 13:46:28     |\n",
            "| episodes                | 3430         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031397443 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.011340344  |\n",
            "| losses_all              | 0.005443736  |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 40.1         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2762871      |\n",
            "------------------------------------------\n",
            " 69% 2770112/4000000 [13:32:20<5:22:16, 63.61it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0875       |\n",
            "| elapsed time            | 13:48:34     |\n",
            "| episodes                | 3440         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031446724 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.002076744  |\n",
            "| loss_td                 | 0.06154737   |\n",
            "| losses_all              | 0.012702532  |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 39.2         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2770112      |\n",
            "------------------------------------------\n",
            " 69% 2777313/4000000 [13:34:25<5:20:21, 63.61it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0874       |\n",
            "| elapsed time            | 13:50:39     |\n",
            "| episodes                | 3450         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003161003  |\n",
            "| loss_margin             | 0.0013561547 |\n",
            "| loss_n_td               | 0.0005632636 |\n",
            "| loss_td                 | 0.019833399  |\n",
            "| losses_all              | 0.005748432  |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 40.5         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2777319      |\n",
            "------------------------------------------\n",
            " 70% 2785951/4000000 [13:36:55<5:22:23, 62.76it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0873       |\n",
            "| elapsed time            | 13:53:09     |\n",
            "| episodes                | 3460         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031691603 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.011838121  |\n",
            "| losses_all              | 0.0048021358 |\n",
            "| max 100 episode reward  | 276          |\n",
            "| mean 100 episode reward | 32.7         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2785954      |\n",
            "------------------------------------------\n",
            " 70% 2791909/4000000 [13:38:41<5:23:54, 62.16it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0873        |\n",
            "| elapsed time            | 13:54:55      |\n",
            "| episodes                | 3470          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031728079  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00043816626 |\n",
            "| loss_td                 | 0.013938626   |\n",
            "| losses_all              | 0.005107307   |\n",
            "| max 100 episode reward  | 276           |\n",
            "| mean 100 episode reward | 34.5          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2791909       |\n",
            "-------------------------------------------\n",
            " 70% 2798538/4000000 [13:40:38<5:15:55, 63.38it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0872        |\n",
            "| elapsed time            | 13:56:52      |\n",
            "| episodes                | 3480          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031739795  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00014850854 |\n",
            "| loss_td                 | 0.012265374   |\n",
            "| losses_all              | 0.005261284   |\n",
            "| max 100 episode reward  | 276           |\n",
            "| mean 100 episode reward | 31            |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2798544       |\n",
            "-------------------------------------------\n",
            " 70% 2799995/4000000 [13:41:04<5:38:42, 59.05it/s]saved checkpoint\n",
            " 70% 2804788/4000000 [13:42:29<5:13:30, 63.54it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0871       |\n",
            "| elapsed time            | 13:58:43     |\n",
            "| episodes                | 3490         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031760565 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.022919493  |\n",
            "| losses_all              | 0.005728936  |\n",
            "| max 100 episode reward  | 276          |\n",
            "| mean 100 episode reward | 30.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2804789      |\n",
            "------------------------------------------\n",
            " 70% 2810406/4000000 [13:44:10<5:10:38, 63.82it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0871       |\n",
            "| elapsed time            | 14:00:24     |\n",
            "| episodes                | 3500         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003183654  |\n",
            "| loss_margin             | 0.005668152  |\n",
            "| loss_n_td               | 0.0029193386 |\n",
            "| loss_td                 | 0.022808412  |\n",
            "| losses_all              | 0.007408422  |\n",
            "| max 100 episode reward  | 276          |\n",
            "| mean 100 episode reward | 30.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2810407      |\n",
            "------------------------------------------\n",
            " 70% 2818879/4000000 [13:46:38<5:23:24, 60.87it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.087        |\n",
            "| elapsed time            | 14:02:52     |\n",
            "| episodes                | 3510         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031896026 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.000592835  |\n",
            "| loss_td                 | 0.029240308  |\n",
            "| losses_all              | 0.006405036  |\n",
            "| max 100 episode reward  | 276          |\n",
            "| mean 100 episode reward | 32.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2818881      |\n",
            "------------------------------------------\n",
            " 71% 2825618/4000000 [13:48:37<5:14:02, 62.32it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0869        |\n",
            "| elapsed time            | 14:04:51      |\n",
            "| episodes                | 3520          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003204685   |\n",
            "| loss_margin             | 0.00044638664 |\n",
            "| loss_n_td               | 0.00049182645 |\n",
            "| loss_td                 | 0.004918769   |\n",
            "| losses_all              | 0.00417491    |\n",
            "| max 100 episode reward  | 276           |\n",
            "| mean 100 episode reward | 31.5          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2825622       |\n",
            "-------------------------------------------\n",
            " 71% 2832850/4000000 [13:50:43<5:07:50, 63.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0869       |\n",
            "| elapsed time            | 14:06:57     |\n",
            "| episodes                | 3530         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032195323 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.028366012  |\n",
            "| losses_all              | 0.0060503082 |\n",
            "| max 100 episode reward  | 276          |\n",
            "| mean 100 episode reward | 30.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2832856      |\n",
            "------------------------------------------\n",
            " 71% 2838778/4000000 [13:52:30<5:03:24, 63.79it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0868        |\n",
            "| elapsed time            | 14:08:44      |\n",
            "| episodes                | 3540          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032138324  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 1.9118039e-05 |\n",
            "| loss_td                 | 0.27822992    |\n",
            "| losses_all              | 0.015811995   |\n",
            "| max 100 episode reward  | 237           |\n",
            "| mean 100 episode reward | 29            |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2838778       |\n",
            "-------------------------------------------\n",
            " 71% 2846334/4000000 [13:54:42<5:02:24, 63.58it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0868        |\n",
            "| elapsed time            | 14:10:56      |\n",
            "| episodes                | 3550          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032219873  |\n",
            "| loss_margin             | 0.00037051737 |\n",
            "| loss_n_td               | 6.942451e-06  |\n",
            "| loss_td                 | 0.007774519   |\n",
            "| losses_all              | 0.0046541295  |\n",
            "| max 100 episode reward  | 237           |\n",
            "| mean 100 episode reward | 27.8          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2846334       |\n",
            "-------------------------------------------\n",
            " 71% 2852070/4000000 [13:56:26<5:17:57, 60.17it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0867       |\n",
            "| elapsed time            | 14:12:40     |\n",
            "| episodes                | 3560         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032325312 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0005171174 |\n",
            "| loss_td                 | 0.047890004  |\n",
            "| losses_all              | 0.007962726  |\n",
            "| max 100 episode reward  | 237          |\n",
            "| mean 100 episode reward | 27.1         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2852075      |\n",
            "------------------------------------------\n",
            " 71% 2857884/4000000 [13:58:13<5:16:22, 60.17it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0866       |\n",
            "| elapsed time            | 14:14:27     |\n",
            "| episodes                | 3570         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032400168 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0002208277 |\n",
            "| loss_td                 | 0.030191768  |\n",
            "| losses_all              | 0.006056346  |\n",
            "| max 100 episode reward  | 237          |\n",
            "| mean 100 episode reward | 25.6         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2857887      |\n",
            "------------------------------------------\n",
            " 72% 2867646/4000000 [14:01:02<5:01:45, 62.54it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0866        |\n",
            "| elapsed time            | 14:17:16      |\n",
            "| episodes                | 3580          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032498657  |\n",
            "| loss_margin             | 0.016188748   |\n",
            "| loss_n_td               | 0.00011536339 |\n",
            "| loss_td                 | 0.0039143004  |\n",
            "| losses_all              | 0.0053950744  |\n",
            "| max 100 episode reward  | 237           |\n",
            "| mean 100 episode reward | 28.6          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2867647       |\n",
            "-------------------------------------------\n",
            " 72% 2875463/4000000 [14:03:18<4:54:33, 63.63it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0865       |\n",
            "| elapsed time            | 14:19:32     |\n",
            "| episodes                | 3590         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032556555 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0002495684 |\n",
            "| loss_td                 | 0.03717927   |\n",
            "| losses_all              | 0.0077790148 |\n",
            "| max 100 episode reward  | 237          |\n",
            "| mean 100 episode reward | 27.5         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2875465      |\n",
            "------------------------------------------\n",
            " 72% 2882306/4000000 [14:05:19<4:53:35, 63.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0864       |\n",
            "| elapsed time            | 14:21:33     |\n",
            "| episodes                | 3600         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032630072 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 6.204795e-05 |\n",
            "| loss_td                 | 0.049728163  |\n",
            "| losses_all              | 0.011546581  |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 29.3         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2882312      |\n",
            "------------------------------------------\n",
            " 72% 2891882/4000000 [14:08:04<4:53:06, 63.01it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0863       |\n",
            "| elapsed time            | 14:24:18     |\n",
            "| episodes                | 3610         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032605664 |\n",
            "| loss_margin             | 0.011427522  |\n",
            "| loss_n_td               | 0.0024588527 |\n",
            "| loss_td                 | 0.01400125   |\n",
            "| losses_all              | 0.0061009587 |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 28.3         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2891886      |\n",
            "------------------------------------------\n",
            " 72% 2898399/4000000 [14:09:59<4:53:44, 62.50it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0863       |\n",
            "| elapsed time            | 14:26:13     |\n",
            "| episodes                | 3620         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032559277 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 6.898909e-05 |\n",
            "| loss_td                 | 0.01723967   |\n",
            "| losses_all              | 0.0057194764 |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 28.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2898404      |\n",
            "------------------------------------------\n",
            " 72% 2899995/4000000 [14:10:29<5:02:32, 60.60it/s]saved checkpoint\n",
            " 73% 2904672/4000000 [14:11:53<4:54:47, 61.93it/s]--------------------------------------------\n",
            "| % time spent exploring  | 1              |\n",
            "| demo sample rate        | 0.0862         |\n",
            "| elapsed time            | 14:28:06       |\n",
            "| episodes                | 3630           |\n",
            "| epsilon                 | 0.01           |\n",
            "| loss_l2                 | 0.0032608514   |\n",
            "| loss_margin             | 0.00010063499  |\n",
            "| loss_n_td               | 1.47813225e-05 |\n",
            "| loss_td                 | 0.0075944625   |\n",
            "| losses_all              | 0.004621058    |\n",
            "| max 100 episode reward  | 341            |\n",
            "| mean 100 episode reward | 28.9           |\n",
            "| min 100 episode reward  | 1              |\n",
            "| pre_train               | False          |\n",
            "| steps                   | 2904674        |\n",
            "--------------------------------------------\n",
            " 73% 2912437/4000000 [14:14:09<4:54:36, 61.52it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0861       |\n",
            "| elapsed time            | 14:30:23     |\n",
            "| episodes                | 3640         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032663702 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0007972057 |\n",
            "| loss_td                 | 0.060309976  |\n",
            "| losses_all              | 0.008460956  |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 29.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2912443      |\n",
            "------------------------------------------\n",
            " 73% 2918896/4000000 [14:16:03<4:50:04, 62.12it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0861       |\n",
            "| elapsed time            | 14:32:17     |\n",
            "| episodes                | 3650         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032638405 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 6.614564e-05 |\n",
            "| loss_td                 | 0.047015585  |\n",
            "| losses_all              | 0.008288952  |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 30.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2918900      |\n",
            "------------------------------------------\n",
            " 73% 2926623/4000000 [14:18:18<4:51:12, 61.43it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.086         |\n",
            "| elapsed time            | 14:34:32      |\n",
            "| episodes                | 3660          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003267253   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00068936317 |\n",
            "| loss_td                 | 0.025912542   |\n",
            "| losses_all              | 0.008683141   |\n",
            "| max 100 episode reward  | 341           |\n",
            "| mean 100 episode reward | 31.6          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2926623       |\n",
            "-------------------------------------------\n",
            " 73% 2936924/4000000 [14:21:15<4:40:51, 63.08it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0859        |\n",
            "| elapsed time            | 14:37:29      |\n",
            "| episodes                | 3670          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032741672  |\n",
            "| loss_margin             | 0.022868812   |\n",
            "| loss_n_td               | 0.00033625582 |\n",
            "| loss_td                 | 0.031089528   |\n",
            "| losses_all              | 0.009445266   |\n",
            "| max 100 episode reward  | 341           |\n",
            "| mean 100 episode reward | 31.4          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2936927       |\n",
            "-------------------------------------------\n",
            " 74% 2943078/4000000 [14:23:05<4:43:14, 62.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0859       |\n",
            "| elapsed time            | 14:39:19     |\n",
            "| episodes                | 3680         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032841007 |\n",
            "| loss_margin             | 0.007445693  |\n",
            "| loss_n_td               | 0.0028163814 |\n",
            "| loss_td                 | 0.007530554  |\n",
            "| losses_all              | 0.0052837026 |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 31.1         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2943083      |\n",
            "------------------------------------------\n",
            " 74% 2950786/4000000 [14:25:20<4:43:00, 61.79it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0858       |\n",
            "| elapsed time            | 14:41:34     |\n",
            "| episodes                | 3690         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032910632 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.025773931  |\n",
            "| losses_all              | 0.007517129  |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 33.7         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2950792      |\n",
            "------------------------------------------\n",
            " 74% 2958250/4000000 [14:27:31<4:56:30, 58.56it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0858       |\n",
            "| elapsed time            | 14:43:45     |\n",
            "| episodes                | 3700         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032973955 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.023753736  |\n",
            "| losses_all              | 0.007357922  |\n",
            "| max 100 episode reward  | 290          |\n",
            "| mean 100 episode reward | 32.4         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2958252      |\n",
            "------------------------------------------\n",
            " 74% 2963953/4000000 [14:29:14<4:57:50, 57.98it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0857        |\n",
            "| elapsed time            | 14:45:28      |\n",
            "| episodes                | 3710          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0033124627  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00028725943 |\n",
            "| loss_td                 | 0.015543662   |\n",
            "| losses_all              | 0.005318173   |\n",
            "| max 100 episode reward  | 290           |\n",
            "| mean 100 episode reward | 30.7          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2963958       |\n",
            "-------------------------------------------\n",
            " 74% 2969737/4000000 [14:30:58<4:34:54, 62.46it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0857       |\n",
            "| elapsed time            | 14:47:12     |\n",
            "| episodes                | 3720         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033137507 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 3.271436e-05 |\n",
            "| loss_td                 | 0.08090332   |\n",
            "| losses_all              | 0.009715248  |\n",
            "| max 100 episode reward  | 290          |\n",
            "| mean 100 episode reward | 30.5         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2969741      |\n",
            "------------------------------------------\n",
            " 74% 2976272/4000000 [14:32:53<4:32:39, 62.58it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0856        |\n",
            "| elapsed time            | 14:49:07      |\n",
            "| episodes                | 3730          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0033218884  |\n",
            "| loss_margin             | 0.00021653622 |\n",
            "| loss_n_td               | 0.0017698477  |\n",
            "| loss_td                 | 0.07802471    |\n",
            "| losses_all              | 0.00873022    |\n",
            "| max 100 episode reward  | 290           |\n",
            "| mean 100 episode reward | 31.6          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2976276       |\n",
            "-------------------------------------------\n",
            " 75% 2982160/4000000 [14:34:38<4:31:54, 62.39it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0855       |\n",
            "| elapsed time            | 14:50:52     |\n",
            "| episodes                | 3740         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003328489  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 9.545709e-05 |\n",
            "| loss_td                 | 0.075133964  |\n",
            "| losses_all              | 0.009536637  |\n",
            "| max 100 episode reward  | 290          |\n",
            "| mean 100 episode reward | 30.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2982160      |\n",
            "------------------------------------------\n",
            " 75% 2991343/4000000 [14:37:16<4:31:47, 61.85it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0855       |\n",
            "| elapsed time            | 14:53:30     |\n",
            "| episodes                | 3750         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033262977 |\n",
            "| loss_margin             | 0.016460136  |\n",
            "| loss_n_td               | 0.0051168213 |\n",
            "| loss_td                 | 0.026465626  |\n",
            "| losses_all              | 0.00804284   |\n",
            "| max 100 episode reward  | 290          |\n",
            "| mean 100 episode reward | 31.3         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2991345      |\n",
            "------------------------------------------\n",
            " 75% 2999994/4000000 [14:39:47<4:26:50, 62.46it/s]saved checkpoint\n",
            " 75% 3000113/4000000 [14:39:49<4:27:42, 62.25it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0854       |\n",
            "| elapsed time            | 14:56:03     |\n",
            "| episodes                | 3760         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033328454 |\n",
            "| loss_margin             | 0.0025677904 |\n",
            "| loss_n_td               | 5.839287e-06 |\n",
            "| loss_td                 | 0.016075468  |\n",
            "| losses_all              | 0.0060839374 |\n",
            "| max 100 episode reward  | 290          |\n",
            "| mean 100 episode reward | 31.2         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3000117      |\n",
            "------------------------------------------\n",
            " 75% 3007728/4000000 [14:42:02<4:29:42, 61.32it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0853        |\n",
            "| elapsed time            | 14:58:15      |\n",
            "| episodes                | 3770          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0033381353  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00011874406 |\n",
            "| loss_td                 | 0.008437803   |\n",
            "| losses_all              | 0.0044901464  |\n",
            "| max 100 episode reward  | 290           |\n",
            "| mean 100 episode reward | 31            |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3007730       |\n",
            "-------------------------------------------\n",
            " 75% 3014175/4000000 [14:43:57<4:21:08, 62.92it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0853       |\n",
            "| elapsed time            | 15:00:11     |\n",
            "| episodes                | 3780         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033466467 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0006567966 |\n",
            "| loss_td                 | 0.03246308   |\n",
            "| losses_all              | 0.0070107793 |\n",
            "| max 100 episode reward  | 153          |\n",
            "| mean 100 episode reward | 28.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3014178      |\n",
            "------------------------------------------\n",
            " 76% 3022777/4000000 [14:46:26<4:22:39, 62.01it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0852       |\n",
            "| elapsed time            | 15:02:40     |\n",
            "| episodes                | 3790         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033548328 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0011672612 |\n",
            "| loss_td                 | 0.030545104  |\n",
            "| losses_all              | 0.008360666  |\n",
            "| max 100 episode reward  | 153          |\n",
            "| mean 100 episode reward | 25.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3022783      |\n",
            "------------------------------------------\n",
            " 76% 3031340/4000000 [14:48:54<4:15:38, 63.15it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0851       |\n",
            "| elapsed time            | 15:05:08     |\n",
            "| episodes                | 3800         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033586451 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0017727691 |\n",
            "| loss_td                 | 0.018312044  |\n",
            "| losses_all              | 0.0062554628 |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 27.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3031342      |\n",
            "------------------------------------------\n",
            " 76% 3038585/4000000 [14:51:01<4:23:02, 60.92it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0851        |\n",
            "| elapsed time            | 15:07:15      |\n",
            "| episodes                | 3810          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0033621283  |\n",
            "| loss_margin             | 0.0013777576  |\n",
            "| loss_n_td               | 7.1664996e-05 |\n",
            "| loss_td                 | 0.025931183   |\n",
            "| losses_all              | 0.0065345806  |\n",
            "| max 100 episode reward  | 354           |\n",
            "| mean 100 episode reward | 28.1          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3038589       |\n",
            "-------------------------------------------\n",
            " 76% 3044203/4000000 [14:52:43<4:17:49, 61.79it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.085         |\n",
            "| elapsed time            | 15:08:57      |\n",
            "| episodes                | 3820          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0033655798  |\n",
            "| loss_margin             | 0.003758788   |\n",
            "| loss_n_td               | 0.00047416522 |\n",
            "| loss_td                 | 0.02216786    |\n",
            "| losses_all              | 0.006567872   |\n",
            "| max 100 episode reward  | 354           |\n",
            "| mean 100 episode reward | 27.8          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3044205       |\n",
            "-------------------------------------------\n",
            " 76% 3049551/4000000 [14:54:19<4:06:41, 64.21it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.085        |\n",
            "| elapsed time            | 15:10:33     |\n",
            "| episodes                | 3830         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033722506 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.016443552  |\n",
            "| losses_all              | 0.005346624  |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 25.8         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3049556      |\n",
            "------------------------------------------\n",
            " 76% 3054518/4000000 [14:55:50<4:10:15, 62.97it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0849        |\n",
            "| elapsed time            | 15:12:04      |\n",
            "| episodes                | 3840          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003378564   |\n",
            "| loss_margin             | 0.0018073991  |\n",
            "| loss_n_td               | 0.00032795375 |\n",
            "| loss_td                 | 0.005574566   |\n",
            "| losses_all              | 0.004427166   |\n",
            "| max 100 episode reward  | 354           |\n",
            "| mean 100 episode reward | 24.4          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3054518       |\n",
            "-------------------------------------------\n",
            " 77% 3060825/4000000 [14:57:41<4:08:30, 62.99it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0849       |\n",
            "| elapsed time            | 15:13:55     |\n",
            "| episodes                | 3850         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033829913 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.16772805   |\n",
            "| losses_all              | 0.011646606  |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 22.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3060825      |\n",
            "------------------------------------------\n",
            " 77% 3068962/4000000 [15:00:03<4:04:46, 63.39it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0848       |\n",
            "| elapsed time            | 15:16:17     |\n",
            "| episodes                | 3860         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033821864 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0013296183 |\n",
            "| loss_td                 | 0.011863148  |\n",
            "| losses_all              | 0.0048480853 |\n",
            "| max 100 episode reward  | 386          |\n",
            "| mean 100 episode reward | 28.3         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3068968      |\n",
            "------------------------------------------\n",
            " 77% 3077540/4000000 [15:02:30<4:01:55, 63.55it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0848       |\n",
            "| elapsed time            | 15:18:44     |\n",
            "| episodes                | 3870         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033861415 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.004716024  |\n",
            "| loss_td                 | 0.035968997  |\n",
            "| losses_all              | 0.007612598  |\n",
            "| max 100 episode reward  | 386          |\n",
            "| mean 100 episode reward | 34.6         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3077541      |\n",
            "------------------------------------------\n",
            " 77% 3087213/4000000 [15:05:16<4:03:57, 62.36it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0847       |\n",
            "| elapsed time            | 15:21:30     |\n",
            "| episodes                | 3880         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033896214 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.0096985325 |\n",
            "| losses_all              | 0.0045188395 |\n",
            "| max 100 episode reward  | 386          |\n",
            "| mean 100 episode reward | 35.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3087215      |\n",
            "------------------------------------------\n",
            " 77% 3094990/4000000 [15:07:31<4:04:31, 61.68it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0846        |\n",
            "| elapsed time            | 15:23:45      |\n",
            "| episodes                | 3890          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0033957122  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00081263855 |\n",
            "| loss_td                 | 0.008246339   |\n",
            "| losses_all              | 0.0046053305  |\n",
            "| max 100 episode reward  | 386           |\n",
            "| mean 100 episode reward | 35            |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3094995       |\n",
            "-------------------------------------------\n",
            " 77% 3099998/4000000 [15:08:58<4:15:22, 58.74it/s]saved checkpoint\n",
            " 78% 3103884/4000000 [15:10:06<3:57:43, 62.83it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0846        |\n",
            "| elapsed time            | 15:26:20      |\n",
            "| episodes                | 3900          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003403164   |\n",
            "| loss_margin             | 0.0024500042  |\n",
            "| loss_n_td               | 0.00049527455 |\n",
            "| loss_td                 | 0.22487308    |\n",
            "| losses_all              | 0.014197607   |\n",
            "| max 100 episode reward  | 386           |\n",
            "| mean 100 episode reward | 30.6          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3103884       |\n",
            "-------------------------------------------\n",
            " 78% 3110272/4000000 [15:11:59<3:58:43, 62.12it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0845       |\n",
            "| elapsed time            | 15:28:13     |\n",
            "| episodes                | 3910         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033931187 |\n",
            "| loss_margin             | 0.0013149083 |\n",
            "| loss_n_td               | 9.866916e-06 |\n",
            "| loss_td                 | 0.0072485525 |\n",
            "| losses_all              | 0.004928592  |\n",
            "| max 100 episode reward  | 386          |\n",
            "| mean 100 episode reward | 30.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3110273      |\n",
            "------------------------------------------\n",
            " 78% 3117037/4000000 [15:13:58<3:57:20, 62.00it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0845       |\n",
            "| elapsed time            | 15:30:12     |\n",
            "| episodes                | 3920         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033849825 |\n",
            "| loss_margin             | 0.00905899   |\n",
            "| loss_n_td               | 0.0011805135 |\n",
            "| loss_td                 | 0.008965726  |\n",
            "| losses_all              | 0.0053706765 |\n",
            "| max 100 episode reward  | 386          |\n",
            "| mean 100 episode reward | 29.9         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3117040      |\n",
            "------------------------------------------\n",
            " 78% 3123472/4000000 [15:15:53<3:50:45, 63.31it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0844       |\n",
            "| elapsed time            | 15:32:06     |\n",
            "| episodes                | 3930         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033867455 |\n",
            "| loss_margin             | 0.0138352215 |\n",
            "| loss_n_td               | 0.001758344  |\n",
            "| loss_td                 | 0.035058867  |\n",
            "| losses_all              | 0.008825085  |\n",
            "| max 100 episode reward  | 386          |\n",
            "| mean 100 episode reward | 32.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3123476      |\n",
            "------------------------------------------\n",
            " 78% 3127613/4000000 [15:17:06<3:54:41, 61.95it/s]saved best model\n",
            " 78% 3129353/4000000 [15:17:38<3:52:47, 62.34it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0844        |\n",
            "| elapsed time            | 15:33:52      |\n",
            "| episodes                | 3940          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0033786045  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00014350281 |\n",
            "| loss_td                 | 0.010088433   |\n",
            "| losses_all              | 0.0049618883  |\n",
            "| max 100 episode reward  | 409           |\n",
            "| mean 100 episode reward | 36.5          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3129357       |\n",
            "-------------------------------------------\n",
            " 78% 3137693/4000000 [15:20:03<3:48:55, 62.78it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0843       |\n",
            "| elapsed time            | 15:36:17     |\n",
            "| episodes                | 3950         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.00337657   |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0019697798 |\n",
            "| loss_td                 | 0.04177037   |\n",
            "| losses_all              | 0.010259012  |\n",
            "| max 100 episode reward  | 409          |\n",
            "| mean 100 episode reward | 36.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3137694      |\n",
            "------------------------------------------\n",
            " 79% 3144272/4000000 [15:21:59<3:48:17, 62.48it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0842       |\n",
            "| elapsed time            | 15:38:13     |\n",
            "| episodes                | 3960         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003371878  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0004539379 |\n",
            "| loss_td                 | 0.030591654  |\n",
            "| losses_all              | 0.007171991  |\n",
            "| max 100 episode reward  | 409          |\n",
            "| mean 100 episode reward | 32.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3144278      |\n",
            "------------------------------------------\n",
            " 79% 3150594/4000000 [15:23:51<3:41:23, 63.95it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0842        |\n",
            "| elapsed time            | 15:40:04      |\n",
            "| episodes                | 3970          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0033738597  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00073907664 |\n",
            "| loss_td                 | 0.020837707   |\n",
            "| losses_all              | 0.0059304913  |\n",
            "| max 100 episode reward  | 409           |\n",
            "| mean 100 episode reward | 29            |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3150597       |\n",
            "-------------------------------------------\n",
            " 79% 3165355/4000000 [15:27:58<3:45:07, 61.79it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0841       |\n",
            "| elapsed time            | 15:44:11     |\n",
            "| episodes                | 3980         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033610612 |\n",
            "| loss_margin             | 0.0038101822 |\n",
            "| loss_n_td               | 0.014860814  |\n",
            "| loss_td                 | 0.02885901   |\n",
            "| losses_all              | 0.0076197    |\n",
            "| max 100 episode reward  | 409          |\n",
            "| mean 100 episode reward | 38.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3165357      |\n",
            "------------------------------------------\n",
            " 79% 3173837/4000000 [15:30:25<3:36:17, 63.66it/s]--------------------------------------------\n",
            "| % time spent exploring  | 1              |\n",
            "| demo sample rate        | 0.084          |\n",
            "| elapsed time            | 15:46:39       |\n",
            "| episodes                | 3990           |\n",
            "| epsilon                 | 0.01           |\n",
            "| loss_l2                 | 0.0033529638   |\n",
            "| loss_margin             | 0.0067355745   |\n",
            "| loss_n_td               | 0.000101628226 |\n",
            "| loss_td                 | 0.0145088965   |\n",
            "| losses_all              | 0.006536885    |\n",
            "| max 100 episode reward  | 409            |\n",
            "| mean 100 episode reward | 40.4           |\n",
            "| min 100 episode reward  | 2              |\n",
            "| pre_train               | False          |\n",
            "| steps                   | 3173843        |\n",
            "--------------------------------------------\n",
            " 80% 3181877/4000000 [15:32:44<3:38:01, 62.54it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.084        |\n",
            "| elapsed time            | 15:48:58     |\n",
            "| episodes                | 4000         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033455633 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0020791981 |\n",
            "| loss_td                 | 0.03401847   |\n",
            "| losses_all              | 0.009801233  |\n",
            "| max 100 episode reward  | 409          |\n",
            "| mean 100 episode reward | 41.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3181880      |\n",
            "------------------------------------------\n",
            " 80% 3187364/4000000 [15:34:23<3:38:35, 61.96it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0839       |\n",
            "| elapsed time            | 15:50:37     |\n",
            "| episodes                | 4010         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033358312 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0007554505 |\n",
            "| loss_td                 | 0.019116415  |\n",
            "| losses_all              | 0.0058466494 |\n",
            "| max 100 episode reward  | 409          |\n",
            "| mean 100 episode reward | 40           |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3187368      |\n",
            "------------------------------------------\n",
            " 80% 3194330/4000000 [15:36:27<3:40:32, 60.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0839       |\n",
            "| elapsed time            | 15:52:41     |\n",
            "| episodes                | 4020         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033369316 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0038505495 |\n",
            "| loss_td                 | 0.0038813883 |\n",
            "| losses_all              | 0.0043202806 |\n",
            "| max 100 episode reward  | 409          |\n",
            "| mean 100 episode reward | 43.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3194331      |\n",
            "------------------------------------------\n",
            " 80% 3199997/4000000 [15:38:06<3:48:27, 58.36it/s]saved checkpoint\n",
            " 80% 3202459/4000000 [15:38:48<3:28:24, 63.78it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0838        |\n",
            "| elapsed time            | 15:55:02      |\n",
            "| episodes                | 4030          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0033289685  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 1.7064334e-05 |\n",
            "| loss_td                 | 0.019281432   |\n",
            "| losses_all              | 0.005346924   |\n",
            "| max 100 episode reward  | 409           |\n",
            "| mean 100 episode reward | 47.9          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3202462       |\n",
            "-------------------------------------------\n",
            " 80% 3210316/4000000 [15:41:06<3:30:31, 62.52it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0838        |\n",
            "| elapsed time            | 15:57:19      |\n",
            "| episodes                | 4040          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003317743   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 3.3661192e-05 |\n",
            "| loss_td                 | 0.01087959    |\n",
            "| losses_all              | 0.0047384733  |\n",
            "| max 100 episode reward  | 374           |\n",
            "| mean 100 episode reward | 46.8          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3210322       |\n",
            "-------------------------------------------\n",
            " 80% 3217091/4000000 [15:43:05<3:24:34, 63.78it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0837       |\n",
            "| elapsed time            | 15:59:19     |\n",
            "| episodes                | 4050         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033201042 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.018224038  |\n",
            "| losses_all              | 0.0060741147 |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 50.2         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3217093      |\n",
            "------------------------------------------\n",
            " 81% 3222091/4000000 [15:44:35<3:27:26, 62.50it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0837        |\n",
            "| elapsed time            | 16:00:49      |\n",
            "| episodes                | 4060          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0033181787  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00036179522 |\n",
            "| loss_td                 | 0.022586431   |\n",
            "| losses_all              | 0.005989031   |\n",
            "| max 100 episode reward  | 374           |\n",
            "| mean 100 episode reward | 48.2          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3222097       |\n",
            "-------------------------------------------\n",
            " 81% 3227898/4000000 [15:46:20<3:31:43, 60.78it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0837       |\n",
            "| elapsed time            | 16:02:34     |\n",
            "| episodes                | 4070         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0033014745 |\n",
            "| loss_margin             | 0.0012106672 |\n",
            "| loss_n_td               | 0.0007167933 |\n",
            "| loss_td                 | 0.013436221  |\n",
            "| losses_all              | 0.0057420544 |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 47.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3227904      |\n",
            "------------------------------------------\n",
            " 81% 3234777/4000000 [15:48:20<3:24:01, 62.51it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0836        |\n",
            "| elapsed time            | 16:04:34      |\n",
            "| episodes                | 4080          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032939822  |\n",
            "| loss_margin             | 0.011354186   |\n",
            "| loss_n_td               | 0.00059675204 |\n",
            "| loss_td                 | 0.007293765   |\n",
            "| losses_all              | 0.0055290633  |\n",
            "| max 100 episode reward  | 374           |\n",
            "| mean 100 episode reward | 36.9          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3234782       |\n",
            "-------------------------------------------\n",
            " 81% 3239920/4000000 [15:49:55<3:22:50, 62.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0836       |\n",
            "| elapsed time            | 16:06:09     |\n",
            "| episodes                | 4090         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032860662 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0014478229 |\n",
            "| loss_td                 | 0.0031053976 |\n",
            "| losses_all              | 0.0039256425 |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 35.6         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3239926      |\n",
            "------------------------------------------\n",
            " 81% 3247947/4000000 [15:52:16<3:18:29, 63.15it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0835       |\n",
            "| elapsed time            | 16:08:30     |\n",
            "| episodes                | 4100         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032876832 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.002143274  |\n",
            "| loss_td                 | 0.005795163  |\n",
            "| losses_all              | 0.004556753  |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 39.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3247951      |\n",
            "------------------------------------------\n",
            " 81% 3254877/4000000 [15:54:17<3:19:39, 62.20it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0835       |\n",
            "| elapsed time            | 16:10:31     |\n",
            "| episodes                | 4110         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032938265 |\n",
            "| loss_margin             | 0.0027881004 |\n",
            "| loss_n_td               | 0.0042128894 |\n",
            "| loss_td                 | 0.0038647125 |\n",
            "| losses_all              | 0.00437494   |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 39.6         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3254878      |\n",
            "------------------------------------------\n",
            " 82% 3260239/4000000 [15:55:55<3:14:20, 63.44it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0834        |\n",
            "| elapsed time            | 16:12:09      |\n",
            "| episodes                | 4120          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032911228  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 2.9425519e-05 |\n",
            "| loss_td                 | 0.018114807   |\n",
            "| losses_all              | 0.0059772134  |\n",
            "| max 100 episode reward  | 374           |\n",
            "| mean 100 episode reward | 36.2          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3260240       |\n",
            "-------------------------------------------\n",
            " 82% 3267174/4000000 [15:57:57<3:17:04, 61.97it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0834       |\n",
            "| elapsed time            | 16:14:11     |\n",
            "| episodes                | 4130         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003290433  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0003887275 |\n",
            "| loss_td                 | 0.02656996   |\n",
            "| losses_all              | 0.0072342334 |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 29.9         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3267180      |\n",
            "------------------------------------------\n",
            " 82% 3273902/4000000 [15:59:55<3:15:24, 61.93it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0834       |\n",
            "| elapsed time            | 16:16:09     |\n",
            "| episodes                | 4140         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032860287 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.013077598  |\n",
            "| losses_all              | 0.005165457  |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 27.3         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3273903      |\n",
            "------------------------------------------\n",
            " 82% 3284471/4000000 [16:02:55<3:10:30, 62.60it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0833       |\n",
            "| elapsed time            | 16:19:09     |\n",
            "| episodes                | 4150         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032793349 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010123403 |\n",
            "| loss_td                 | 0.014006507  |\n",
            "| losses_all              | 0.0048570177 |\n",
            "| max 100 episode reward  | 339          |\n",
            "| mean 100 episode reward | 27.3         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3284477      |\n",
            "------------------------------------------\n",
            " 82% 3292220/4000000 [16:05:10<3:08:22, 62.62it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0832       |\n",
            "| elapsed time            | 16:21:24     |\n",
            "| episodes                | 4160         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032785777 |\n",
            "| loss_margin             | 0.0149294585 |\n",
            "| loss_n_td               | 0.0020298345 |\n",
            "| loss_td                 | 0.011597727  |\n",
            "| losses_all              | 0.006198526  |\n",
            "| max 100 episode reward  | 339          |\n",
            "| mean 100 episode reward | 27.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3292226      |\n",
            "------------------------------------------\n",
            " 82% 3300000/4000000 [16:07:25<7:04:47, 27.46it/s]saved checkpoint\n",
            " 83% 3302055/4000000 [16:08:00<3:13:42, 60.05it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0832       |\n",
            "| elapsed time            | 16:24:14     |\n",
            "| episodes                | 4170         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032711152 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.14194362   |\n",
            "| losses_all              | 0.011320078  |\n",
            "| max 100 episode reward  | 339          |\n",
            "| mean 100 episode reward | 26.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3302060      |\n",
            "------------------------------------------\n",
            " 83% 3309312/4000000 [16:10:08<3:02:47, 62.98it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0831       |\n",
            "| elapsed time            | 16:26:22     |\n",
            "| episodes                | 4180         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032643187 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0006320242 |\n",
            "| loss_td                 | 0.0358252    |\n",
            "| losses_all              | 0.007450046  |\n",
            "| max 100 episode reward  | 339          |\n",
            "| mean 100 episode reward | 27.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3309317      |\n",
            "------------------------------------------\n",
            " 83% 3313924/4000000 [16:11:34<3:03:39, 62.26it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0831        |\n",
            "| elapsed time            | 16:27:48      |\n",
            "| episodes                | 4190          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032647788  |\n",
            "| loss_margin             | 0.0012821406  |\n",
            "| loss_n_td               | 0.00092113443 |\n",
            "| loss_td                 | 0.0049865786  |\n",
            "| losses_all              | 0.0044828914  |\n",
            "| max 100 episode reward  | 339           |\n",
            "| mean 100 episode reward | 26.8          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3313925       |\n",
            "-------------------------------------------\n",
            " 83% 3320084/4000000 [16:13:23<3:02:54, 61.96it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.083        |\n",
            "| elapsed time            | 16:29:37     |\n",
            "| episodes                | 4200         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003256579  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0012218052 |\n",
            "| loss_td                 | 0.024610996  |\n",
            "| losses_all              | 0.0060163047 |\n",
            "| max 100 episode reward  | 339          |\n",
            "| mean 100 episode reward | 22.9         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3320084      |\n",
            "------------------------------------------\n",
            " 83% 3326333/4000000 [16:15:14<3:03:44, 61.11it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.083       |\n",
            "| elapsed time            | 16:31:28    |\n",
            "| episodes                | 4210        |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.003255484 |\n",
            "| loss_margin             | 0.029859453 |\n",
            "| loss_n_td               | 0.010204647 |\n",
            "| loss_td                 | 0.04842816  |\n",
            "| losses_all              | 0.010784622 |\n",
            "| max 100 episode reward  | 339         |\n",
            "| mean 100 episode reward | 23.3        |\n",
            "| min 100 episode reward  | 3           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 3326338     |\n",
            "-----------------------------------------\n",
            " 83% 3334718/4000000 [16:17:41<3:05:50, 59.66it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.083        |\n",
            "| elapsed time            | 16:33:55     |\n",
            "| episodes                | 4220         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032491365 |\n",
            "| loss_margin             | 0.0059705526 |\n",
            "| loss_n_td               | 0.0031607952 |\n",
            "| loss_td                 | 0.0077670575 |\n",
            "| losses_all              | 0.0047342577 |\n",
            "| max 100 episode reward  | 339          |\n",
            "| mean 100 episode reward | 24.1         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3334721      |\n",
            "------------------------------------------\n",
            " 84% 3342690/4000000 [16:20:01<2:58:07, 61.50it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0829        |\n",
            "| elapsed time            | 16:36:15      |\n",
            "| episodes                | 4230          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032495526  |\n",
            "| loss_margin             | 0.029648125   |\n",
            "| loss_n_td               | 0.00026247546 |\n",
            "| loss_td                 | 0.017244134   |\n",
            "| losses_all              | 0.0073663383  |\n",
            "| max 100 episode reward  | 339           |\n",
            "| mean 100 episode reward | 24.5          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3342696       |\n",
            "-------------------------------------------\n",
            " 84% 3350369/4000000 [16:22:17<2:56:27, 61.36it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0829        |\n",
            "| elapsed time            | 16:38:31      |\n",
            "| episodes                | 4240          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032463952  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 4.0330204e-05 |\n",
            "| loss_td                 | 0.0696322     |\n",
            "| losses_all              | 0.01014347    |\n",
            "| max 100 episode reward  | 339           |\n",
            "| mean 100 episode reward | 24.5          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3350373       |\n",
            "-------------------------------------------\n",
            " 84% 3356339/4000000 [16:24:05<2:55:25, 61.15it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0828       |\n",
            "| elapsed time            | 16:40:18     |\n",
            "| episodes                | 4250         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032424245 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010502726 |\n",
            "| loss_td                 | 0.010641783  |\n",
            "| losses_all              | 0.0050076013 |\n",
            "| max 100 episode reward  | 173          |\n",
            "| mean 100 episode reward | 21.9         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3356345      |\n",
            "------------------------------------------\n",
            " 84% 3362969/4000000 [16:26:02<2:49:48, 62.52it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0828       |\n",
            "| elapsed time            | 16:42:16     |\n",
            "| episodes                | 4260         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032369595 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 8.769471e-05 |\n",
            "| loss_td                 | 0.022912387  |\n",
            "| losses_all              | 0.0049106986 |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 25           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3362971      |\n",
            "------------------------------------------\n",
            " 84% 3371418/4000000 [16:28:29<2:46:29, 62.93it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0827       |\n",
            "| elapsed time            | 16:44:43     |\n",
            "| episodes                | 4270         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032291552 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0023488144 |\n",
            "| loss_td                 | 0.03814424   |\n",
            "| losses_all              | 0.00785457   |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 25.2         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3371420      |\n",
            "------------------------------------------\n",
            " 84% 3378775/4000000 [16:30:38<2:51:00, 60.54it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0827       |\n",
            "| elapsed time            | 16:46:51     |\n",
            "| episodes                | 4280         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032195123 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.023618639  |\n",
            "| losses_all              | 0.0056983875 |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 24.1         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3378778      |\n",
            "------------------------------------------\n",
            " 85% 3388918/4000000 [16:33:31<2:44:22, 61.96it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0826       |\n",
            "| elapsed time            | 16:49:45     |\n",
            "| episodes                | 4290         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032193975 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0009929406 |\n",
            "| loss_td                 | 0.049504817  |\n",
            "| losses_all              | 0.006112648  |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 24.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3388919      |\n",
            "------------------------------------------\n",
            " 85% 3396529/4000000 [16:35:43<2:37:18, 63.94it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0826        |\n",
            "| elapsed time            | 16:51:56      |\n",
            "| episodes                | 4300          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032109166  |\n",
            "| loss_margin             | 0.014713891   |\n",
            "| loss_n_td               | 0.00014401703 |\n",
            "| loss_td                 | 0.008642374   |\n",
            "| losses_all              | 0.0053240443  |\n",
            "| max 100 episode reward  | 354           |\n",
            "| mean 100 episode reward | 26.6          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3396532       |\n",
            "-------------------------------------------\n",
            " 85% 3399996/4000000 [16:36:44<3:53:03, 42.91it/s]saved checkpoint\n",
            " 85% 3404198/4000000 [16:38:00<2:42:02, 61.28it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0825       |\n",
            "| elapsed time            | 16:54:14     |\n",
            "| episodes                | 4310         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032096936 |\n",
            "| loss_margin             | 0.0016937926 |\n",
            "| loss_n_td               | 0.0010730138 |\n",
            "| loss_td                 | 0.00398039   |\n",
            "| losses_all              | 0.004125066  |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 30.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3404203      |\n",
            "------------------------------------------\n",
            " 85% 3413519/4000000 [16:40:43<2:39:22, 61.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0825       |\n",
            "| elapsed time            | 16:56:57     |\n",
            "| episodes                | 4320         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032047622 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010495164 |\n",
            "| loss_td                 | 0.036717772  |\n",
            "| losses_all              | 0.0069634067 |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 31.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3413519      |\n",
            "------------------------------------------\n",
            " 86% 3420971/4000000 [16:42:56<2:37:57, 61.10it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0824        |\n",
            "| elapsed time            | 16:59:10      |\n",
            "| episodes                | 4330          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003199847   |\n",
            "| loss_margin             | 0.00086410344 |\n",
            "| loss_n_td               | 0.0007232419  |\n",
            "| loss_td                 | 0.01129939    |\n",
            "| losses_all              | 0.0048767272  |\n",
            "| max 100 episode reward  | 354           |\n",
            "| mean 100 episode reward | 30.4          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3420973       |\n",
            "-------------------------------------------\n",
            " 86% 3428497/4000000 [16:45:08<2:34:40, 61.58it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0824        |\n",
            "| elapsed time            | 17:01:22      |\n",
            "| episodes                | 4340          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003191847   |\n",
            "| loss_margin             | 0.00405588    |\n",
            "| loss_n_td               | 2.4791177e-07 |\n",
            "| loss_td                 | 0.06187734    |\n",
            "| losses_all              | 0.011285918   |\n",
            "| max 100 episode reward  | 354           |\n",
            "| mean 100 episode reward | 29.7          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3428502       |\n",
            "-------------------------------------------\n",
            " 86% 3435584/4000000 [16:47:14<2:32:28, 61.69it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0824       |\n",
            "| elapsed time            | 17:03:28     |\n",
            "| episodes                | 4350         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031922918 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0003733835 |\n",
            "| loss_td                 | 0.014193343  |\n",
            "| losses_all              | 0.00508899   |\n",
            "| max 100 episode reward  | 354          |\n",
            "| mean 100 episode reward | 28.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3435589      |\n",
            "------------------------------------------\n",
            " 86% 3442332/4000000 [16:49:15<2:30:22, 61.81it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0823       |\n",
            "| elapsed time            | 17:05:28     |\n",
            "| episodes                | 4360         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031887938 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0022420292 |\n",
            "| loss_td                 | 0.012022192  |\n",
            "| losses_all              | 0.005064216  |\n",
            "| max 100 episode reward  | 339          |\n",
            "| mean 100 episode reward | 24.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3442332      |\n",
            "------------------------------------------\n",
            " 86% 3450104/4000000 [16:51:31<2:26:59, 62.35it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0823       |\n",
            "| elapsed time            | 17:07:45     |\n",
            "| episodes                | 4370         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031819318 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.01413187   |\n",
            "| losses_all              | 0.005967987  |\n",
            "| max 100 episode reward  | 339          |\n",
            "| mean 100 episode reward | 23.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3450104      |\n",
            "------------------------------------------\n",
            " 86% 3455005/4000000 [16:53:03<2:28:27, 61.18it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0822      |\n",
            "| elapsed time            | 17:09:16    |\n",
            "| episodes                | 4380        |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.003179539 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.0         |\n",
            "| loss_td                 | 0.033002265 |\n",
            "| losses_all              | 0.021168046 |\n",
            "| max 100 episode reward  | 339         |\n",
            "| mean 100 episode reward | 23.1        |\n",
            "| min 100 episode reward  | 2           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 3455011     |\n",
            "-----------------------------------------\n",
            " 87% 3461120/4000000 [16:54:52<2:26:50, 61.16it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0822       |\n",
            "| elapsed time            | 17:11:06     |\n",
            "| episodes                | 4390         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031773236 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 4.952799e-06 |\n",
            "| loss_td                 | 0.05853175   |\n",
            "| losses_all              | 0.006802953  |\n",
            "| max 100 episode reward  | 339          |\n",
            "| mean 100 episode reward | 23.2         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3461121      |\n",
            "------------------------------------------\n",
            " 87% 3468203/4000000 [16:56:58<2:32:03, 58.29it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0822        |\n",
            "| elapsed time            | 17:13:12      |\n",
            "| episodes                | 4400          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003174229   |\n",
            "| loss_margin             | 0.0031789467  |\n",
            "| loss_n_td               | 0.00041866465 |\n",
            "| loss_td                 | 0.003874251   |\n",
            "| losses_all              | 0.00408776    |\n",
            "| max 100 episode reward  | 339           |\n",
            "| mean 100 episode reward | 21.7          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3468207       |\n",
            "-------------------------------------------\n",
            " 87% 3477260/4000000 [16:59:36<2:17:42, 63.27it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0821        |\n",
            "| elapsed time            | 17:15:50      |\n",
            "| episodes                | 4410          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031695203  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00042136334 |\n",
            "| loss_td                 | 0.019569138   |\n",
            "| losses_all              | 0.0058283787  |\n",
            "| max 100 episode reward  | 375           |\n",
            "| mean 100 episode reward | 29.7          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3477264       |\n",
            "-------------------------------------------\n",
            " 87% 3484032/4000000 [17:01:36<2:18:25, 62.12it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0821        |\n",
            "| elapsed time            | 17:17:50      |\n",
            "| episodes                | 4420          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031665917  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 5.7562353e-05 |\n",
            "| loss_td                 | 0.04161386    |\n",
            "| losses_all              | 0.0084563615  |\n",
            "| max 100 episode reward  | 375           |\n",
            "| mean 100 episode reward | 30.1          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3484037       |\n",
            "-------------------------------------------\n",
            " 87% 3491269/4000000 [17:03:45<2:19:39, 60.71it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.082        |\n",
            "| elapsed time            | 17:19:59     |\n",
            "| episodes                | 4430         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031661065 |\n",
            "| loss_margin             | 0.027265403  |\n",
            "| loss_n_td               | 0.0019827613 |\n",
            "| loss_td                 | 0.013588252  |\n",
            "| losses_all              | 0.006224991  |\n",
            "| max 100 episode reward  | 375          |\n",
            "| mean 100 episode reward | 32.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3491270      |\n",
            "------------------------------------------\n",
            " 87% 3497113/4000000 [17:05:30<2:19:27, 60.10it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.082       |\n",
            "| elapsed time            | 17:21:44    |\n",
            "| episodes                | 4440        |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.003156458 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.0         |\n",
            "| loss_td                 | 0.040908895 |\n",
            "| losses_all              | 0.005793415 |\n",
            "| max 100 episode reward  | 375         |\n",
            "| mean 100 episode reward | 33.9        |\n",
            "| min 100 episode reward  | 3           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 3497117     |\n",
            "-----------------------------------------\n",
            " 87% 3499996/4000000 [17:06:20<2:18:34, 60.14it/s]saved checkpoint\n",
            " 88% 3506580/4000000 [17:08:15<2:11:41, 62.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.082        |\n",
            "| elapsed time            | 17:24:29     |\n",
            "| episodes                | 4450         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003172162  |\n",
            "| loss_margin             | 0.0043621063 |\n",
            "| loss_n_td               | 0.0013260313 |\n",
            "| loss_td                 | 0.011737215  |\n",
            "| losses_all              | 0.0045847613 |\n",
            "| max 100 episode reward  | 375          |\n",
            "| mean 100 episode reward | 35.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3506580      |\n",
            "------------------------------------------\n",
            " 88% 3516736/4000000 [17:11:10<2:11:40, 61.17it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0819       |\n",
            "| elapsed time            | 17:27:24     |\n",
            "| episodes                | 4460         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003189431  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0011280157 |\n",
            "| loss_td                 | 0.014140969  |\n",
            "| losses_all              | 0.0048252535 |\n",
            "| max 100 episode reward  | 375          |\n",
            "| mean 100 episode reward | 35.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3516737      |\n",
            "------------------------------------------\n",
            " 88% 3522743/4000000 [17:12:58<2:09:27, 61.44it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0819        |\n",
            "| elapsed time            | 17:29:12      |\n",
            "| episodes                | 4470          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031887915  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 1.8558224e-07 |\n",
            "| loss_td                 | 0.02256454    |\n",
            "| losses_all              | 0.005667816   |\n",
            "| max 100 episode reward  | 375           |\n",
            "| mean 100 episode reward | 35.3          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3522744       |\n",
            "-------------------------------------------\n",
            " 88% 3529995/4000000 [17:15:07<2:09:21, 60.56it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0818        |\n",
            "| elapsed time            | 17:31:21      |\n",
            "| episodes                | 4480          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003185131   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00059950317 |\n",
            "| loss_td                 | 0.0119329635  |\n",
            "| losses_all              | 0.0051562865  |\n",
            "| max 100 episode reward  | 375           |\n",
            "| mean 100 episode reward | 39.7          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3530001       |\n",
            "-------------------------------------------\n",
            " 88% 3538649/4000000 [17:17:38<2:06:57, 60.56it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0818       |\n",
            "| elapsed time            | 17:33:52     |\n",
            "| episodes                | 4490         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031781138 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0036188166 |\n",
            "| loss_td                 | 0.016411316  |\n",
            "| losses_all              | 0.005049485  |\n",
            "| max 100 episode reward  | 375          |\n",
            "| mean 100 episode reward | 40           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3538652      |\n",
            "------------------------------------------\n",
            " 89% 3544210/4000000 [17:19:18<2:01:54, 62.31it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0817       |\n",
            "| elapsed time            | 17:35:32     |\n",
            "| episodes                | 4500         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031828093 |\n",
            "| loss_margin             | 0.0026601553 |\n",
            "| loss_n_td               | 0.0010015533 |\n",
            "| loss_td                 | 0.00661179   |\n",
            "| losses_all              | 0.004368029  |\n",
            "| max 100 episode reward  | 375          |\n",
            "| mean 100 episode reward | 39.1         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3544216      |\n",
            "------------------------------------------\n",
            " 89% 3552368/4000000 [17:21:40<1:58:47, 62.81it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0817        |\n",
            "| elapsed time            | 17:37:54      |\n",
            "| episodes                | 4510          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003178577   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00042102055 |\n",
            "| loss_td                 | 0.007700959   |\n",
            "| losses_all              | 0.0042722262  |\n",
            "| max 100 episode reward  | 341           |\n",
            "| mean 100 episode reward | 27.5          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3552368       |\n",
            "-------------------------------------------\n",
            " 89% 3560533/4000000 [17:24:03<1:57:15, 62.47it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0817        |\n",
            "| elapsed time            | 17:40:17      |\n",
            "| episodes                | 4520          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031776493  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00011399854 |\n",
            "| loss_td                 | 0.010710144   |\n",
            "| losses_all              | 0.0077058747  |\n",
            "| max 100 episode reward  | 341           |\n",
            "| mean 100 episode reward | 25.8          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3560537       |\n",
            "-------------------------------------------\n",
            " 89% 3567596/4000000 [17:26:07<1:55:05, 62.62it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0816       |\n",
            "| elapsed time            | 17:42:21     |\n",
            "| episodes                | 4530         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003171384  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0007509023 |\n",
            "| loss_td                 | 0.005469444  |\n",
            "| losses_all              | 0.004016325  |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 24           |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3567602      |\n",
            "------------------------------------------\n",
            " 89% 3574672/4000000 [17:28:11<1:51:34, 63.53it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0816       |\n",
            "| elapsed time            | 17:44:25     |\n",
            "| episodes                | 4540         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031730463 |\n",
            "| loss_margin             | 0.031340223  |\n",
            "| loss_n_td               | 0.0022575287 |\n",
            "| loss_td                 | 0.023914963  |\n",
            "| losses_all              | 0.007513398  |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 23.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3574677      |\n",
            "------------------------------------------\n",
            " 90% 3582444/4000000 [17:30:26<1:52:07, 62.07it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0815        |\n",
            "| elapsed time            | 17:46:40      |\n",
            "| episodes                | 4550          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003172689   |\n",
            "| loss_margin             | 0.001112774   |\n",
            "| loss_n_td               | 0.00042269996 |\n",
            "| loss_td                 | 0.011227996   |\n",
            "| losses_all              | 0.0049856002  |\n",
            "| max 100 episode reward  | 341           |\n",
            "| mean 100 episode reward | 22.6          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3582450       |\n",
            "-------------------------------------------\n",
            " 90% 3589022/4000000 [17:32:22<1:50:12, 62.16it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0815       |\n",
            "| elapsed time            | 17:48:36     |\n",
            "| episodes                | 4560         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031667117 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.001170307  |\n",
            "| loss_td                 | 0.018353933  |\n",
            "| losses_all              | 0.005095696  |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 22.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3589022      |\n",
            "------------------------------------------\n",
            " 90% 3599178/4000000 [17:35:16<1:47:10, 62.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0814       |\n",
            "| elapsed time            | 17:51:30     |\n",
            "| episodes                | 4570         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031672255 |\n",
            "| loss_margin             | 0.0127795935 |\n",
            "| loss_n_td               | 5.017877e-06 |\n",
            "| loss_td                 | 0.01562691   |\n",
            "| losses_all              | 0.0057705794 |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 23.8         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3599181      |\n",
            "------------------------------------------\n",
            " 90% 3599997/4000000 [17:35:30<1:46:38, 62.51it/s]saved checkpoint\n",
            " 90% 3606939/4000000 [17:37:31<1:43:59, 63.00it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0814        |\n",
            "| elapsed time            | 17:53:45      |\n",
            "| episodes                | 4580          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003175327   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00021010892 |\n",
            "| loss_td                 | 0.053058565   |\n",
            "| losses_all              | 0.007890525   |\n",
            "| max 100 episode reward  | 155           |\n",
            "| mean 100 episode reward | 21.5          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3606941       |\n",
            "-------------------------------------------\n",
            " 90% 3612980/4000000 [17:39:19<1:45:07, 61.36it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0814        |\n",
            "| elapsed time            | 17:55:33      |\n",
            "| episodes                | 4590          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031823162  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 2.2279548e-05 |\n",
            "| loss_td                 | 0.15518412    |\n",
            "| losses_all              | 0.013120941   |\n",
            "| max 100 episode reward  | 155           |\n",
            "| mean 100 episode reward | 20.8          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3612983       |\n",
            "-------------------------------------------\n",
            " 91% 3621914/4000000 [17:41:52<1:43:26, 60.91it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0813       |\n",
            "| elapsed time            | 17:58:06     |\n",
            "| episodes                | 4600         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003175573  |\n",
            "| loss_margin             | 0.0042129233 |\n",
            "| loss_n_td               | 0.000688476  |\n",
            "| loss_td                 | 0.18346536   |\n",
            "| losses_all              | 0.0122773    |\n",
            "| max 100 episode reward  | 155          |\n",
            "| mean 100 episode reward | 20.7         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3621914      |\n",
            "------------------------------------------\n",
            " 91% 3629150/4000000 [17:43:59<1:37:44, 63.23it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0813       |\n",
            "| elapsed time            | 18:00:13     |\n",
            "| episodes                | 4610         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031696202 |\n",
            "| loss_margin             | 0.002925314  |\n",
            "| loss_n_td               | 0.003194442  |\n",
            "| loss_td                 | 0.028586328  |\n",
            "| losses_all              | 0.005863837  |\n",
            "| max 100 episode reward  | 155          |\n",
            "| mean 100 episode reward | 20.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3629156      |\n",
            "------------------------------------------\n",
            " 91% 3635702/4000000 [17:45:55<1:39:20, 61.12it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0813       |\n",
            "| elapsed time            | 18:02:08     |\n",
            "| episodes                | 4620         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031749744 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.001857759  |\n",
            "| loss_td                 | 0.029110122  |\n",
            "| losses_all              | 0.0062972177 |\n",
            "| max 100 episode reward  | 221          |\n",
            "| mean 100 episode reward | 22.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3635702      |\n",
            "------------------------------------------\n",
            " 91% 3643430/4000000 [17:48:09<1:32:35, 64.18it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0812        |\n",
            "| elapsed time            | 18:04:23      |\n",
            "| episodes                | 4630          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031719548  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00025934307 |\n",
            "| loss_td                 | 0.04827866    |\n",
            "| losses_all              | 0.0070508937  |\n",
            "| max 100 episode reward  | 221           |\n",
            "| mean 100 episode reward | 23            |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3643433       |\n",
            "-------------------------------------------\n",
            " 91% 3649455/4000000 [17:49:56<1:34:29, 61.83it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0812        |\n",
            "| elapsed time            | 18:06:10      |\n",
            "| episodes                | 4640          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031637133  |\n",
            "| loss_margin             | 0.00037812442 |\n",
            "| loss_n_td               | 0.00089503394 |\n",
            "| loss_td                 | 0.021029018   |\n",
            "| losses_all              | 0.006841679   |\n",
            "| max 100 episode reward  | 221           |\n",
            "| mean 100 episode reward | 22.4          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3649458       |\n",
            "-------------------------------------------\n",
            " 91% 3654689/4000000 [17:51:31<1:30:19, 63.71it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0812        |\n",
            "| elapsed time            | 18:07:44      |\n",
            "| episodes                | 4650          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003163288   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00054563023 |\n",
            "| loss_td                 | 0.017181044   |\n",
            "| losses_all              | 0.004894075   |\n",
            "| max 100 episode reward  | 221           |\n",
            "| mean 100 episode reward | 21.4          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3654690       |\n",
            "-------------------------------------------\n",
            " 92% 3660927/4000000 [17:53:21<1:30:12, 62.64it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0811        |\n",
            "| elapsed time            | 18:09:35      |\n",
            "| episodes                | 4660          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031601388  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00015747885 |\n",
            "| loss_td                 | 0.06695513    |\n",
            "| losses_all              | 0.007394109   |\n",
            "| max 100 episode reward  | 390           |\n",
            "| mean 100 episode reward | 26            |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3660929       |\n",
            "-------------------------------------------\n",
            " 92% 3667670/4000000 [17:55:20<1:29:34, 61.84it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0811        |\n",
            "| elapsed time            | 18:11:34      |\n",
            "| episodes                | 4670          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031639456  |\n",
            "| loss_margin             | 0.0011247322  |\n",
            "| loss_n_td               | 2.4292412e-05 |\n",
            "| loss_td                 | 0.010127753   |\n",
            "| losses_all              | 0.0049909847  |\n",
            "| max 100 episode reward  | 390           |\n",
            "| mean 100 episode reward | 25.3          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3667673       |\n",
            "-------------------------------------------\n",
            " 92% 3677636/4000000 [17:58:10<1:24:54, 63.28it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.081         |\n",
            "| elapsed time            | 18:14:24      |\n",
            "| episodes                | 4680          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031541607  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00023649521 |\n",
            "| loss_td                 | 0.023548974   |\n",
            "| losses_all              | 0.005898786   |\n",
            "| max 100 episode reward  | 390           |\n",
            "| mean 100 episode reward | 24.7          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3677637       |\n",
            "-------------------------------------------\n",
            " 92% 3683375/4000000 [17:59:52<1:32:20, 57.15it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.081         |\n",
            "| elapsed time            | 18:16:06      |\n",
            "| episodes                | 4690          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031557698  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 5.6810073e-05 |\n",
            "| loss_td                 | 0.010182413   |\n",
            "| losses_all              | 0.0053408025  |\n",
            "| max 100 episode reward  | 390           |\n",
            "| mean 100 episode reward | 24.4          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3683375       |\n",
            "-------------------------------------------\n",
            " 92% 3691957/4000000 [18:02:20<1:21:31, 62.97it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.081         |\n",
            "| elapsed time            | 18:18:34      |\n",
            "| episodes                | 4700          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031538995  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00087986095 |\n",
            "| loss_td                 | 0.0065907985  |\n",
            "| losses_all              | 0.003987005   |\n",
            "| max 100 episode reward  | 390           |\n",
            "| mean 100 episode reward | 27.9          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3691961       |\n",
            "-------------------------------------------\n",
            " 92% 3699574/4000000 [18:04:33<1:18:27, 63.82it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0809        |\n",
            "| elapsed time            | 18:20:47      |\n",
            "| episodes                | 4710          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031370556  |\n",
            "| loss_margin             | 0.0057454035  |\n",
            "| loss_n_td               | 0.00013066456 |\n",
            "| loss_td                 | 0.009439945   |\n",
            "| losses_all              | 0.004637449   |\n",
            "| max 100 episode reward  | 390           |\n",
            "| mean 100 episode reward | 28.1          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3699579       |\n",
            "-------------------------------------------\n",
            " 92% 3699994/4000000 [18:04:41<1:19:38, 62.78it/s]saved checkpoint\n",
            " 93% 3706961/4000000 [18:06:42<1:18:32, 62.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0809       |\n",
            "| elapsed time            | 18:22:56     |\n",
            "| episodes                | 4720         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031392896 |\n",
            "| loss_margin             | 0.028569348  |\n",
            "| loss_n_td               | 0.001291594  |\n",
            "| loss_td                 | 0.008334193  |\n",
            "| losses_all              | 0.005745407  |\n",
            "| max 100 episode reward  | 390          |\n",
            "| mean 100 episode reward | 26.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3706962      |\n",
            "------------------------------------------\n",
            " 93% 3715483/4000000 [18:09:10<1:17:03, 61.53it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0808       |\n",
            "| elapsed time            | 18:25:24     |\n",
            "| episodes                | 4730         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031331533 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0019433008 |\n",
            "| loss_td                 | 0.008115284  |\n",
            "| losses_all              | 0.0042648083 |\n",
            "| max 100 episode reward  | 390          |\n",
            "| mean 100 episode reward | 30           |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3715489      |\n",
            "------------------------------------------\n",
            " 93% 3721779/4000000 [18:11:02<1:13:41, 62.93it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0808       |\n",
            "| elapsed time            | 18:27:15     |\n",
            "| episodes                | 4740         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031323517 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010175987 |\n",
            "| loss_td                 | 0.010880958  |\n",
            "| losses_all              | 0.0041767783 |\n",
            "| max 100 episode reward  | 390          |\n",
            "| mean 100 episode reward | 29.8         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3721785      |\n",
            "------------------------------------------\n",
            " 93% 3728465/4000000 [18:12:59<1:13:39, 61.44it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0808       |\n",
            "| elapsed time            | 18:29:13     |\n",
            "| episodes                | 4750         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031235272 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0004971542 |\n",
            "| loss_td                 | 0.03190884   |\n",
            "| losses_all              | 0.006490509  |\n",
            "| max 100 episode reward  | 390          |\n",
            "| mean 100 episode reward | 31.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3728470      |\n",
            "------------------------------------------\n",
            " 93% 3734335/4000000 [18:14:44<1:09:54, 63.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0807       |\n",
            "| elapsed time            | 18:30:58     |\n",
            "| episodes                | 4760         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031221267 |\n",
            "| loss_margin             | 0.0016074553 |\n",
            "| loss_n_td               | 0.0014332556 |\n",
            "| loss_td                 | 0.007950139  |\n",
            "| losses_all              | 0.004400796  |\n",
            "| max 100 episode reward  | 355          |\n",
            "| mean 100 episode reward | 28.2         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3734340      |\n",
            "------------------------------------------\n",
            " 94% 3744429/4000000 [18:17:36<1:08:06, 62.54it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0807       |\n",
            "| elapsed time            | 18:33:50     |\n",
            "| episodes                | 4770         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031147795 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.057739235  |\n",
            "| losses_all              | 0.006887572  |\n",
            "| max 100 episode reward  | 355          |\n",
            "| mean 100 episode reward | 34           |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3744433      |\n",
            "------------------------------------------\n",
            " 94% 3750478/4000000 [18:19:24<1:10:20, 59.12it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0807       |\n",
            "| elapsed time            | 18:35:38     |\n",
            "| episodes                | 4780         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003120504  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0036278295 |\n",
            "| loss_td                 | 0.019110491  |\n",
            "| losses_all              | 0.005139229  |\n",
            "| max 100 episode reward  | 369          |\n",
            "| mean 100 episode reward | 37           |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3750484      |\n",
            "------------------------------------------\n",
            " 94% 3756399/4000000 [18:21:09<1:04:19, 63.11it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0806        |\n",
            "| elapsed time            | 18:37:23      |\n",
            "| episodes                | 4790          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031165434  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00039496305 |\n",
            "| loss_td                 | 0.032041885   |\n",
            "| losses_all              | 0.0055814097  |\n",
            "| max 100 episode reward  | 369           |\n",
            "| mean 100 episode reward | 39.2          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3756401       |\n",
            "-------------------------------------------\n",
            " 94% 3761606/4000000 [18:22:43<1:02:26, 63.63it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0806       |\n",
            "| elapsed time            | 18:38:57     |\n",
            "| episodes                | 4800         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031229663 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.003937413  |\n",
            "| loss_td                 | 0.01157338   |\n",
            "| losses_all              | 0.004417097  |\n",
            "| max 100 episode reward  | 369          |\n",
            "| mean 100 episode reward | 38.6         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3761606      |\n",
            "------------------------------------------\n",
            " 94% 3767046/4000000 [18:24:21<1:01:19, 63.31it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0806        |\n",
            "| elapsed time            | 18:40:35      |\n",
            "| episodes                | 4810          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031174696  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00057129597 |\n",
            "| loss_td                 | 0.033049706   |\n",
            "| losses_all              | 0.0058071855  |\n",
            "| max 100 episode reward  | 369           |\n",
            "| mean 100 episode reward | 38.8          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3767046       |\n",
            "-------------------------------------------\n",
            " 94% 3772986/4000000 [18:26:08<59:41, 63.38it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0806       |\n",
            "| elapsed time            | 18:42:22     |\n",
            "| episodes                | 4820         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031170647 |\n",
            "| loss_margin             | 2.733618e-05 |\n",
            "| loss_n_td               | 0.0039645345 |\n",
            "| loss_td                 | 0.020020418  |\n",
            "| losses_all              | 0.0055270074 |\n",
            "| max 100 episode reward  | 369          |\n",
            "| mean 100 episode reward | 38.2         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3772989      |\n",
            "------------------------------------------\n",
            " 95% 3781983/4000000 [18:28:42<57:20, 63.36it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0805       |\n",
            "| elapsed time            | 18:44:56     |\n",
            "| episodes                | 4830         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003119963  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0006490795 |\n",
            "| loss_td                 | 0.023859322  |\n",
            "| losses_all              | 0.005347817  |\n",
            "| max 100 episode reward  | 369          |\n",
            "| mean 100 episode reward | 33.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3781983      |\n",
            "------------------------------------------\n",
            " 95% 3792749/4000000 [18:31:45<56:31, 61.11it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0805       |\n",
            "| elapsed time            | 18:47:59     |\n",
            "| episodes                | 4840         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003122874  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.019660965  |\n",
            "| loss_td                 | 0.020211205  |\n",
            "| losses_all              | 0.0056473315 |\n",
            "| max 100 episode reward  | 369          |\n",
            "| mean 100 episode reward | 36.2         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3792749      |\n",
            "------------------------------------------\n",
            " 95% 3799995/4000000 [18:33:50<53:52, 61.87it/s]saved checkpoint\n",
            " 95% 3801920/4000000 [18:34:23<52:46, 62.55it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0804        |\n",
            "| elapsed time            | 18:50:37      |\n",
            "| episodes                | 4850          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.003125461   |\n",
            "| loss_margin             | 0.00044232607 |\n",
            "| loss_n_td               | 0.00021906964 |\n",
            "| loss_td                 | 0.11190098    |\n",
            "| losses_all              | 0.008305853   |\n",
            "| max 100 episode reward  | 369           |\n",
            "| mean 100 episode reward | 36            |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3801924       |\n",
            "-------------------------------------------\n",
            " 95% 3808812/4000000 [18:36:24<50:20, 63.29it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0804        |\n",
            "| elapsed time            | 18:52:38      |\n",
            "| episodes                | 4860          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031264857  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00046500308 |\n",
            "| loss_td                 | 0.01445305    |\n",
            "| losses_all              | 0.005934329   |\n",
            "| max 100 episode reward  | 369           |\n",
            "| mean 100 episode reward | 35.2          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3808816       |\n",
            "-------------------------------------------\n",
            " 95% 3815539/4000000 [18:38:22<49:52, 61.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0804       |\n",
            "| elapsed time            | 18:54:36     |\n",
            "| episodes                | 4870         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031326974 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0015296323 |\n",
            "| loss_td                 | 0.016352337  |\n",
            "| losses_all              | 0.0053957603 |\n",
            "| max 100 episode reward  | 369          |\n",
            "| mean 100 episode reward | 30.6         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3815542      |\n",
            "------------------------------------------\n",
            " 96% 3820123/4000000 [18:39:46<48:08, 62.28it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0803       |\n",
            "| elapsed time            | 18:56:00     |\n",
            "| episodes                | 4880         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031308422 |\n",
            "| loss_margin             | 0.0064744353 |\n",
            "| loss_n_td               | 0.0018612552 |\n",
            "| loss_td                 | 0.003966579  |\n",
            "| losses_all              | 0.0044099344 |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 26.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3820129      |\n",
            "------------------------------------------\n",
            " 96% 3827477/4000000 [18:41:55<44:42, 64.32it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0803       |\n",
            "| elapsed time            | 18:58:09     |\n",
            "| episodes                | 4890         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031493076 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0004222724 |\n",
            "| loss_td                 | 0.016687753  |\n",
            "| losses_all              | 0.005459182  |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 25.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3827477      |\n",
            "------------------------------------------\n",
            " 96% 3832969/4000000 [18:43:34<46:22, 60.03it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0803       |\n",
            "| elapsed time            | 18:59:48     |\n",
            "| episodes                | 4900         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031483837 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0006759516 |\n",
            "| loss_td                 | 0.008296158  |\n",
            "| losses_all              | 0.0042774156 |\n",
            "| max 100 episode reward  | 213          |\n",
            "| mean 100 episode reward | 22.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3832971      |\n",
            "------------------------------------------\n",
            " 96% 3840452/4000000 [18:45:44<42:07, 63.13it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0802       |\n",
            "| elapsed time            | 19:01:58     |\n",
            "| episodes                | 4910         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003154895  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0012440054 |\n",
            "| loss_td                 | 0.42591923   |\n",
            "| losses_all              | 0.018125676  |\n",
            "| max 100 episode reward  | 213          |\n",
            "| mean 100 episode reward | 22.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3840458      |\n",
            "------------------------------------------\n",
            " 96% 3850704/4000000 [18:48:39<39:12, 63.47it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0802        |\n",
            "| elapsed time            | 19:04:53      |\n",
            "| episodes                | 4920          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031631363  |\n",
            "| loss_margin             | 0.00076470524 |\n",
            "| loss_n_td               | 0.0017212589  |\n",
            "| loss_td                 | 0.019147038   |\n",
            "| losses_all              | 0.0049450044  |\n",
            "| max 100 episode reward  | 238           |\n",
            "| mean 100 episode reward | 25.9          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3850708       |\n",
            "-------------------------------------------\n",
            " 96% 3856270/4000000 [18:50:19<39:06, 61.26it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0802       |\n",
            "| elapsed time            | 19:06:33     |\n",
            "| episodes                | 4930         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031634741 |\n",
            "| loss_margin             | 0.0013049394 |\n",
            "| loss_n_td               | 0.0009071703 |\n",
            "| loss_td                 | 0.009944031  |\n",
            "| losses_all              | 0.004678322  |\n",
            "| max 100 episode reward  | 336          |\n",
            "| mean 100 episode reward | 29.9         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3856272      |\n",
            "------------------------------------------\n",
            " 97% 3862484/4000000 [18:52:09<36:40, 62.48it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0801       |\n",
            "| elapsed time            | 19:08:23     |\n",
            "| episodes                | 4940         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.003180902  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.0043123616 |\n",
            "| losses_all              | 0.004056543  |\n",
            "| max 100 episode reward  | 336          |\n",
            "| mean 100 episode reward | 26.8         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3862486      |\n",
            "------------------------------------------\n",
            " 97% 3868711/4000000 [18:54:00<37:34, 58.24it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0801       |\n",
            "| elapsed time            | 19:10:13     |\n",
            "| episodes                | 4950         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0031784212 |\n",
            "| loss_margin             | 0.005313799  |\n",
            "| loss_n_td               | 0.0022216712 |\n",
            "| loss_td                 | 0.03217692   |\n",
            "| losses_all              | 0.0062715393 |\n",
            "| max 100 episode reward  | 375          |\n",
            "| mean 100 episode reward | 30.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3868713      |\n",
            "------------------------------------------\n",
            " 97% 3875876/4000000 [18:56:05<33:01, 62.64it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0801        |\n",
            "| elapsed time            | 19:12:19      |\n",
            "| episodes                | 4960          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0031909985  |\n",
            "| loss_margin             | 0.019889645   |\n",
            "| loss_n_td               | 3.0397578e-05 |\n",
            "| loss_td                 | 0.021702364   |\n",
            "| losses_all              | 0.00647645    |\n",
            "| max 100 episode reward  | 375           |\n",
            "| mean 100 episode reward | 30.5          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3875882       |\n",
            "-------------------------------------------\n",
            " 97% 3882269/4000000 [18:57:58<31:43, 61.83it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.08         |\n",
            "| elapsed time            | 19:14:12     |\n",
            "| episodes                | 4970         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032017296 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0009965416 |\n",
            "| loss_td                 | 0.03883273   |\n",
            "| losses_all              | 0.0074789855 |\n",
            "| max 100 episode reward  | 375          |\n",
            "| mean 100 episode reward | 33.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3882272      |\n",
            "------------------------------------------\n",
            " 97% 3888509/4000000 [18:59:48<29:54, 62.12it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.08          |\n",
            "| elapsed time            | 19:16:02      |\n",
            "| episodes                | 4980          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032064468  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00012946884 |\n",
            "| loss_td                 | 0.014988182   |\n",
            "| losses_all              | 0.0047031348  |\n",
            "| max 100 episode reward  | 375           |\n",
            "| mean 100 episode reward | 34.1          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3888509       |\n",
            "-------------------------------------------\n",
            " 97% 3894404/4000000 [19:01:33<27:20, 64.36it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.08          |\n",
            "| elapsed time            | 19:17:46      |\n",
            "| episodes                | 4990          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032142242  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00033667893 |\n",
            "| loss_td                 | 0.046161048   |\n",
            "| losses_all              | 0.0066840677  |\n",
            "| max 100 episode reward  | 375           |\n",
            "| mean 100 episode reward | 36.4          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3894410       |\n",
            "-------------------------------------------\n",
            " 97% 3899999/4000000 [19:03:10<26:43, 62.36it/s]saved checkpoint\n",
            " 98% 3902600/4000000 [19:03:55<25:50, 62.81it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0799       |\n",
            "| elapsed time            | 19:20:09     |\n",
            "| episodes                | 5000         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032213016 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 9.650927e-08 |\n",
            "| loss_td                 | 0.030874252  |\n",
            "| losses_all              | 0.0070846668 |\n",
            "| max 100 episode reward  | 375          |\n",
            "| mean 100 episode reward | 39.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3902603      |\n",
            "------------------------------------------\n",
            " 98% 3911065/4000000 [19:06:21<23:20, 63.48it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0799        |\n",
            "| elapsed time            | 19:22:35      |\n",
            "| episodes                | 5010          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032345103  |\n",
            "| loss_margin             | 0.0038259365  |\n",
            "| loss_n_td               | 0.00066661544 |\n",
            "| loss_td                 | 0.013964539   |\n",
            "| losses_all              | 0.005298402   |\n",
            "| max 100 episode reward  | 375           |\n",
            "| mean 100 episode reward | 40.2          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3911067       |\n",
            "-------------------------------------------\n",
            " 98% 3917875/4000000 [19:08:21<21:31, 63.61it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0799       |\n",
            "| elapsed time            | 19:24:35     |\n",
            "| episodes                | 5020         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032373192 |\n",
            "| loss_margin             | 0.0018807054 |\n",
            "| loss_n_td               | 0.000490853  |\n",
            "| loss_td                 | 0.006252115  |\n",
            "| losses_all              | 0.004284893  |\n",
            "| max 100 episode reward  | 375          |\n",
            "| mean 100 episode reward | 38.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3917879      |\n",
            "------------------------------------------\n",
            " 98% 3925583/4000000 [19:10:34<19:45, 62.76it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0798       |\n",
            "| elapsed time            | 19:26:48     |\n",
            "| episodes                | 5030         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.00324838   |\n",
            "| loss_margin             | 0.006290175  |\n",
            "| loss_n_td               | 0.0007901283 |\n",
            "| loss_td                 | 0.022987153  |\n",
            "| losses_all              | 0.005996027  |\n",
            "| max 100 episode reward  | 375          |\n",
            "| mean 100 episode reward | 35.3         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3925589      |\n",
            "------------------------------------------\n",
            " 98% 3933465/4000000 [19:12:51<17:29, 63.40it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0798        |\n",
            "| elapsed time            | 19:29:05      |\n",
            "| episodes                | 5040          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032544804  |\n",
            "| loss_margin             | 0.0034037828  |\n",
            "| loss_n_td               | 0.00096732867 |\n",
            "| loss_td                 | 0.03899549    |\n",
            "| losses_all              | 0.0070233     |\n",
            "| max 100 episode reward  | 375           |\n",
            "| mean 100 episode reward | 39.5          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3933469       |\n",
            "-------------------------------------------\n",
            " 99% 3941848/4000000 [19:15:16<15:11, 63.77it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0797        |\n",
            "| elapsed time            | 19:31:29      |\n",
            "| episodes                | 5050          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0032646933  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00055155664 |\n",
            "| loss_td                 | 0.022681803   |\n",
            "| losses_all              | 0.0059291376  |\n",
            "| max 100 episode reward  | 361           |\n",
            "| mean 100 episode reward | 35.4          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3941849       |\n",
            "-------------------------------------------\n",
            " 99% 3951219/4000000 [19:17:56<12:50, 63.29it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0797       |\n",
            "| elapsed time            | 19:34:10     |\n",
            "| episodes                | 5060         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032705914 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0008987389 |\n",
            "| loss_td                 | 0.014452534  |\n",
            "| losses_all              | 0.005390617  |\n",
            "| max 100 episode reward  | 361          |\n",
            "| mean 100 episode reward | 34.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3951224      |\n",
            "------------------------------------------\n",
            " 99% 3958119/4000000 [19:19:55<10:56, 63.81it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0797       |\n",
            "| elapsed time            | 19:36:09     |\n",
            "| episodes                | 5070         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0032709206 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0023672015 |\n",
            "| loss_td                 | 0.0102853235 |\n",
            "| losses_all              | 0.004576454  |\n",
            "| max 100 episode reward  | 361          |\n",
            "| mean 100 episode reward | 30.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3958123      |\n",
            "------------------------------------------\n",
            " 99% 3958805/4000000 [19:20:08<17:51, 38.46it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u3ghxyr50fh",
        "colab_type": "code",
        "outputId": "daa680ec-fa03-4470-d8b3-105c99c44ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "!git status "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch master\n",
            "Your branch is up to date with 'origin/master'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
            "\n",
            "\t\u001b[31mmodified:   run_atari.py\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_9L_dwWbBoZ",
        "colab_type": "code",
        "outputId": "9a05d8d8-878b-4f3a-c678-ad344fc20f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!git add . \n",
        "!git commit -m \"add commandline control of more parameters\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master 96ca851] add commandline control of more parameters\n",
            " 1 file changed, 15 insertions(+), 8 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A2hNQE_bMcN",
        "colab_type": "code",
        "outputId": "b7882fdc-135a-47fa-b75d-ae751182bd33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "!git push"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 3, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:  33% (1/3)   \rCompressing objects:  66% (2/3)   \rCompressing objects: 100% (3/3)   \rCompressing objects: 100% (3/3), done.\n",
            "Writing objects:  33% (1/3)   \rWriting objects:  66% (2/3)   \rWriting objects: 100% (3/3)   \rWriting objects: 100% (3/3), 661 bytes | 661.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/Kokkini/DQfD.git\n",
            "   5d5fb69..96ca851  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAZjuQCVbN-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}