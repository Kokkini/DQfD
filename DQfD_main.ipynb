{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQfD_main.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/Kokkini/DQfD/blob/master/DQfD_main.ipynb",
      "authorship_tag": "ABX9TyPoWYQQFMrigarN5yQuvhRo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kokkini/DQfD/blob/master/DQfD_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLKIVoRu16Fy",
        "colab_type": "code",
        "outputId": "890c2a56-fd1e-43ce-da0d-32fe03b6a7e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "# !pip install stable-baselines[mpi]==2.10.0\n",
        "!pip install gym\n",
        "!pip install pynput"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Collecting pynput\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/0a/ea13c055a90b1aff5945e7eb330584f15e5282aead15a8f3cdb977a1534e/pynput-1.6.8-py2.py3-none-any.whl (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.6MB/s \n",
            "\u001b[?25hCollecting python-xlib>=0.17; \"linux\" in sys_platform\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/10/2eb938852a9bdf6745808f141c9fede76b1bd5a9530859bacc71985d29d9/python_xlib-0.27-py2.py3-none-any.whl (174kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 14.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pynput) (1.12.0)\n",
            "Installing collected packages: python-xlib, pynput\n",
            "Successfully installed pynput-1.6.8 python-xlib-0.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99IlmkkQ7mcr",
        "colab_type": "code",
        "outputId": "beb8169d-93ea-4bea-a4d5-1b35ac70af62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun  3 17:05:53 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7VAg5r42H9q",
        "colab_type": "code",
        "outputId": "23b471e4-f44c-4673-d930-d7104930a6df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "from getpass import getpass\n",
        "\n",
        "def clone_with_token(repo_name, owner_name=\"Kokkini\", user_email=\"trannhatquang1104@gmail.com\", user_name=\"Kokkini\"):\n",
        "  GIT_TOKEN = getpass('insert token: ')\n",
        "  GIT_PATH = f\"https://{GIT_TOKEN}@github.com/{owner_name}/{repo_name}.git\"\n",
        "  !git config --global user.email \"{user_email}\"\n",
        "  !git config --global user.name \"{user_name}\"\n",
        "  !git clone \"{GIT_PATH}\"\n",
        "  GIT_TOKEN, GIT_PATH = \"\", \"\"\n",
        "clone_with_token(\"DQfD\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "insert token: ··········\n",
            "Cloning into 'DQfD'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (239/239), done.\u001b[K\n",
            "remote: Compressing objects: 100% (198/198), done.\u001b[K\n",
            "remote: Total 239 (delta 141), reused 89 (delta 36), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (239/239), 204.84 KiB | 5.54 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tBPFxBF55tf",
        "colab_type": "code",
        "outputId": "184b33e3-24b2-4a63-dabf-6701959eacf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd DQfD/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DQfD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1mT261H2VMr",
        "colab_type": "code",
        "outputId": "da6642f3-a464-4085-be9e-deb7780fd741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_atari.py --pre_train_timesteps=1e5 --num_timesteps=2e6 --batch_size=64 --save_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/models13\" --load_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/models13\" --demo_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/human.BreakoutNoFrameskip-v4.pkl\" --log_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/logs13\" "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "------------------------------------------\n",
            " 31% 623275/2000000 [1:08:41<2:20:37, 163.16it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.14          |\n",
            "| elapsed time            | 01:25:42      |\n",
            "| episodes                | 1920          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.003413081   |\n",
            "| loss_margin             | 0.009821229   |\n",
            "| loss_n_td               | 0.00084269507 |\n",
            "| loss_td                 | 0.019449402   |\n",
            "| losses_all              | 0.0085584875  |\n",
            "| max 100 episode reward  | 188           |\n",
            "| mean 100 episode reward | 13.7          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 623286        |\n",
            "-------------------------------------------\n",
            " 31% 627356/2000000 [1:09:08<2:22:41, 160.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.14         |\n",
            "| elapsed time            | 01:26:09     |\n",
            "| episodes                | 1930         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0034100793 |\n",
            "| loss_margin             | 0.003785625  |\n",
            "| loss_n_td               | 0.0010808451 |\n",
            "| loss_td                 | 0.012716831  |\n",
            "| losses_all              | 0.0070867417 |\n",
            "| max 100 episode reward  | 188          |\n",
            "| mean 100 episode reward | 13.9         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 627367       |\n",
            "------------------------------------------\n",
            " 32% 631422/2000000 [1:09:35<2:21:57, 160.67it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.139        |\n",
            "| elapsed time            | 01:26:35     |\n",
            "| episodes                | 1940         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0034070231 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0011529442 |\n",
            "| loss_td                 | 0.018501267  |\n",
            "| losses_all              | 0.0070695933 |\n",
            "| max 100 episode reward  | 188          |\n",
            "| mean 100 episode reward | 14.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 631424       |\n",
            "------------------------------------------\n",
            " 32% 635789/2000000 [1:10:04<2:25:34, 156.18it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.139         |\n",
            "| elapsed time            | 01:27:04      |\n",
            "| episodes                | 1950          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0034025586  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00029306705 |\n",
            "| loss_td                 | 0.010051494   |\n",
            "| losses_all              | 0.0056079286  |\n",
            "| max 100 episode reward  | 188           |\n",
            "| mean 100 episode reward | 13.2          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 635799        |\n",
            "-------------------------------------------\n",
            " 32% 639885/2000000 [1:10:31<2:23:37, 157.84it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.138         |\n",
            "| elapsed time            | 01:27:31      |\n",
            "| episodes                | 1960          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0033969316  |\n",
            "| loss_margin             | 0.0093175955  |\n",
            "| loss_n_td               | 0.00019822703 |\n",
            "| loss_td                 | 0.007824815   |\n",
            "| losses_all              | 0.0067351037  |\n",
            "| max 100 episode reward  | 188           |\n",
            "| mean 100 episode reward | 12.7          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 639901        |\n",
            "-------------------------------------------\n",
            " 32% 644291/2000000 [1:10:59<2:20:21, 160.98it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.138        |\n",
            "| elapsed time            | 01:28:00     |\n",
            "| episodes                | 1970         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033948284 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0005792781 |\n",
            "| loss_td                 | 0.008075636  |\n",
            "| losses_all              | 0.005293674  |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 12.7         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 644305       |\n",
            "------------------------------------------\n",
            " 32% 648534/2000000 [1:11:27<2:21:33, 159.12it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.137         |\n",
            "| elapsed time            | 01:28:28      |\n",
            "| episodes                | 1980          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0033948077  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 1.4652359e-05 |\n",
            "| loss_td                 | 0.008169267   |\n",
            "| losses_all              | 0.005287545   |\n",
            "| max 100 episode reward  | 152           |\n",
            "| mean 100 episode reward | 12.7          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 648544        |\n",
            "-------------------------------------------\n",
            " 33% 652622/2000000 [1:11:54<2:23:47, 156.18it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.136        |\n",
            "| elapsed time            | 01:28:55     |\n",
            "| episodes                | 1990         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033993633 |\n",
            "| loss_margin             | 0.015979338  |\n",
            "| loss_n_td               | 0.0033057716 |\n",
            "| loss_td                 | 0.010433188  |\n",
            "| losses_all              | 0.0077245147 |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 12.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 652627       |\n",
            "------------------------------------------\n",
            " 33% 656751/2000000 [1:12:22<2:18:30, 161.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.136        |\n",
            "| elapsed time            | 01:29:22     |\n",
            "| episodes                | 2000         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033939013 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.001134803  |\n",
            "| loss_td                 | 0.0075139124 |\n",
            "| losses_all              | 0.0053754495 |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 12.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 656756       |\n",
            "------------------------------------------\n",
            " 33% 660925/2000000 [1:12:50<2:22:24, 156.72it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.135         |\n",
            "| elapsed time            | 01:29:50      |\n",
            "| episodes                | 2010          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0033880086  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 5.4236643e-05 |\n",
            "| loss_td                 | 0.011926212   |\n",
            "| losses_all              | 0.006498738   |\n",
            "| max 100 episode reward  | 152           |\n",
            "| mean 100 episode reward | 11.6          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 660936        |\n",
            "-------------------------------------------\n",
            " 33% 665965/2000000 [1:13:22<2:21:56, 156.64it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.135         |\n",
            "| elapsed time            | 01:30:23      |\n",
            "| episodes                | 2020          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0033864363  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00083268044 |\n",
            "| loss_td                 | 0.008680472   |\n",
            "| losses_all              | 0.005127845   |\n",
            "| max 100 episode reward  | 152           |\n",
            "| mean 100 episode reward | 12.1          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 665976        |\n",
            "-------------------------------------------\n",
            " 33% 669632/2000000 [1:13:47<2:17:14, 161.56it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.134        |\n",
            "| elapsed time            | 01:30:47     |\n",
            "| episodes                | 2030         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033820514 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.013610942  |\n",
            "| losses_all              | 0.005937249  |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 12           |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 669636       |\n",
            "------------------------------------------\n",
            " 34% 672935/2000000 [1:14:08<2:15:52, 162.77it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.134        |\n",
            "| elapsed time            | 01:31:09     |\n",
            "| episodes                | 2040         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033761687 |\n",
            "| loss_margin             | 0.007685557  |\n",
            "| loss_n_td               | 0.004508506  |\n",
            "| loss_td                 | 0.011076562  |\n",
            "| losses_all              | 0.006785754  |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 11.6         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 672938       |\n",
            "------------------------------------------\n",
            " 34% 677555/2000000 [1:14:38<2:17:15, 160.59it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.134        |\n",
            "| elapsed time            | 01:31:39     |\n",
            "| episodes                | 2050         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033727034 |\n",
            "| loss_margin             | 0.008877102  |\n",
            "| loss_n_td               | 0.0005677559 |\n",
            "| loss_td                 | 0.005512632  |\n",
            "| losses_all              | 0.005912085  |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 12.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 677571       |\n",
            "------------------------------------------\n",
            " 34% 681675/2000000 [1:15:06<2:14:38, 163.18it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.133        |\n",
            "| elapsed time            | 01:32:06     |\n",
            "| episodes                | 2060         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033712494 |\n",
            "| loss_margin             | 0.0058509    |\n",
            "| loss_n_td               | 0.0012014771 |\n",
            "| loss_td                 | 0.013067716  |\n",
            "| losses_all              | 0.0065148417 |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 12           |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 681681       |\n",
            "------------------------------------------\n",
            " 34% 686064/2000000 [1:15:34<2:12:07, 165.73it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.133        |\n",
            "| elapsed time            | 01:32:35     |\n",
            "| episodes                | 2070         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033657774 |\n",
            "| loss_margin             | 0.0028880574 |\n",
            "| loss_n_td               | 0.0013690016 |\n",
            "| loss_td                 | 0.010999395  |\n",
            "| losses_all              | 0.0063926987 |\n",
            "| max 100 episode reward  | 45           |\n",
            "| mean 100 episode reward | 10.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 686080       |\n",
            "------------------------------------------\n",
            " 35% 690222/2000000 [1:16:01<2:17:05, 159.23it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.132         |\n",
            "| elapsed time            | 01:33:02      |\n",
            "| episodes                | 2080          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0033593841  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00021620939 |\n",
            "| loss_td                 | 0.02348129    |\n",
            "| losses_all              | 0.0077814795  |\n",
            "| max 100 episode reward  | 45            |\n",
            "| mean 100 episode reward | 10.2          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 690223        |\n",
            "-------------------------------------------\n",
            " 35% 694341/2000000 [1:16:28<2:16:04, 159.92it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.132         |\n",
            "| elapsed time            | 01:33:29      |\n",
            "| episodes                | 2090          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0033531573  |\n",
            "| loss_margin             | 0.009326208   |\n",
            "| loss_n_td               | 0.00024759554 |\n",
            "| loss_td                 | 0.0050782263  |\n",
            "| losses_all              | 0.005702356   |\n",
            "| max 100 episode reward  | 45            |\n",
            "| mean 100 episode reward | 10.1          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 694344        |\n",
            "-------------------------------------------\n",
            " 35% 698555/2000000 [1:16:56<2:13:28, 162.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.131        |\n",
            "| elapsed time            | 01:33:56     |\n",
            "| episodes                | 2100         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033467663 |\n",
            "| loss_margin             | 0.0047334135 |\n",
            "| loss_n_td               | 0.0012169618 |\n",
            "| loss_td                 | 0.016270183  |\n",
            "| losses_all              | 0.0073432177 |\n",
            "| max 100 episode reward  | 45           |\n",
            "| mean 100 episode reward | 9.91         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 698563       |\n",
            "------------------------------------------\n",
            " 35% 699993/2000000 [1:17:06<2:16:15, 159.01it/s]saved checkpoint\n",
            " 35% 702721/2000000 [1:17:23<2:17:13, 157.56it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.131         |\n",
            "| elapsed time            | 01:34:23      |\n",
            "| episodes                | 2110          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0033406976  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00070590305 |\n",
            "| loss_td                 | 0.007958574   |\n",
            "| losses_all              | 0.006074718   |\n",
            "| max 100 episode reward  | 45            |\n",
            "| mean 100 episode reward | 10.1          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 702725        |\n",
            "-------------------------------------------\n",
            " 35% 707181/2000000 [1:17:52<2:20:54, 152.92it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.13         |\n",
            "| elapsed time            | 01:34:53     |\n",
            "| episodes                | 2120         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033358561 |\n",
            "| loss_margin             | 0.007507734  |\n",
            "| loss_n_td               | 0.0054269074 |\n",
            "| loss_td                 | 0.009729332  |\n",
            "| losses_all              | 0.006742567  |\n",
            "| max 100 episode reward  | 45           |\n",
            "| mean 100 episode reward | 10.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 707193       |\n",
            "------------------------------------------\n",
            " 36% 711578/2000000 [1:18:21<2:13:11, 161.23it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.13         |\n",
            "| elapsed time            | 01:35:22     |\n",
            "| episodes                | 2130         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003332038  |\n",
            "| loss_margin             | 0.01034921   |\n",
            "| loss_n_td               | 0.0010380538 |\n",
            "| loss_td                 | 0.006869659  |\n",
            "| losses_all              | 0.006648876  |\n",
            "| max 100 episode reward  | 45           |\n",
            "| mean 100 episode reward | 10.8         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 711583       |\n",
            "------------------------------------------\n",
            " 36% 715309/2000000 [1:18:45<2:15:03, 158.54it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.129        |\n",
            "| elapsed time            | 01:35:46     |\n",
            "| episodes                | 2140         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033283867 |\n",
            "| loss_margin             | 0.007481899  |\n",
            "| loss_n_td               | 5.923825e-05 |\n",
            "| loss_td                 | 0.023938702  |\n",
            "| losses_all              | 0.00718793   |\n",
            "| max 100 episode reward  | 45           |\n",
            "| mean 100 episode reward | 11.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 715325       |\n",
            "------------------------------------------\n",
            " 36% 719942/2000000 [1:19:15<2:12:09, 161.43it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.129        |\n",
            "| elapsed time            | 01:36:16     |\n",
            "| episodes                | 2150         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033290826 |\n",
            "| loss_margin             | 0.01958793   |\n",
            "| loss_n_td               | 0.0003356501 |\n",
            "| loss_td                 | 0.00514465   |\n",
            "| losses_all              | 0.0070616873 |\n",
            "| max 100 episode reward  | 38           |\n",
            "| mean 100 episode reward | 11           |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 719944       |\n",
            "------------------------------------------\n",
            " 36% 724134/2000000 [1:19:42<2:10:35, 162.83it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.129        |\n",
            "| elapsed time            | 01:36:43     |\n",
            "| episodes                | 2160         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.00331799   |\n",
            "| loss_margin             | 0.010271683  |\n",
            "| loss_n_td               | 0.0035783984 |\n",
            "| loss_td                 | 0.013818621  |\n",
            "| losses_all              | 0.0072508818 |\n",
            "| max 100 episode reward  | 38           |\n",
            "| mean 100 episode reward | 11.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 724138       |\n",
            "------------------------------------------\n",
            " 36% 728438/2000000 [1:20:10<2:07:33, 166.15it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.128        |\n",
            "| elapsed time            | 01:37:11     |\n",
            "| episodes                | 2170         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033089733 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.011779003  |\n",
            "| losses_all              | 0.006505684  |\n",
            "| max 100 episode reward  | 38           |\n",
            "| mean 100 episode reward | 11.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 728453       |\n",
            "------------------------------------------\n",
            " 37% 733325/2000000 [1:20:42<2:12:33, 159.26it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.128         |\n",
            "| elapsed time            | 01:37:43      |\n",
            "| episodes                | 2180          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00330451    |\n",
            "| loss_margin             | 0.007813271   |\n",
            "| loss_n_td               | 4.6469762e-05 |\n",
            "| loss_td                 | 0.005093693   |\n",
            "| losses_all              | 0.005447058   |\n",
            "| max 100 episode reward  | 41            |\n",
            "| mean 100 episode reward | 11.9          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 733339        |\n",
            "-------------------------------------------\n",
            " 37% 738005/2000000 [1:21:14<2:18:20, 152.05it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.127        |\n",
            "| elapsed time            | 01:38:14     |\n",
            "| episodes                | 2190         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0033028258 |\n",
            "| loss_margin             | 0.006996747  |\n",
            "| loss_n_td               | 0.0025695483 |\n",
            "| loss_td                 | 0.010131722  |\n",
            "| losses_all              | 0.006496095  |\n",
            "| max 100 episode reward  | 41           |\n",
            "| mean 100 episode reward | 12.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 738007       |\n",
            "------------------------------------------\n",
            " 37% 742573/2000000 [1:21:44<2:13:00, 157.55it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.127        |\n",
            "| elapsed time            | 01:38:44     |\n",
            "| episodes                | 2200         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003296889  |\n",
            "| loss_margin             | 0.0013779122 |\n",
            "| loss_n_td               | 0.0002627621 |\n",
            "| loss_td                 | 0.009461693  |\n",
            "| losses_all              | 0.0051364866 |\n",
            "| max 100 episode reward  | 41           |\n",
            "| mean 100 episode reward | 12.7         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 742580       |\n",
            "------------------------------------------\n",
            " 37% 747217/2000000 [1:22:14<2:11:59, 158.20it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.126        |\n",
            "| elapsed time            | 01:39:15     |\n",
            "| episodes                | 2210         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0032890472 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0011295213 |\n",
            "| loss_td                 | 0.016335556  |\n",
            "| losses_all              | 0.006191695  |\n",
            "| max 100 episode reward  | 41           |\n",
            "| mean 100 episode reward | 12.7         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 747217       |\n",
            "------------------------------------------\n",
            " 38% 751484/2000000 [1:22:43<2:11:32, 158.18it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.126         |\n",
            "| elapsed time            | 01:39:43      |\n",
            "| episodes                | 2220          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0032839254  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00042669888 |\n",
            "| loss_td                 | 0.0060222177  |\n",
            "| losses_all              | 0.0046710838  |\n",
            "| max 100 episode reward  | 41            |\n",
            "| mean 100 episode reward | 12.8          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 751484        |\n",
            "-------------------------------------------\n",
            " 38% 755726/2000000 [1:23:11<2:08:57, 160.81it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.126         |\n",
            "| elapsed time            | 01:40:11      |\n",
            "| episodes                | 2230          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0032784392  |\n",
            "| loss_margin             | 0.00019873306 |\n",
            "| loss_n_td               | 0.00093436084 |\n",
            "| loss_td                 | 0.009639699   |\n",
            "| losses_all              | 0.005708676   |\n",
            "| max 100 episode reward  | 41            |\n",
            "| mean 100 episode reward | 12.3          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 755743        |\n",
            "-------------------------------------------\n",
            " 38% 760383/2000000 [1:23:41<2:06:26, 163.41it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.125        |\n",
            "| elapsed time            | 01:40:41     |\n",
            "| episodes                | 2240         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0032772012 |\n",
            "| loss_margin             | 0.007105669  |\n",
            "| loss_n_td               | 0.0034625556 |\n",
            "| loss_td                 | 0.01152733   |\n",
            "| losses_all              | 0.0064450363 |\n",
            "| max 100 episode reward  | 41           |\n",
            "| mean 100 episode reward | 12.7         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 760394       |\n",
            "------------------------------------------\n",
            " 38% 764887/2000000 [1:24:10<2:05:29, 164.04it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.125        |\n",
            "| elapsed time            | 01:41:10     |\n",
            "| episodes                | 2250         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0032702782 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0001457748 |\n",
            "| loss_td                 | 0.005456052  |\n",
            "| losses_all              | 0.0045028804 |\n",
            "| max 100 episode reward  | 41           |\n",
            "| mean 100 episode reward | 12.8         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 764902       |\n",
            "------------------------------------------\n",
            " 38% 769296/2000000 [1:24:38<2:04:27, 164.80it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.124        |\n",
            "| elapsed time            | 01:41:39     |\n",
            "| episodes                | 2260         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0032629352 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0042054504 |\n",
            "| loss_td                 | 0.013546109  |\n",
            "| losses_all              | 0.0058113076 |\n",
            "| max 100 episode reward  | 41           |\n",
            "| mean 100 episode reward | 12.5         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 769308       |\n",
            "------------------------------------------\n",
            " 39% 773590/2000000 [1:25:06<2:07:09, 160.74it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.124        |\n",
            "| elapsed time            | 01:42:06     |\n",
            "| episodes                | 2270         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003259773  |\n",
            "| loss_margin             | 0.0077313    |\n",
            "| loss_n_td               | 0.0021442845 |\n",
            "| loss_td                 | 0.008024014  |\n",
            "| losses_all              | 0.006360105  |\n",
            "| max 100 episode reward  | 41           |\n",
            "| mean 100 episode reward | 12.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 773599       |\n",
            "------------------------------------------\n",
            " 39% 777824/2000000 [1:25:33<2:02:22, 166.45it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.124         |\n",
            "| elapsed time            | 01:42:34      |\n",
            "| episodes                | 2280          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0032557228  |\n",
            "| loss_margin             | 0.0059133396  |\n",
            "| loss_n_td               | 0.00043032147 |\n",
            "| loss_td                 | 0.014547323   |\n",
            "| losses_all              | 0.0066739414  |\n",
            "| max 100 episode reward  | 32            |\n",
            "| mean 100 episode reward | 12            |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 777828        |\n",
            "-------------------------------------------\n",
            " 39% 782211/2000000 [1:26:02<2:05:03, 162.30it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.123         |\n",
            "| elapsed time            | 01:43:02      |\n",
            "| episodes                | 2290          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0032498161  |\n",
            "| loss_margin             | 0.0012105592  |\n",
            "| loss_n_td               | 0.00037378928 |\n",
            "| loss_td                 | 0.005790105   |\n",
            "| losses_all              | 0.0047722245  |\n",
            "| max 100 episode reward  | 32            |\n",
            "| mean 100 episode reward | 11.8          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 782213        |\n",
            "-------------------------------------------\n",
            " 39% 787005/2000000 [1:26:32<2:06:55, 159.29it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.123        |\n",
            "| elapsed time            | 01:43:33     |\n",
            "| episodes                | 2300         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0032432617 |\n",
            "| loss_margin             | 0.003105048  |\n",
            "| loss_n_td               | 0.0008979875 |\n",
            "| loss_td                 | 0.005908942  |\n",
            "| losses_all              | 0.0049321814 |\n",
            "| max 100 episode reward  | 32           |\n",
            "| mean 100 episode reward | 11.8         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 787011       |\n",
            "------------------------------------------\n",
            " 40% 791274/2000000 [1:27:00<2:06:28, 159.28it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.122         |\n",
            "| elapsed time            | 01:44:00      |\n",
            "| episodes                | 2310          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0032414752  |\n",
            "| loss_margin             | 0.025135534   |\n",
            "| loss_n_td               | 0.00035968205 |\n",
            "| loss_td                 | 0.0078933835  |\n",
            "| losses_all              | 0.00787699    |\n",
            "| max 100 episode reward  | 32            |\n",
            "| mean 100 episode reward | 11.8          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 791277        |\n",
            "-------------------------------------------\n",
            " 40% 796088/2000000 [1:27:31<2:02:32, 163.75it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.122        |\n",
            "| elapsed time            | 01:44:31     |\n",
            "| episodes                | 2320         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0032353597 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0002306029 |\n",
            "| loss_td                 | 0.0055091456 |\n",
            "| losses_all              | 0.00448245   |\n",
            "| max 100 episode reward  | 32           |\n",
            "| mean 100 episode reward | 11.9         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 796088       |\n",
            "------------------------------------------\n",
            " 40% 799995/2000000 [1:27:56<2:03:34, 161.84it/s]saved checkpoint\n",
            " 40% 800858/2000000 [1:28:01<2:05:19, 159.47it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.122        |\n",
            "| elapsed time            | 01:45:02     |\n",
            "| episodes                | 2330         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0032327226 |\n",
            "| loss_margin             | 0.009117063  |\n",
            "| loss_n_td               | 0.0011378392 |\n",
            "| loss_td                 | 0.014372183  |\n",
            "| losses_all              | 0.007253214  |\n",
            "| max 100 episode reward  | 39           |\n",
            "| mean 100 episode reward | 12.3         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 800873       |\n",
            "------------------------------------------\n",
            " 40% 806268/2000000 [1:28:37<2:02:01, 163.04it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.121       |\n",
            "| elapsed time            | 01:45:37    |\n",
            "| episodes                | 2340        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.0032251   |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.0         |\n",
            "| loss_td                 | 0.00981119  |\n",
            "| losses_all              | 0.004929982 |\n",
            "| max 100 episode reward  | 229         |\n",
            "| mean 100 episode reward | 14.6        |\n",
            "| min 100 episode reward  | 5           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 806269      |\n",
            "-----------------------------------------\n",
            " 41% 811009/2000000 [1:29:07<2:03:30, 160.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.121        |\n",
            "| elapsed time            | 01:46:07     |\n",
            "| episodes                | 2350         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0032176457 |\n",
            "| loss_margin             | 0.022418335  |\n",
            "| loss_n_td               | 0.0007910337 |\n",
            "| loss_td                 | 0.0072462587 |\n",
            "| losses_all              | 0.007762851  |\n",
            "| max 100 episode reward  | 229          |\n",
            "| mean 100 episode reward | 14.8         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 811018       |\n",
            "------------------------------------------\n",
            " 41% 815447/2000000 [1:29:36<1:58:10, 167.05it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.121        |\n",
            "| elapsed time            | 01:46:36     |\n",
            "| episodes                | 2360         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0032099127 |\n",
            "| loss_margin             | 0.012208529  |\n",
            "| loss_n_td               | 0.0017240765 |\n",
            "| loss_td                 | 0.0074365702 |\n",
            "| losses_all              | 0.006396384  |\n",
            "| max 100 episode reward  | 229          |\n",
            "| mean 100 episode reward | 14.9         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 815464       |\n",
            "------------------------------------------\n",
            " 41% 820181/2000000 [1:30:06<2:06:10, 155.84it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.12         |\n",
            "| elapsed time            | 01:47:07     |\n",
            "| episodes                | 2370         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0032020651 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0004231804 |\n",
            "| loss_td                 | 0.009192128  |\n",
            "| losses_all              | 0.005970033  |\n",
            "| max 100 episode reward  | 229          |\n",
            "| mean 100 episode reward | 15.3         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 820196       |\n",
            "------------------------------------------\n",
            " 41% 824978/2000000 [1:30:37<2:01:32, 161.14it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.12         |\n",
            "| elapsed time            | 01:47:37     |\n",
            "| episodes                | 2380         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0032007894 |\n",
            "| loss_margin             | 0.022328202  |\n",
            "| loss_n_td               | 0.015750598  |\n",
            "| loss_td                 | 0.017331623  |\n",
            "| losses_all              | 0.008897515  |\n",
            "| max 100 episode reward  | 229          |\n",
            "| mean 100 episode reward | 15.4         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 824985       |\n",
            "------------------------------------------\n",
            " 41% 829295/2000000 [1:31:05<1:58:41, 164.38it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.119        |\n",
            "| elapsed time            | 01:48:05     |\n",
            "| episodes                | 2390         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031987077 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0016281641 |\n",
            "| loss_td                 | 0.0077300733 |\n",
            "| losses_all              | 0.005608639  |\n",
            "| max 100 episode reward  | 229          |\n",
            "| mean 100 episode reward | 15.3         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 829300       |\n",
            "------------------------------------------\n",
            " 42% 834253/2000000 [1:31:36<2:01:42, 159.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.119        |\n",
            "| elapsed time            | 01:48:36     |\n",
            "| episodes                | 2400         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031947575 |\n",
            "| loss_margin             | 0.01927332   |\n",
            "| loss_n_td               | 0.0016919891 |\n",
            "| loss_td                 | 0.008903881  |\n",
            "| losses_all              | 0.0072786743 |\n",
            "| max 100 episode reward  | 229          |\n",
            "| mean 100 episode reward | 15.5         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 834269       |\n",
            "------------------------------------------\n",
            " 42% 839241/2000000 [1:32:08<2:01:43, 158.93it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.119        |\n",
            "| elapsed time            | 01:49:08     |\n",
            "| episodes                | 2410         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031885528 |\n",
            "| loss_margin             | 0.0120494515 |\n",
            "| loss_n_td               | 0.0026209333 |\n",
            "| loss_td                 | 0.0064136465 |\n",
            "| losses_all              | 0.006036441  |\n",
            "| max 100 episode reward  | 229          |\n",
            "| mean 100 episode reward | 15.9         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 839250       |\n",
            "------------------------------------------\n",
            " 42% 844245/2000000 [1:32:40<2:00:19, 160.10it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.118         |\n",
            "| elapsed time            | 01:49:40      |\n",
            "| episodes                | 2420          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0031842205  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00086354744 |\n",
            "| loss_td                 | 0.009894444   |\n",
            "| losses_all              | 0.004988387   |\n",
            "| max 100 episode reward  | 229           |\n",
            "| mean 100 episode reward | 16            |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 844251        |\n",
            "-------------------------------------------\n",
            " 42% 849408/2000000 [1:33:13<1:57:41, 162.93it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.118        |\n",
            "| elapsed time            | 01:50:13     |\n",
            "| episodes                | 2430         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031792154 |\n",
            "| loss_margin             | 0.026359104  |\n",
            "| loss_n_td               | 0.0027678944 |\n",
            "| loss_td                 | 0.0071054143 |\n",
            "| losses_all              | 0.007738278  |\n",
            "| max 100 episode reward  | 229          |\n",
            "| mean 100 episode reward | 16.4         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 849414       |\n",
            "------------------------------------------\n",
            " 43% 853852/2000000 [1:33:42<1:54:53, 166.26it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.118         |\n",
            "| elapsed time            | 01:50:42      |\n",
            "| episodes                | 2440          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0031779823  |\n",
            "| loss_margin             | 0.007845975   |\n",
            "| loss_n_td               | 0.00065093976 |\n",
            "| loss_td                 | 0.01106122    |\n",
            "| losses_all              | 0.0060537187  |\n",
            "| max 100 episode reward  | 38            |\n",
            "| mean 100 episode reward | 13.9          |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 853856        |\n",
            "-------------------------------------------\n",
            " 43% 858909/2000000 [1:34:14<2:01:25, 156.63it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.117        |\n",
            "| elapsed time            | 01:51:14     |\n",
            "| episodes                | 2450         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031780058 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0018799643 |\n",
            "| loss_td                 | 0.035874363  |\n",
            "| losses_all              | 0.00781977   |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 14.3         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 858919       |\n",
            "------------------------------------------\n",
            " 43% 863673/2000000 [1:34:44<2:00:25, 157.27it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.117        |\n",
            "| elapsed time            | 01:51:45     |\n",
            "| episodes                | 2460         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031751178 |\n",
            "| loss_margin             | 0.003454361  |\n",
            "| loss_n_td               | 0.002592592  |\n",
            "| loss_td                 | 0.00916967   |\n",
            "| losses_all              | 0.005391001  |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 14.8         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 863675       |\n",
            "------------------------------------------\n",
            " 43% 868068/2000000 [1:35:13<2:02:06, 154.49it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.117         |\n",
            "| elapsed time            | 01:52:13      |\n",
            "| episodes                | 2470          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.003177478   |\n",
            "| loss_margin             | 0.024915248   |\n",
            "| loss_n_td               | 0.00083775946 |\n",
            "| loss_td                 | 0.006000589   |\n",
            "| losses_all              | 0.007413705   |\n",
            "| max 100 episode reward  | 43            |\n",
            "| mean 100 episode reward | 14.9          |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 868081        |\n",
            "-------------------------------------------\n",
            " 44% 872846/2000000 [1:35:44<1:57:58, 159.24it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.116        |\n",
            "| elapsed time            | 01:52:45     |\n",
            "| episodes                | 2480         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031655598 |\n",
            "| loss_margin             | 0.010330364  |\n",
            "| loss_n_td               | 0.0018884469 |\n",
            "| loss_td                 | 0.008322504  |\n",
            "| losses_all              | 0.006180523  |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 15           |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 872857       |\n",
            "------------------------------------------\n",
            " 44% 877828/2000000 [1:36:17<1:54:55, 162.73it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.116        |\n",
            "| elapsed time            | 01:53:17     |\n",
            "| episodes                | 2490         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031664462 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010837525 |\n",
            "| loss_td                 | 0.007169554  |\n",
            "| losses_all              | 0.004540301  |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 15.3         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 877836       |\n",
            "------------------------------------------\n",
            " 44% 883162/2000000 [1:36:51<1:55:50, 160.68it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.116        |\n",
            "| elapsed time            | 01:53:52     |\n",
            "| episodes                | 2500         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031616234 |\n",
            "| loss_margin             | 0.0080587715 |\n",
            "| loss_n_td               | 0.0011012955 |\n",
            "| loss_td                 | 0.007712152  |\n",
            "| losses_all              | 0.00579465   |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 15.2         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 883175       |\n",
            "------------------------------------------\n",
            " 44% 883977/2000000 [1:36:57<1:59:00, 156.30it/s]saved best model\n",
            " 44% 888394/2000000 [1:37:25<1:55:37, 160.23it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.115        |\n",
            "| elapsed time            | 01:54:26     |\n",
            "| episodes                | 2510         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031573956 |\n",
            "| loss_margin             | 0.020700134  |\n",
            "| loss_n_td               | 0.0018969682 |\n",
            "| loss_td                 | 0.006736851  |\n",
            "| losses_all              | 0.0072090356 |\n",
            "| max 100 episode reward  | 242          |\n",
            "| mean 100 episode reward | 17.8         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 888398       |\n",
            "------------------------------------------\n",
            " 45% 893959/2000000 [1:38:01<1:53:06, 162.97it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.115         |\n",
            "| elapsed time            | 01:55:02      |\n",
            "| episodes                | 2520          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0031632097  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 5.1201212e-05 |\n",
            "| loss_td                 | 0.009781083   |\n",
            "| losses_all              | 0.0047247903  |\n",
            "| max 100 episode reward  | 242           |\n",
            "| mean 100 episode reward | 17.8          |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 893967        |\n",
            "-------------------------------------------\n",
            " 45% 898677/2000000 [1:38:32<2:02:21, 150.01it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.115        |\n",
            "| elapsed time            | 01:55:33     |\n",
            "| episodes                | 2530         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031563097 |\n",
            "| loss_margin             | 0.0010396652 |\n",
            "| loss_n_td               | 0.0015615551 |\n",
            "| loss_td                 | 0.013193084  |\n",
            "| losses_all              | 0.0059999265 |\n",
            "| max 100 episode reward  | 242          |\n",
            "| mean 100 episode reward | 17.8         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 898690       |\n",
            "------------------------------------------\n",
            " 45% 899991/2000000 [1:38:42<1:52:20, 163.19it/s]saved checkpoint\n",
            " 45% 903971/2000000 [1:39:07<1:50:53, 164.74it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.114         |\n",
            "| elapsed time            | 01:56:07      |\n",
            "| episodes                | 2540          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0031500435  |\n",
            "| loss_margin             | 0.009376228   |\n",
            "| loss_n_td               | 5.5126085e-05 |\n",
            "| loss_td                 | 0.0060384795  |\n",
            "| losses_all              | 0.005605433   |\n",
            "| max 100 episode reward  | 242           |\n",
            "| mean 100 episode reward | 18.1          |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 903986        |\n",
            "-------------------------------------------\n",
            " 45% 908873/2000000 [1:39:38<1:57:19, 155.00it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.114         |\n",
            "| elapsed time            | 01:56:39      |\n",
            "| episodes                | 2550          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0031477031  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00059163704 |\n",
            "| loss_td                 | 0.011609597   |\n",
            "| losses_all              | 0.0054209074  |\n",
            "| max 100 episode reward  | 242           |\n",
            "| mean 100 episode reward | 17.5          |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 908886        |\n",
            "-------------------------------------------\n",
            " 46% 913665/2000000 [1:40:09<1:54:38, 157.93it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.114         |\n",
            "| elapsed time            | 01:57:09      |\n",
            "| episodes                | 2560          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.003148511   |\n",
            "| loss_margin             | 0.00045709312 |\n",
            "| loss_n_td               | 0.00026641935 |\n",
            "| loss_td                 | 0.006087019   |\n",
            "| losses_all              | 0.0046112346  |\n",
            "| max 100 episode reward  | 242           |\n",
            "| mean 100 episode reward | 17.2          |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 913667        |\n",
            "-------------------------------------------\n",
            " 46% 918763/2000000 [1:40:41<1:50:39, 162.85it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.113       |\n",
            "| elapsed time            | 01:57:42    |\n",
            "| episodes                | 2570        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.003143005 |\n",
            "| loss_margin             | 0.01119224  |\n",
            "| loss_n_td               | 0.005289331 |\n",
            "| loss_td                 | 0.010560699 |\n",
            "| losses_all              | 0.007008726 |\n",
            "| max 100 episode reward  | 242         |\n",
            "| mean 100 episode reward | 17.4        |\n",
            "| min 100 episode reward  | 5           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 918766      |\n",
            "-----------------------------------------\n",
            " 46% 923539/2000000 [1:41:12<1:48:21, 165.57it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.113        |\n",
            "| elapsed time            | 01:58:12     |\n",
            "| episodes                | 2580         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.00314875   |\n",
            "| loss_margin             | 0.0134138055 |\n",
            "| loss_n_td               | 0.0026396583 |\n",
            "| loss_td                 | 0.0057208887 |\n",
            "| losses_all              | 0.0062331236 |\n",
            "| max 100 episode reward  | 242          |\n",
            "| mean 100 episode reward | 17.3         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 923544       |\n",
            "------------------------------------------\n",
            " 46% 927915/2000000 [1:41:40<1:47:28, 166.26it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.113         |\n",
            "| elapsed time            | 01:58:40      |\n",
            "| episodes                | 2590          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0031408276  |\n",
            "| loss_margin             | 0.00055797026 |\n",
            "| loss_n_td               | 0.0004869239  |\n",
            "| loss_td                 | 0.0047502373  |\n",
            "| losses_all              | 0.00424783    |\n",
            "| max 100 episode reward  | 242           |\n",
            "| mean 100 episode reward | 16.8          |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 927919        |\n",
            "-------------------------------------------\n",
            " 47% 932495/2000000 [1:42:09<1:49:39, 162.25it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.113        |\n",
            "| elapsed time            | 01:59:09     |\n",
            "| episodes                | 2600         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031450798 |\n",
            "| loss_margin             | 0.010639021  |\n",
            "| loss_n_td               | 0.0008293324 |\n",
            "| loss_td                 | 0.026784148  |\n",
            "| losses_all              | 0.008050285  |\n",
            "| max 100 episode reward  | 242          |\n",
            "| mean 100 episode reward | 16.8         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 932502       |\n",
            "------------------------------------------\n",
            " 47% 937549/2000000 [1:42:41<1:51:46, 158.41it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.112        |\n",
            "| elapsed time            | 01:59:41     |\n",
            "| episodes                | 2610         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003127883  |\n",
            "| loss_margin             | 0.0031091832 |\n",
            "| loss_n_td               | 0.0020678618 |\n",
            "| loss_td                 | 0.016712505  |\n",
            "| losses_all              | 0.006052316  |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 14.5         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 937564       |\n",
            "------------------------------------------\n",
            " 47% 941682/2000000 [1:43:07<1:49:06, 161.66it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.112        |\n",
            "| elapsed time            | 02:00:08     |\n",
            "| episodes                | 2620         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003130022  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0029106115 |\n",
            "| loss_td                 | 0.007561876  |\n",
            "| losses_all              | 0.0051655704 |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 13.9         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 941698       |\n",
            "------------------------------------------\n",
            " 47% 946850/2000000 [1:43:40<1:52:06, 156.56it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.112        |\n",
            "| elapsed time            | 02:00:41     |\n",
            "| episodes                | 2630         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031250122 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.006311396  |\n",
            "| loss_td                 | 0.014233326  |\n",
            "| losses_all              | 0.0062422976 |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 13.4         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 946852       |\n",
            "------------------------------------------\n",
            " 48% 951359/2000000 [1:44:09<1:47:10, 163.07it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.111         |\n",
            "| elapsed time            | 02:01:10      |\n",
            "| episodes                | 2640          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0031203167  |\n",
            "| loss_margin             | 0.00014099106 |\n",
            "| loss_n_td               | 0.002961458   |\n",
            "| loss_td                 | 0.008357864   |\n",
            "| losses_all              | 0.00535325    |\n",
            "| max 100 episode reward  | 43            |\n",
            "| mean 100 episode reward | 12.9          |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 951360        |\n",
            "-------------------------------------------\n",
            " 48% 956021/2000000 [1:44:39<1:47:56, 161.18it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.111        |\n",
            "| elapsed time            | 02:01:40     |\n",
            "| episodes                | 2650         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031183898 |\n",
            "| loss_margin             | 0.022423703  |\n",
            "| loss_n_td               | 0.0023349952 |\n",
            "| loss_td                 | 0.006243592  |\n",
            "| losses_all              | 0.007105964  |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 12.9         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 956028       |\n",
            "------------------------------------------\n",
            " 48% 960544/2000000 [1:45:08<1:45:19, 164.50it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.111         |\n",
            "| elapsed time            | 02:02:08      |\n",
            "| episodes                | 2660          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.003110306   |\n",
            "| loss_margin             | 0.00010264665 |\n",
            "| loss_n_td               | 0.0012844912  |\n",
            "| loss_td                 | 0.011221058   |\n",
            "| losses_all              | 0.0061424184  |\n",
            "| max 100 episode reward  | 43            |\n",
            "| mean 100 episode reward | 13.2          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 960554        |\n",
            "-------------------------------------------\n",
            " 48% 965539/2000000 [1:45:40<1:45:28, 163.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.111        |\n",
            "| elapsed time            | 02:02:41     |\n",
            "| episodes                | 2670         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003118599  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0001686748 |\n",
            "| loss_td                 | 0.009043316  |\n",
            "| losses_all              | 0.005111222  |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 13.6         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 965539       |\n",
            "------------------------------------------\n",
            " 49% 970349/2000000 [1:46:11<1:46:13, 161.56it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.11          |\n",
            "| elapsed time            | 02:03:11      |\n",
            "| episodes                | 2680          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.003108297   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00023170336 |\n",
            "| loss_td                 | 0.0070126783  |\n",
            "| losses_all              | 0.0046902997  |\n",
            "| max 100 episode reward  | 41            |\n",
            "| mean 100 episode reward | 13.9          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 970361        |\n",
            "-------------------------------------------\n",
            " 49% 975089/2000000 [1:46:41<1:46:09, 160.92it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.11         |\n",
            "| elapsed time            | 02:03:41     |\n",
            "| episodes                | 2690         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031061904 |\n",
            "| loss_margin             | 0.012699604  |\n",
            "| loss_n_td               | 0.0024609452 |\n",
            "| loss_td                 | 0.0034183783 |\n",
            "| losses_all              | 0.005547907  |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 16.3         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 975092       |\n",
            "------------------------------------------\n",
            " 49% 980653/2000000 [1:47:15<1:45:40, 160.78it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.11         |\n",
            "| elapsed time            | 02:04:16     |\n",
            "| episodes                | 2700         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031089007 |\n",
            "| loss_margin             | 0.004856989  |\n",
            "| loss_n_td               | 0.0007450506 |\n",
            "| loss_td                 | 0.017015837  |\n",
            "| losses_all              | 0.006697263  |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 16.3         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 980658       |\n",
            "------------------------------------------\n",
            " 49% 985341/2000000 [1:47:45<1:50:34, 152.94it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.11         |\n",
            "| elapsed time            | 02:04:46     |\n",
            "| episodes                | 2710         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031077813 |\n",
            "| loss_margin             | 0.008807048  |\n",
            "| loss_n_td               | 0.0007550176 |\n",
            "| loss_td                 | 0.0038837842 |\n",
            "| losses_all              | 0.0051163053 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 15.7         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 985355       |\n",
            "------------------------------------------\n",
            " 50% 990705/2000000 [1:48:20<1:44:26, 161.06it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.109         |\n",
            "| elapsed time            | 02:05:21      |\n",
            "| episodes                | 2720          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0031133215  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00029296588 |\n",
            "| loss_td                 | 0.010303029   |\n",
            "| losses_all              | 0.005478351   |\n",
            "| max 100 episode reward  | 232           |\n",
            "| mean 100 episode reward | 16.6          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 990716        |\n",
            "-------------------------------------------\n",
            " 50% 995222/2000000 [1:48:49<1:49:30, 152.93it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.109        |\n",
            "| elapsed time            | 02:05:50     |\n",
            "| episodes                | 2730         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031191576 |\n",
            "| loss_margin             | 0.005399581  |\n",
            "| loss_n_td               | 0.001481926  |\n",
            "| loss_td                 | 0.014361035  |\n",
            "| losses_all              | 0.0060580447 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 16.6         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 995230       |\n",
            "------------------------------------------\n",
            " 50% 999962/2000000 [1:49:20<1:42:02, 163.34it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.109        |\n",
            "| elapsed time            | 02:06:20     |\n",
            "| episodes                | 2740         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031139324 |\n",
            "| loss_margin             | 1.501292e-05 |\n",
            "| loss_n_td               | 0.0016814905 |\n",
            "| loss_td                 | 0.012910183  |\n",
            "| losses_all              | 0.005416445  |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 17.2         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 999971       |\n",
            "------------------------------------------\n",
            " 50% 999994/2000000 [1:49:21<4:07:22, 67.38it/s]saved checkpoint\n",
            " 50% 1005086/2000000 [1:49:52<1:40:11, 165.49it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.108        |\n",
            "| elapsed time            | 02:06:53     |\n",
            "| episodes                | 2750         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031125073 |\n",
            "| loss_margin             | 0.017671376  |\n",
            "| loss_n_td               | 0.000880602  |\n",
            "| loss_td                 | 0.0047724913 |\n",
            "| losses_all              | 0.0060729105 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 18.6         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1005096      |\n",
            "------------------------------------------\n",
            " 50% 1009427/2000000 [1:50:19<1:38:28, 167.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.108        |\n",
            "| elapsed time            | 02:07:20     |\n",
            "| episodes                | 2760         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031071724 |\n",
            "| loss_margin             | 0.014971457  |\n",
            "| loss_n_td               | 0.0009087841 |\n",
            "| loss_td                 | 0.0071854275 |\n",
            "| losses_all              | 0.0061401553 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 18.4         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1009437      |\n",
            "------------------------------------------\n",
            " 51% 1013942/2000000 [1:50:48<1:39:38, 164.93it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.108        |\n",
            "| elapsed time            | 02:07:48     |\n",
            "| episodes                | 2770         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031039987 |\n",
            "| loss_margin             | 0.0009172261 |\n",
            "| loss_n_td               | 0.0016682171 |\n",
            "| loss_td                 | 0.012432934  |\n",
            "| losses_all              | 0.0053275274 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 17.6         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1013954      |\n",
            "------------------------------------------\n",
            " 51% 1018621/2000000 [1:51:17<1:37:35, 167.59it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.108        |\n",
            "| elapsed time            | 02:08:18     |\n",
            "| episodes                | 2780         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0031033072 |\n",
            "| loss_margin             | 0.010610841  |\n",
            "| loss_n_td               | 0.0008601139 |\n",
            "| loss_td                 | 0.0079810545 |\n",
            "| losses_all              | 0.005982142  |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 17.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1018626      |\n",
            "------------------------------------------\n",
            " 51% 1023659/2000000 [1:51:48<1:36:16, 169.03it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.108         |\n",
            "| elapsed time            | 02:08:49      |\n",
            "| episodes                | 2790          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0031011887  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 1.0406967e-05 |\n",
            "| loss_td                 | 0.004573617   |\n",
            "| losses_all              | 0.004053519   |\n",
            "| max 100 episode reward  | 152           |\n",
            "| mean 100 episode reward | 16.1          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1023663       |\n",
            "-------------------------------------------\n",
            " 51% 1028408/2000000 [1:52:18<1:34:43, 170.95it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.107        |\n",
            "| elapsed time            | 02:09:18     |\n",
            "| episodes                | 2800         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030944513 |\n",
            "| loss_margin             | 0.008091394  |\n",
            "| loss_n_td               | 0.0034266294 |\n",
            "| loss_td                 | 0.0074571013 |\n",
            "| losses_all              | 0.0055251108 |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 15.8         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1028415      |\n",
            "------------------------------------------\n",
            " 52% 1033036/2000000 [1:52:47<1:36:07, 167.65it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.107        |\n",
            "| elapsed time            | 02:09:47     |\n",
            "| episodes                | 2810         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003086938  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0017305677 |\n",
            "| loss_td                 | 0.009137383  |\n",
            "| losses_all              | 0.0049503595 |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 15.9         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1033037      |\n",
            "------------------------------------------\n",
            " 52% 1037566/2000000 [1:53:15<1:36:36, 166.05it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.107        |\n",
            "| elapsed time            | 02:10:15     |\n",
            "| episodes                | 2820         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030834929 |\n",
            "| loss_margin             | 0.009627905  |\n",
            "| loss_n_td               | 0.003033002  |\n",
            "| loss_td                 | 0.009759231  |\n",
            "| losses_all              | 0.0065855826 |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 15           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1037583      |\n",
            "------------------------------------------\n",
            " 52% 1042008/2000000 [1:53:43<1:34:37, 168.72it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.107         |\n",
            "| elapsed time            | 02:10:44      |\n",
            "| episodes                | 2830          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.003079831   |\n",
            "| loss_margin             | 0.011366343   |\n",
            "| loss_n_td               | 0.00058845396 |\n",
            "| loss_td                 | 0.009318588   |\n",
            "| losses_all              | 0.0058467602  |\n",
            "| max 100 episode reward  | 152           |\n",
            "| mean 100 episode reward | 14.9          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1042017       |\n",
            "-------------------------------------------\n",
            " 52% 1046962/2000000 [1:54:15<1:37:27, 162.98it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.106        |\n",
            "| elapsed time            | 02:11:16     |\n",
            "| episodes                | 2840         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030788959 |\n",
            "| loss_margin             | 0.012122147  |\n",
            "| loss_n_td               | 0.0015250364 |\n",
            "| loss_td                 | 0.0033265157 |\n",
            "| losses_all              | 0.005339631  |\n",
            "| max 100 episode reward  | 152          |\n",
            "| mean 100 episode reward | 14.6         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1046971      |\n",
            "------------------------------------------\n",
            " 53% 1050487/2000000 [1:54:38<1:34:20, 167.73it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.106         |\n",
            "| elapsed time            | 02:11:38      |\n",
            "| episodes                | 2850          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0030800772  |\n",
            "| loss_margin             | 0.008144934   |\n",
            "| loss_n_td               | 0.00065536826 |\n",
            "| loss_td                 | 0.0164746     |\n",
            "| losses_all              | 0.0065455553  |\n",
            "| max 100 episode reward  | 40            |\n",
            "| mean 100 episode reward | 12.5          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1050495       |\n",
            "-------------------------------------------\n",
            " 53% 1055181/2000000 [1:55:07<1:35:26, 164.99it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.106        |\n",
            "| elapsed time            | 02:12:08     |\n",
            "| episodes                | 2860         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030759715 |\n",
            "| loss_margin             | 0.017074287  |\n",
            "| loss_n_td               | 0.00160133   |\n",
            "| loss_td                 | 0.013460536  |\n",
            "| losses_all              | 0.0069983006 |\n",
            "| max 100 episode reward  | 40           |\n",
            "| mean 100 episode reward | 12.4         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1055182      |\n",
            "------------------------------------------\n",
            " 53% 1059943/2000000 [1:55:37<1:38:08, 159.63it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.106         |\n",
            "| elapsed time            | 02:12:38      |\n",
            "| episodes                | 2870          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.003068498   |\n",
            "| loss_margin             | 0.009532616   |\n",
            "| loss_n_td               | 0.00027138228 |\n",
            "| loss_td                 | 0.009619536   |\n",
            "| losses_all              | 0.005583573   |\n",
            "| max 100 episode reward  | 40            |\n",
            "| mean 100 episode reward | 12.4          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1059960       |\n",
            "-------------------------------------------\n",
            " 53% 1064532/2000000 [1:56:06<1:34:13, 165.47it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.106        |\n",
            "| elapsed time            | 02:13:06     |\n",
            "| episodes                | 2880         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003057658  |\n",
            "| loss_margin             | 0.015770268  |\n",
            "| loss_n_td               | 0.0015859453 |\n",
            "| loss_td                 | 0.008495597  |\n",
            "| losses_all              | 0.0062862188 |\n",
            "| max 100 episode reward  | 40           |\n",
            "| mean 100 episode reward | 12.1         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1064543      |\n",
            "------------------------------------------\n",
            " 53% 1068696/2000000 [1:56:32<1:29:46, 172.89it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.105         |\n",
            "| elapsed time            | 02:13:32      |\n",
            "| episodes                | 2890          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0030479827  |\n",
            "| loss_margin             | 0.008891728   |\n",
            "| loss_n_td               | 0.00033359005 |\n",
            "| loss_td                 | 0.045807082   |\n",
            "| losses_all              | 0.007865992   |\n",
            "| max 100 episode reward  | 36            |\n",
            "| mean 100 episode reward | 11.4          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1068711       |\n",
            "-------------------------------------------\n",
            " 54% 1073194/2000000 [1:57:00<1:32:58, 166.13it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.105        |\n",
            "| elapsed time            | 02:14:00     |\n",
            "| episodes                | 2900         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030491722 |\n",
            "| loss_margin             | 0.0056631267 |\n",
            "| loss_n_td               | 0.0019161587 |\n",
            "| loss_td                 | 0.011437895  |\n",
            "| losses_all              | 0.0059448183 |\n",
            "| max 100 episode reward  | 36           |\n",
            "| mean 100 episode reward | 11.5         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1073202      |\n",
            "------------------------------------------\n",
            " 54% 1077592/2000000 [1:57:27<1:31:59, 167.12it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.105        |\n",
            "| elapsed time            | 02:14:27     |\n",
            "| episodes                | 2910         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003043634  |\n",
            "| loss_margin             | 0.016736358  |\n",
            "| loss_n_td               | 0.0015813108 |\n",
            "| loss_td                 | 0.0067500975 |\n",
            "| losses_all              | 0.0064393454 |\n",
            "| max 100 episode reward  | 39           |\n",
            "| mean 100 episode reward | 11.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1077596      |\n",
            "------------------------------------------\n",
            " 54% 1082672/2000000 [1:57:59<1:30:25, 169.08it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.105         |\n",
            "| elapsed time            | 02:14:59      |\n",
            "| episodes                | 2920          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0030436525  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00045008448 |\n",
            "| loss_td                 | 0.032483175   |\n",
            "| losses_all              | 0.0078017134  |\n",
            "| max 100 episode reward  | 234           |\n",
            "| mean 100 episode reward | 14.3          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1082688       |\n",
            "-------------------------------------------\n",
            " 54% 1087183/2000000 [1:58:27<1:31:38, 166.00it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.105        |\n",
            "| elapsed time            | 02:15:27     |\n",
            "| episodes                | 2930         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030375905 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.0063618585 |\n",
            "| losses_all              | 0.0045397663 |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 14.1         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1087199      |\n",
            "------------------------------------------\n",
            " 55% 1091339/2000000 [1:58:53<1:31:07, 166.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.104        |\n",
            "| elapsed time            | 02:15:53     |\n",
            "| episodes                | 2940         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003035851  |\n",
            "| loss_margin             | 0.006256629  |\n",
            "| loss_n_td               | 7.340443e-05 |\n",
            "| loss_td                 | 0.0060831397 |\n",
            "| losses_all              | 0.0048706746 |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 14.1         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1091351      |\n",
            "------------------------------------------\n",
            " 55% 1095321/2000000 [1:59:18<1:36:06, 156.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.104        |\n",
            "| elapsed time            | 02:16:18     |\n",
            "| episodes                | 2950         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030347758 |\n",
            "| loss_margin             | 0.0096494295 |\n",
            "| loss_n_td               | 0.0018253541 |\n",
            "| loss_td                 | 0.0077782962 |\n",
            "| losses_all              | 0.0055696303 |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 14.3         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1095331      |\n",
            "------------------------------------------\n",
            " 55% 1099672/2000000 [1:59:45<1:28:51, 168.87it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.104        |\n",
            "| elapsed time            | 02:16:46     |\n",
            "| episodes                | 2960         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030318475 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 8.527912e-05 |\n",
            "| loss_td                 | 0.015774429  |\n",
            "| losses_all              | 0.005516885  |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 14.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1099688      |\n",
            "------------------------------------------\n",
            " 55% 1099994/2000000 [1:59:48<1:35:50, 156.52it/s]saved checkpoint\n",
            " 55% 1104335/2000000 [2:00:14<1:29:21, 167.04it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.104        |\n",
            "| elapsed time            | 02:17:15     |\n",
            "| episodes                | 2970         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003027387  |\n",
            "| loss_margin             | 0.008034799  |\n",
            "| loss_n_td               | 0.0006824344 |\n",
            "| loss_td                 | 0.030421969  |\n",
            "| losses_all              | 0.010216821  |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 15.6         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1104347      |\n",
            "------------------------------------------\n",
            " 55% 1109015/2000000 [2:00:44<1:28:24, 167.98it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.104         |\n",
            "| elapsed time            | 02:17:44      |\n",
            "| episodes                | 2980          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0030255902  |\n",
            "| loss_margin             | 0.014078785   |\n",
            "| loss_n_td               | 0.00056614017 |\n",
            "| loss_td                 | 0.008883126   |\n",
            "| losses_all              | 0.0062183533  |\n",
            "| max 100 episode reward  | 234           |\n",
            "| mean 100 episode reward | 16.1          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1109029       |\n",
            "-------------------------------------------\n",
            " 56% 1113861/2000000 [2:01:14<1:32:24, 159.82it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.103       |\n",
            "| elapsed time            | 02:18:14    |\n",
            "| episodes                | 2990        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.00302805  |\n",
            "| loss_margin             | 0.02863113  |\n",
            "| loss_n_td               | 0.008904755 |\n",
            "| loss_td                 | 0.01659593  |\n",
            "| losses_all              | 0.008486241 |\n",
            "| max 100 episode reward  | 234         |\n",
            "| mean 100 episode reward | 16.4        |\n",
            "| min 100 episode reward  | 1           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1113875     |\n",
            "-----------------------------------------\n",
            " 56% 1118156/2000000 [2:01:41<1:27:05, 168.77it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.103        |\n",
            "| elapsed time            | 02:18:41     |\n",
            "| episodes                | 3000         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030323283 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010061112 |\n",
            "| loss_td                 | 0.01103252   |\n",
            "| losses_all              | 0.006312892  |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 16.1         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1118166      |\n",
            "------------------------------------------\n",
            " 56% 1122243/2000000 [2:02:06<1:26:55, 168.31it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.103         |\n",
            "| elapsed time            | 02:19:07      |\n",
            "| episodes                | 3010          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.003036565   |\n",
            "| loss_margin             | 0.0006031245  |\n",
            "| loss_n_td               | 0.00051535777 |\n",
            "| loss_td                 | 0.016828267   |\n",
            "| losses_all              | 0.005743727   |\n",
            "| max 100 episode reward  | 234           |\n",
            "| mean 100 episode reward | 15.8          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1122249       |\n",
            "-------------------------------------------\n",
            " 56% 1126813/2000000 [2:02:34<1:29:13, 163.11it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.103         |\n",
            "| elapsed time            | 02:19:35      |\n",
            "| episodes                | 3020          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0030301516  |\n",
            "| loss_margin             | 0.011994172   |\n",
            "| loss_n_td               | 0.00013691385 |\n",
            "| loss_td                 | 0.026572313   |\n",
            "| losses_all              | 0.007667678   |\n",
            "| max 100 episode reward  | 96            |\n",
            "| mean 100 episode reward | 13.5          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1126817       |\n",
            "-------------------------------------------\n",
            " 57% 1131040/2000000 [2:03:01<1:24:55, 170.52it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.103        |\n",
            "| elapsed time            | 02:20:01     |\n",
            "| episodes                | 3030         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030192155 |\n",
            "| loss_margin             | 0.009452708  |\n",
            "| loss_n_td               | 0.0007655302 |\n",
            "| loss_td                 | 0.009309208  |\n",
            "| losses_all              | 0.00578026   |\n",
            "| max 100 episode reward  | 96           |\n",
            "| mean 100 episode reward | 13.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1131049      |\n",
            "------------------------------------------\n",
            " 57% 1135837/2000000 [2:03:30<1:27:07, 165.30it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 02:20:31     |\n",
            "| episodes                | 3040         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003013134  |\n",
            "| loss_margin             | 0.022371244  |\n",
            "| loss_n_td               | 0.004384634  |\n",
            "| loss_td                 | 0.0057063643 |\n",
            "| losses_all              | 0.0067091207 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 15.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1135841      |\n",
            "------------------------------------------\n",
            " 57% 1140505/2000000 [2:03:59<1:25:36, 167.32it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 02:21:00     |\n",
            "| episodes                | 3050         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030025041 |\n",
            "| loss_margin             | 0.008235335  |\n",
            "| loss_n_td               | 0.0017159453 |\n",
            "| loss_td                 | 0.010903552  |\n",
            "| losses_all              | 0.0059286067 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 17.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1140513      |\n",
            "------------------------------------------\n",
            " 57% 1144371/2000000 [2:04:24<1:29:11, 159.87it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.102         |\n",
            "| elapsed time            | 02:21:24      |\n",
            "| episodes                | 3060          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0030012578  |\n",
            "| loss_margin             | 0.008864749   |\n",
            "| loss_n_td               | 0.00013276597 |\n",
            "| loss_td                 | 0.0059907874  |\n",
            "| losses_all              | 0.004952187   |\n",
            "| max 100 episode reward  | 150           |\n",
            "| mean 100 episode reward | 16.8          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1144378       |\n",
            "-------------------------------------------\n",
            " 57% 1148594/2000000 [2:04:50<1:24:07, 168.66it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 02:21:51     |\n",
            "| episodes                | 3070         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029989714 |\n",
            "| loss_margin             | 0.032394733  |\n",
            "| loss_n_td               | 0.009583039  |\n",
            "| loss_td                 | 0.019845586  |\n",
            "| losses_all              | 0.008272544  |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 16.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1148594      |\n",
            "------------------------------------------\n",
            " 58% 1153413/2000000 [2:05:21<1:25:50, 164.38it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 02:22:21     |\n",
            "| episodes                | 3080         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029996673 |\n",
            "| loss_margin             | 0.010774981  |\n",
            "| loss_n_td               | 0.0015701185 |\n",
            "| loss_td                 | 0.017037848  |\n",
            "| losses_all              | 0.0069632614 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 15.6         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1153419      |\n",
            "------------------------------------------\n",
            " 58% 1158279/2000000 [2:05:52<1:22:50, 169.34it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.102         |\n",
            "| elapsed time            | 02:22:52      |\n",
            "| episodes                | 3090          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029905138  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00021907513 |\n",
            "| loss_td                 | 0.010554721   |\n",
            "| losses_all              | 0.0059819086  |\n",
            "| max 100 episode reward  | 150           |\n",
            "| mean 100 episode reward | 15.5          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1158292       |\n",
            "-------------------------------------------\n",
            " 58% 1162584/2000000 [2:06:19<1:30:09, 154.82it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 02:23:19     |\n",
            "| episodes                | 3100         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029910144 |\n",
            "| loss_margin             | 0.0094209835 |\n",
            "| loss_n_td               | 0.0024781688 |\n",
            "| loss_td                 | 0.009798691  |\n",
            "| losses_all              | 0.0053587514 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 15.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1162595      |\n",
            "------------------------------------------\n",
            " 58% 1167055/2000000 [2:06:47<1:22:02, 169.20it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 02:23:47     |\n",
            "| episodes                | 3110         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029908172 |\n",
            "| loss_margin             | 0.008701928  |\n",
            "| loss_n_td               | 0.001949911  |\n",
            "| loss_td                 | 0.016031161  |\n",
            "| losses_all              | 0.0067241676 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 16           |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1167069      |\n",
            "------------------------------------------\n",
            " 59% 1171246/2000000 [2:07:13<1:23:08, 166.14it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.101         |\n",
            "| elapsed time            | 02:24:14      |\n",
            "| episodes                | 3120          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029936037  |\n",
            "| loss_margin             | 0.00044836476 |\n",
            "| loss_n_td               | 0.00064055383 |\n",
            "| loss_td                 | 0.008061352   |\n",
            "| losses_all              | 0.004522844   |\n",
            "| max 100 episode reward  | 150           |\n",
            "| mean 100 episode reward | 16.1          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1171247       |\n",
            "-------------------------------------------\n",
            " 59% 1175835/2000000 [2:07:42<1:24:50, 161.89it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.101         |\n",
            "| elapsed time            | 02:24:43      |\n",
            "| episodes                | 3130          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029948473  |\n",
            "| loss_margin             | 0.01199837    |\n",
            "| loss_n_td               | 0.00096628687 |\n",
            "| loss_td                 | 0.006875903   |\n",
            "| losses_all              | 0.0053116353  |\n",
            "| max 100 episode reward  | 150           |\n",
            "| mean 100 episode reward | 15.9          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1175839       |\n",
            "-------------------------------------------\n",
            " 59% 1180394/2000000 [2:08:11<1:22:50, 164.90it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 02:25:11     |\n",
            "| episodes                | 3140         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029943418 |\n",
            "| loss_margin             | 0.012658268  |\n",
            "| loss_n_td               | 0.0019877737 |\n",
            "| loss_td                 | 0.0135576995 |\n",
            "| losses_all              | 0.006389763  |\n",
            "| max 100 episode reward  | 148          |\n",
            "| mean 100 episode reward | 14.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1180405      |\n",
            "------------------------------------------\n",
            " 59% 1184839/2000000 [2:08:39<1:21:23, 166.93it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 02:25:39     |\n",
            "| episodes                | 3150         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.00299398   |\n",
            "| loss_margin             | 0.0064648986 |\n",
            "| loss_n_td               | 0.010866744  |\n",
            "| loss_td                 | 0.004184374  |\n",
            "| losses_all              | 0.0053940983 |\n",
            "| max 100 episode reward  | 48           |\n",
            "| mean 100 episode reward | 13.2         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1184851      |\n",
            "------------------------------------------\n",
            " 59% 1189105/2000000 [2:09:06<1:21:52, 165.08it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.1           |\n",
            "| elapsed time            | 02:26:06      |\n",
            "| episodes                | 3160          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029913671  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00022192785 |\n",
            "| loss_td                 | 0.02067316    |\n",
            "| losses_all              | 0.0056586256  |\n",
            "| max 100 episode reward  | 48            |\n",
            "| mean 100 episode reward | 13.1          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1189114       |\n",
            "-------------------------------------------\n",
            " 60% 1193626/2000000 [2:09:35<1:25:50, 156.57it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.1          |\n",
            "| elapsed time            | 02:26:35     |\n",
            "| episodes                | 3170         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030011693 |\n",
            "| loss_margin             | 0.0115888845 |\n",
            "| loss_n_td               | 0.001652915  |\n",
            "| loss_td                 | 0.009056669  |\n",
            "| losses_all              | 0.005785106  |\n",
            "| max 100 episode reward  | 48           |\n",
            "| mean 100 episode reward | 12.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1193637      |\n",
            "------------------------------------------\n",
            " 60% 1198736/2000000 [2:10:07<1:17:25, 172.48it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.1          |\n",
            "| elapsed time            | 02:27:07     |\n",
            "| episodes                | 3180         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029985006 |\n",
            "| loss_margin             | 0.0067077726 |\n",
            "| loss_n_td               | 0.0012977847 |\n",
            "| loss_td                 | 0.0058865664 |\n",
            "| losses_all              | 0.0047821626 |\n",
            "| max 100 episode reward  | 48           |\n",
            "| mean 100 episode reward | 12.9         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1198738      |\n",
            "------------------------------------------\n",
            " 60% 1199993/2000000 [2:10:15<1:20:23, 165.85it/s]saved checkpoint\n",
            " 60% 1203375/2000000 [2:10:36<1:19:13, 167.59it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0999       |\n",
            "| elapsed time            | 02:27:36     |\n",
            "| episodes                | 3190         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030033612 |\n",
            "| loss_margin             | 0.0017171577 |\n",
            "| loss_n_td               | 0.0009090974 |\n",
            "| loss_td                 | 0.012062739  |\n",
            "| losses_all              | 0.005113231  |\n",
            "| max 100 episode reward  | 48           |\n",
            "| mean 100 episode reward | 12.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1203377      |\n",
            "------------------------------------------\n",
            " 60% 1208125/2000000 [2:11:05<1:19:33, 165.90it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0997       |\n",
            "| elapsed time            | 02:28:06     |\n",
            "| episodes                | 3200         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029954242 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0002633723 |\n",
            "| loss_td                 | 0.0121503975 |\n",
            "| losses_all              | 0.005400053  |\n",
            "| max 100 episode reward  | 154          |\n",
            "| mean 100 episode reward | 14.2         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1208139      |\n",
            "------------------------------------------\n",
            " 61% 1213070/2000000 [2:11:36<1:18:26, 167.21it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0995       |\n",
            "| elapsed time            | 02:28:37     |\n",
            "| episodes                | 3210         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029932687 |\n",
            "| loss_margin             | 0.011995092  |\n",
            "| loss_n_td               | 0.0030073635 |\n",
            "| loss_td                 | 0.006191727  |\n",
            "| losses_all              | 0.0056441096 |\n",
            "| max 100 episode reward  | 154          |\n",
            "| mean 100 episode reward | 13.9         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1213073      |\n",
            "------------------------------------------\n",
            " 61% 1217709/2000000 [2:12:05<1:18:11, 166.73it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0994       |\n",
            "| elapsed time            | 02:29:05     |\n",
            "| episodes                | 3220         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029934202 |\n",
            "| loss_margin             | 0.0074132606 |\n",
            "| loss_n_td               | 0.0011297012 |\n",
            "| loss_td                 | 0.0073111504 |\n",
            "| losses_all              | 0.0048413705 |\n",
            "| max 100 episode reward  | 154          |\n",
            "| mean 100 episode reward | 13.9         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1217719      |\n",
            "------------------------------------------\n",
            " 61% 1222192/2000000 [2:12:33<1:16:05, 170.38it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0992        |\n",
            "| elapsed time            | 02:29:33      |\n",
            "| episodes                | 3230          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029957094  |\n",
            "| loss_margin             | 0.0050745867  |\n",
            "| loss_n_td               | 0.00024637836 |\n",
            "| loss_td                 | 0.01041382    |\n",
            "| losses_all              | 0.0052133286  |\n",
            "| max 100 episode reward  | 154           |\n",
            "| mean 100 episode reward | 13.9          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1222202       |\n",
            "-------------------------------------------\n",
            " 61% 1226786/2000000 [2:13:01<1:17:11, 166.95it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.099        |\n",
            "| elapsed time            | 02:30:02     |\n",
            "| episodes                | 3240         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029956389 |\n",
            "| loss_margin             | 0.002255544  |\n",
            "| loss_n_td               | 0.0013030046 |\n",
            "| loss_td                 | 0.013775955  |\n",
            "| losses_all              | 0.0054324092 |\n",
            "| max 100 episode reward  | 154          |\n",
            "| mean 100 episode reward | 13.4         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1226803      |\n",
            "------------------------------------------\n",
            " 62% 1231384/2000000 [2:13:30<1:14:20, 172.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0989       |\n",
            "| elapsed time            | 02:30:30     |\n",
            "| episodes                | 3250         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029967108 |\n",
            "| loss_margin             | 0.0021641254 |\n",
            "| loss_n_td               | 0.0002959698 |\n",
            "| loss_td                 | 0.009544866  |\n",
            "| losses_all              | 0.0052393293 |\n",
            "| max 100 episode reward  | 154          |\n",
            "| mean 100 episode reward | 13.3         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1231399      |\n",
            "------------------------------------------\n",
            " 62% 1236371/2000000 [2:14:01<1:15:14, 169.15it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0987       |\n",
            "| elapsed time            | 02:31:01     |\n",
            "| episodes                | 3260         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029961455 |\n",
            "| loss_margin             | 0.006675873  |\n",
            "| loss_n_td               | 0.003482584  |\n",
            "| loss_td                 | 0.0075729406 |\n",
            "| losses_all              | 0.005568783  |\n",
            "| max 100 episode reward  | 154          |\n",
            "| mean 100 episode reward | 14.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1236380      |\n",
            "------------------------------------------\n",
            " 62% 1240663/2000000 [2:14:27<1:14:58, 168.79it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0985       |\n",
            "| elapsed time            | 02:31:28     |\n",
            "| episodes                | 3270         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029934943 |\n",
            "| loss_margin             | 0.024537943  |\n",
            "| loss_n_td               | 0.0056536556 |\n",
            "| loss_td                 | 0.0055710003 |\n",
            "| losses_all              | 0.006655681  |\n",
            "| max 100 episode reward  | 154          |\n",
            "| mean 100 episode reward | 14.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1240677      |\n",
            "------------------------------------------\n",
            " 62% 1245701/2000000 [2:14:59<1:16:38, 164.04it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0984       |\n",
            "| elapsed time            | 02:32:00     |\n",
            "| episodes                | 3280         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029948743 |\n",
            "| loss_margin             | 0.011310257  |\n",
            "| loss_n_td               | 0.0010824575 |\n",
            "| loss_td                 | 0.022335697  |\n",
            "| losses_all              | 0.0070107337 |\n",
            "| max 100 episode reward  | 154          |\n",
            "| mean 100 episode reward | 14.9         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1245704      |\n",
            "------------------------------------------\n",
            " 62% 1249694/2000000 [2:15:24<1:14:29, 167.86it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0982        |\n",
            "| elapsed time            | 02:32:24      |\n",
            "| episodes                | 3290          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029947476  |\n",
            "| loss_margin             | 0.006814748   |\n",
            "| loss_n_td               | 0.00012934444 |\n",
            "| loss_td                 | 0.009185407   |\n",
            "| losses_all              | 0.0051284363  |\n",
            "| max 100 episode reward  | 154           |\n",
            "| mean 100 episode reward | 14.8          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1249711       |\n",
            "-------------------------------------------\n",
            " 63% 1253896/2000000 [2:15:50<1:12:39, 171.14it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0981       |\n",
            "| elapsed time            | 02:32:51     |\n",
            "| episodes                | 3300         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029921685 |\n",
            "| loss_margin             | 0.0081744455 |\n",
            "| loss_n_td               | 0.001314049  |\n",
            "| loss_td                 | 0.014720336  |\n",
            "| losses_all              | 0.006157219  |\n",
            "| max 100 episode reward  | 45           |\n",
            "| mean 100 episode reward | 13.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1253913      |\n",
            "------------------------------------------\n",
            " 63% 1258215/2000000 [2:16:17<1:13:47, 167.53it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.098         |\n",
            "| elapsed time            | 02:33:18      |\n",
            "| episodes                | 3310          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.003000293   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00044739756 |\n",
            "| loss_td                 | 0.013637206   |\n",
            "| losses_all              | 0.005269453   |\n",
            "| max 100 episode reward  | 45            |\n",
            "| mean 100 episode reward | 13.5          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1258228       |\n",
            "-------------------------------------------\n",
            " 63% 1262182/2000000 [2:16:42<1:13:38, 166.98it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0978       |\n",
            "| elapsed time            | 02:33:42     |\n",
            "| episodes                | 3320         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030036487 |\n",
            "| loss_margin             | 0.017003976  |\n",
            "| loss_n_td               | 0.001341792  |\n",
            "| loss_td                 | 0.015224557  |\n",
            "| losses_all              | 0.0071663326 |\n",
            "| max 100 episode reward  | 45           |\n",
            "| mean 100 episode reward | 13           |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1262188      |\n",
            "------------------------------------------\n",
            " 63% 1266097/2000000 [2:17:06<1:13:51, 165.61it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0977       |\n",
            "| elapsed time            | 02:34:07     |\n",
            "| episodes                | 3330         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029982473 |\n",
            "| loss_margin             | 0.008157536  |\n",
            "| loss_n_td               | 0.0012412636 |\n",
            "| loss_td                 | 0.011741959  |\n",
            "| losses_all              | 0.006304514  |\n",
            "| max 100 episode reward  | 45           |\n",
            "| mean 100 episode reward | 12.8         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1266113      |\n",
            "------------------------------------------\n",
            " 64% 1270444/2000000 [2:17:33<1:12:34, 167.54it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0976       |\n",
            "| elapsed time            | 02:34:33     |\n",
            "| episodes                | 3340         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002999656  |\n",
            "| loss_margin             | 0.014975674  |\n",
            "| loss_n_td               | 0.0025629278 |\n",
            "| loss_td                 | 0.010192535  |\n",
            "| losses_all              | 0.0058331965 |\n",
            "| max 100 episode reward  | 48           |\n",
            "| mean 100 episode reward | 13           |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1270448      |\n",
            "------------------------------------------\n",
            " 64% 1274353/2000000 [2:17:58<1:12:19, 167.22it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0974       |\n",
            "| elapsed time            | 02:34:58     |\n",
            "| episodes                | 3350         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030030974 |\n",
            "| loss_margin             | 0.0108467005 |\n",
            "| loss_n_td               | 0.0019118441 |\n",
            "| loss_td                 | 0.03049859   |\n",
            "| losses_all              | 0.0075449683 |\n",
            "| max 100 episode reward  | 48           |\n",
            "| mean 100 episode reward | 12.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1274369      |\n",
            "------------------------------------------\n",
            " 64% 1279206/2000000 [2:18:27<1:12:10, 166.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0973       |\n",
            "| elapsed time            | 02:35:28     |\n",
            "| episodes                | 3360         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030022026 |\n",
            "| loss_margin             | 0.02200966   |\n",
            "| loss_n_td               | 0.0029187375 |\n",
            "| loss_td                 | 0.01054025   |\n",
            "| losses_all              | 0.0063141203 |\n",
            "| max 100 episode reward  | 48           |\n",
            "| mean 100 episode reward | 12.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1279217      |\n",
            "------------------------------------------\n",
            " 64% 1283852/2000000 [2:18:56<1:10:33, 169.17it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0971       |\n",
            "| elapsed time            | 02:35:57     |\n",
            "| episodes                | 3370         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030037358 |\n",
            "| loss_margin             | 0.030934248  |\n",
            "| loss_n_td               | 0.0040972955 |\n",
            "| loss_td                 | 0.013515089  |\n",
            "| losses_all              | 0.007971781  |\n",
            "| max 100 episode reward  | 48           |\n",
            "| mean 100 episode reward | 12.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1283854      |\n",
            "------------------------------------------\n",
            " 64% 1288320/2000000 [2:19:24<1:08:38, 172.81it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.097        |\n",
            "| elapsed time            | 02:36:24     |\n",
            "| episodes                | 3380         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003001283  |\n",
            "| loss_margin             | 0.008463293  |\n",
            "| loss_n_td               | 0.0012090512 |\n",
            "| loss_td                 | 0.013092164  |\n",
            "| losses_all              | 0.005840729  |\n",
            "| max 100 episode reward  | 48           |\n",
            "| mean 100 episode reward | 11.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1288328      |\n",
            "------------------------------------------\n",
            " 65% 1292301/2000000 [2:19:49<1:10:24, 167.51it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0969        |\n",
            "| elapsed time            | 02:36:49      |\n",
            "| episodes                | 3390          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029991004  |\n",
            "| loss_margin             | 0.0032718182  |\n",
            "| loss_n_td               | 3.1945178e-06 |\n",
            "| loss_td                 | 0.030548735   |\n",
            "| losses_all              | 0.006595634   |\n",
            "| max 100 episode reward  | 48            |\n",
            "| mean 100 episode reward | 11.4          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1292310       |\n",
            "-------------------------------------------\n",
            " 65% 1296693/2000000 [2:20:17<1:11:27, 164.05it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0967        |\n",
            "| elapsed time            | 02:37:17      |\n",
            "| episodes                | 3400          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.003001997   |\n",
            "| loss_margin             | 0.007824756   |\n",
            "| loss_n_td               | 0.00041796098 |\n",
            "| loss_td                 | 0.0067143384  |\n",
            "| losses_all              | 0.0049564354  |\n",
            "| max 100 episode reward  | 48            |\n",
            "| mean 100 episode reward | 11.5          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1296700       |\n",
            "-------------------------------------------\n",
            " 65% 1299991/2000000 [2:20:37<1:09:00, 169.05it/s]saved checkpoint\n",
            " 65% 1300700/2000000 [2:20:42<1:08:45, 169.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0966       |\n",
            "| elapsed time            | 02:37:42     |\n",
            "| episodes                | 3410         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030007889 |\n",
            "| loss_margin             | 0.022048056  |\n",
            "| loss_n_td               | 0.0024954432 |\n",
            "| loss_td                 | 0.009966326  |\n",
            "| losses_all              | 0.0069487127 |\n",
            "| max 100 episode reward  | 48           |\n",
            "| mean 100 episode reward | 11.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1300709      |\n",
            "------------------------------------------\n",
            " 65% 1305375/2000000 [2:21:11<1:08:09, 169.85it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0965       |\n",
            "| elapsed time            | 02:38:11     |\n",
            "| episodes                | 3420         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002999364  |\n",
            "| loss_margin             | 0.01640968   |\n",
            "| loss_n_td               | 0.0016445315 |\n",
            "| loss_td                 | 0.009391444  |\n",
            "| losses_all              | 0.0063962257 |\n",
            "| max 100 episode reward  | 48           |\n",
            "| mean 100 episode reward | 11.8         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1305388      |\n",
            "------------------------------------------\n",
            " 65% 1309874/2000000 [2:21:39<1:09:57, 164.40it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0963        |\n",
            "| elapsed time            | 02:38:39      |\n",
            "| episodes                | 3430          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029959762  |\n",
            "| loss_margin             | 0.0010330155  |\n",
            "| loss_n_td               | 1.3505584e-07 |\n",
            "| loss_td                 | 0.007877365   |\n",
            "| losses_all              | 0.004374326   |\n",
            "| max 100 episode reward  | 48            |\n",
            "| mean 100 episode reward | 12.2          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1309877       |\n",
            "-------------------------------------------\n",
            " 66% 1314397/2000000 [2:22:07<1:08:49, 166.02it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0962       |\n",
            "| elapsed time            | 02:39:07     |\n",
            "| episodes                | 3440         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029971758 |\n",
            "| loss_margin             | 0.009165555  |\n",
            "| loss_n_td               | 0.0011715657 |\n",
            "| loss_td                 | 0.010702716  |\n",
            "| losses_all              | 0.005450159  |\n",
            "| max 100 episode reward  | 34           |\n",
            "| mean 100 episode reward | 12.3         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1314409      |\n",
            "------------------------------------------\n",
            " 66% 1319002/2000000 [2:22:35<1:07:48, 167.38it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.096        |\n",
            "| elapsed time            | 02:39:36     |\n",
            "| episodes                | 3450         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002988643  |\n",
            "| loss_margin             | 0.0029710792 |\n",
            "| loss_n_td               | 0.0020564469 |\n",
            "| loss_td                 | 0.010116171  |\n",
            "| losses_all              | 0.0048569897 |\n",
            "| max 100 episode reward  | 34           |\n",
            "| mean 100 episode reward | 12.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1319013      |\n",
            "------------------------------------------\n",
            " 66% 1323853/2000000 [2:23:05<1:07:22, 167.26it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0959       |\n",
            "| elapsed time            | 02:40:06     |\n",
            "| episodes                | 3460         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029937492 |\n",
            "| loss_margin             | 0.01502566   |\n",
            "| loss_n_td               | 0.002235051  |\n",
            "| loss_td                 | 0.009412351  |\n",
            "| losses_all              | 0.0057938597 |\n",
            "| max 100 episode reward  | 34           |\n",
            "| mean 100 episode reward | 12.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1323869      |\n",
            "------------------------------------------\n",
            " 66% 1328451/2000000 [2:23:34<1:05:38, 170.50it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0958        |\n",
            "| elapsed time            | 02:40:34      |\n",
            "| episodes                | 3470          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029895885  |\n",
            "| loss_margin             | 0.00087985024 |\n",
            "| loss_n_td               | 0.0012278163  |\n",
            "| loss_td                 | 0.012301003   |\n",
            "| losses_all              | 0.004803514   |\n",
            "| max 100 episode reward  | 34            |\n",
            "| mean 100 episode reward | 12.3          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1328457       |\n",
            "-------------------------------------------\n",
            " 67% 1333481/2000000 [2:24:05<1:07:37, 164.27it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0956        |\n",
            "| elapsed time            | 02:41:05      |\n",
            "| episodes                | 3480          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029837387  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00019984783 |\n",
            "| loss_td                 | 0.010973595   |\n",
            "| losses_all              | 0.004809107   |\n",
            "| max 100 episode reward  | 43            |\n",
            "| mean 100 episode reward | 13            |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1333482       |\n",
            "-------------------------------------------\n",
            " 67% 1337760/2000000 [2:24:32<1:05:23, 168.80it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0955       |\n",
            "| elapsed time            | 02:41:33     |\n",
            "| episodes                | 3490         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029856337 |\n",
            "| loss_margin             | 0.021567468  |\n",
            "| loss_n_td               | 0.0012962215 |\n",
            "| loss_td                 | 0.013319641  |\n",
            "| losses_all              | 0.006984883  |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 12.8         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1337773      |\n",
            "------------------------------------------\n",
            " 67% 1343754/2000000 [2:25:10<1:09:29, 157.39it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0953        |\n",
            "| elapsed time            | 02:42:11      |\n",
            "| episodes                | 3500          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029819747  |\n",
            "| loss_margin             | 0.004379511   |\n",
            "| loss_n_td               | 3.0070332e-05 |\n",
            "| loss_td                 | 0.018043518   |\n",
            "| losses_all              | 0.0055482034  |\n",
            "| max 100 episode reward  | 43            |\n",
            "| mean 100 episode reward | 13.1          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1343762       |\n",
            "-------------------------------------------\n",
            " 67% 1349001/2000000 [2:25:43<1:06:20, 163.55it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0951        |\n",
            "| elapsed time            | 02:42:44      |\n",
            "| episodes                | 3510          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029821554  |\n",
            "| loss_margin             | 0.010169245   |\n",
            "| loss_n_td               | 2.1362528e-05 |\n",
            "| loss_td                 | 0.016396852   |\n",
            "| losses_all              | 0.0053057335  |\n",
            "| max 100 episode reward  | 153           |\n",
            "| mean 100 episode reward | 15            |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1349011       |\n",
            "-------------------------------------------\n",
            " 68% 1353617/2000000 [2:26:12<1:07:28, 159.66it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.095        |\n",
            "| elapsed time            | 02:43:13     |\n",
            "| episodes                | 3520         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029815782 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0011548811 |\n",
            "| loss_td                 | 0.008828588  |\n",
            "| losses_all              | 0.004613938  |\n",
            "| max 100 episode reward  | 153          |\n",
            "| mean 100 episode reward | 14.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1353620      |\n",
            "------------------------------------------\n",
            " 68% 1357934/2000000 [2:26:39<1:04:33, 165.77it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0949       |\n",
            "| elapsed time            | 02:43:40     |\n",
            "| episodes                | 3530         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002986305  |\n",
            "| loss_margin             | 0.0108150225 |\n",
            "| loss_n_td               | 0.0011085934 |\n",
            "| loss_td                 | 0.008370401  |\n",
            "| losses_all              | 0.0055997726 |\n",
            "| max 100 episode reward  | 153          |\n",
            "| mean 100 episode reward | 14.8         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1357939      |\n",
            "------------------------------------------\n",
            " 68% 1362869/2000000 [2:27:11<1:04:31, 164.57it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0947        |\n",
            "| elapsed time            | 02:44:11      |\n",
            "| episodes                | 3540          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029806695  |\n",
            "| loss_margin             | 0.010527659   |\n",
            "| loss_n_td               | 0.00019348064 |\n",
            "| loss_td                 | 0.017494092   |\n",
            "| losses_all              | 0.0061158463  |\n",
            "| max 100 episode reward  | 153           |\n",
            "| mean 100 episode reward | 14.8          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1362874       |\n",
            "-------------------------------------------\n",
            " 68% 1368115/2000000 [2:27:44<1:02:41, 167.99it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0946       |\n",
            "| elapsed time            | 02:44:44     |\n",
            "| episodes                | 3550         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029855482 |\n",
            "| loss_margin             | 0.003808722  |\n",
            "| loss_n_td               | 0.017990023  |\n",
            "| loss_td                 | 0.019995654  |\n",
            "| losses_all              | 0.0065337736 |\n",
            "| max 100 episode reward  | 153          |\n",
            "| mean 100 episode reward | 15           |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1368120      |\n",
            "------------------------------------------\n",
            " 69% 1372850/2000000 [2:28:14<1:06:36, 156.94it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0945       |\n",
            "| elapsed time            | 02:45:14     |\n",
            "| episodes                | 3560         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029889483 |\n",
            "| loss_margin             | 0.0024911724 |\n",
            "| loss_n_td               | 0.0027975473 |\n",
            "| loss_td                 | 0.009364405  |\n",
            "| losses_all              | 0.0048531615 |\n",
            "| max 100 episode reward  | 153          |\n",
            "| mean 100 episode reward | 15           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1372861      |\n",
            "------------------------------------------\n",
            " 69% 1377453/2000000 [2:28:43<1:03:51, 162.49it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0943       |\n",
            "| elapsed time            | 02:45:43     |\n",
            "| episodes                | 3570         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029957362 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010632392 |\n",
            "| loss_td                 | 0.011447586  |\n",
            "| losses_all              | 0.0052409386 |\n",
            "| max 100 episode reward  | 153          |\n",
            "| mean 100 episode reward | 15.1         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1377466      |\n",
            "------------------------------------------\n",
            " 69% 1381693/2000000 [2:29:10<1:01:45, 166.86it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0942       |\n",
            "| elapsed time            | 02:46:10     |\n",
            "| episodes                | 3580         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029853163 |\n",
            "| loss_margin             | 0.017542975  |\n",
            "| loss_n_td               | 0.0035434181 |\n",
            "| loss_td                 | 0.03589196   |\n",
            "| losses_all              | 0.008250875  |\n",
            "| max 100 episode reward  | 153          |\n",
            "| mean 100 episode reward | 14.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1381699      |\n",
            "------------------------------------------\n",
            " 69% 1386031/2000000 [2:29:37<1:03:41, 160.67it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0941       |\n",
            "| elapsed time            | 02:46:37     |\n",
            "| episodes                | 3590         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002989533  |\n",
            "| loss_margin             | 0.008151336  |\n",
            "| loss_n_td               | 0.0032572076 |\n",
            "| loss_td                 | 0.010240253  |\n",
            "| losses_all              | 0.0055067497 |\n",
            "| max 100 episode reward  | 153          |\n",
            "| mean 100 episode reward | 14.7         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1386039      |\n",
            "------------------------------------------\n",
            " 70% 1390705/2000000 [2:30:07<1:01:24, 165.35it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.094         |\n",
            "| elapsed time            | 02:47:07      |\n",
            "| episodes                | 3600          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029943376  |\n",
            "| loss_margin             | 0.003681615   |\n",
            "| loss_n_td               | 0.00045577384 |\n",
            "| loss_td                 | 0.07769274    |\n",
            "| losses_all              | 0.010272581   |\n",
            "| max 100 episode reward  | 153           |\n",
            "| mean 100 episode reward | 14.2          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1390713       |\n",
            "-------------------------------------------\n",
            " 70% 1395423/2000000 [2:30:37<1:01:25, 164.05it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0939        |\n",
            "| elapsed time            | 02:47:38      |\n",
            "| episodes                | 3610          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029913897  |\n",
            "| loss_margin             | 0.003068842   |\n",
            "| loss_n_td               | 0.00014669783 |\n",
            "| loss_td                 | 0.024392635   |\n",
            "| losses_all              | 0.0060061608  |\n",
            "| max 100 episode reward  | 34            |\n",
            "| mean 100 episode reward | 13            |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1395428       |\n",
            "-------------------------------------------\n",
            " 70% 1399718/2000000 [2:31:04<1:03:30, 157.52it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0937       |\n",
            "| elapsed time            | 02:48:05     |\n",
            "| episodes                | 3620         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029923706 |\n",
            "| loss_margin             | 0.003796745  |\n",
            "| loss_n_td               | 0.0011492285 |\n",
            "| loss_td                 | 0.007938241  |\n",
            "| losses_all              | 0.0046951207 |\n",
            "| max 100 episode reward  | 34           |\n",
            "| mean 100 episode reward | 13.1         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1399731      |\n",
            "------------------------------------------\n",
            " 70% 1399989/2000000 [2:31:07<1:06:10, 151.11it/s]saved checkpoint\n",
            " 70% 1403779/2000000 [2:31:31<58:58, 168.48it/s]  ------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0936       |\n",
            "| elapsed time            | 02:48:31     |\n",
            "| episodes                | 3630         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030010045 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0029044845 |\n",
            "| loss_td                 | 0.008314559  |\n",
            "| losses_all              | 0.004690579  |\n",
            "| max 100 episode reward  | 30           |\n",
            "| mean 100 episode reward | 12.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1403781      |\n",
            "------------------------------------------\n",
            " 70% 1408075/2000000 [2:31:58<58:51, 167.63it/s]  -------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0935        |\n",
            "| elapsed time            | 02:48:58      |\n",
            "| episodes                | 3640          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029973919  |\n",
            "| loss_margin             | 0.00015512481 |\n",
            "| loss_n_td               | 0.00019378847 |\n",
            "| loss_td                 | 0.012152785   |\n",
            "| losses_all              | 0.004670185   |\n",
            "| max 100 episode reward  | 30            |\n",
            "| mean 100 episode reward | 12.3          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1408083       |\n",
            "-------------------------------------------\n",
            " 71% 1413485/2000000 [2:32:32<59:14, 165.03it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0934        |\n",
            "| elapsed time            | 02:49:32      |\n",
            "| episodes                | 3650          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029965932  |\n",
            "| loss_margin             | 0.015754785   |\n",
            "| loss_n_td               | 0.00052999123 |\n",
            "| loss_td                 | 0.00884947    |\n",
            "| losses_all              | 0.0058666305  |\n",
            "| max 100 episode reward  | 47            |\n",
            "| mean 100 episode reward | 13.1          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1413485       |\n",
            "-------------------------------------------\n",
            " 71% 1419192/2000000 [2:33:08<57:30, 168.34it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0932       |\n",
            "| elapsed time            | 02:50:08     |\n",
            "| episodes                | 3660         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030008263 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0018806765 |\n",
            "| loss_td                 | 0.0117691485 |\n",
            "| losses_all              | 0.0044947253 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 15.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1419199      |\n",
            "------------------------------------------\n",
            " 71% 1423418/2000000 [2:33:34<58:10, 165.20it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0931       |\n",
            "| elapsed time            | 02:50:35     |\n",
            "| episodes                | 3670         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029953872 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.0084292535 |\n",
            "| losses_all              | 0.0041755172 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 15.2         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1423430      |\n",
            "------------------------------------------\n",
            " 71% 1429117/2000000 [2:34:10<57:54, 164.32it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0929       |\n",
            "| elapsed time            | 02:51:10     |\n",
            "| episodes                | 3680         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029991174 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010945624 |\n",
            "| loss_td                 | 0.014644589  |\n",
            "| losses_all              | 0.0051885825 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 16.1         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1429129      |\n",
            "------------------------------------------\n",
            " 72% 1434612/2000000 [2:34:44<56:23, 167.11it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0928       |\n",
            "| elapsed time            | 02:51:45     |\n",
            "| episodes                | 3690         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002997443  |\n",
            "| loss_margin             | 0.01045784   |\n",
            "| loss_n_td               | 0.0013565009 |\n",
            "| loss_td                 | 0.008932391  |\n",
            "| losses_all              | 0.0051870216 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 16.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1434619      |\n",
            "------------------------------------------\n",
            " 72% 1439553/2000000 [2:35:15<56:30, 165.32it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0927       |\n",
            "| elapsed time            | 02:52:16     |\n",
            "| episodes                | 3700         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029931706 |\n",
            "| loss_margin             | 0.0013697892 |\n",
            "| loss_n_td               | 0.0045367987 |\n",
            "| loss_td                 | 0.01245838   |\n",
            "| losses_all              | 0.0052141994 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 16.7         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1439556      |\n",
            "------------------------------------------\n",
            " 72% 1445373/2000000 [2:35:52<55:53, 165.41it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0925       |\n",
            "| elapsed time            | 02:52:52     |\n",
            "| episodes                | 3710         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002997749  |\n",
            "| loss_margin             | 0.0002530776 |\n",
            "| loss_n_td               | 0.0013756223 |\n",
            "| loss_td                 | 0.015254144  |\n",
            "| losses_all              | 0.0058296705 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 17.6         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1445386      |\n",
            "------------------------------------------\n",
            " 73% 1450044/2000000 [2:36:21<55:29, 165.16it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0924       |\n",
            "| elapsed time            | 02:53:21     |\n",
            "| episodes                | 3720         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029988524 |\n",
            "| loss_margin             | 0.013191275  |\n",
            "| loss_n_td               | 0.0008771511 |\n",
            "| loss_td                 | 0.01880021   |\n",
            "| losses_all              | 0.0071437517 |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 17.6         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1450048      |\n",
            "------------------------------------------\n",
            " 73% 1454793/2000000 [2:36:51<54:30, 166.70it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.0923      |\n",
            "| elapsed time            | 02:53:51    |\n",
            "| episodes                | 3730        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.003002014 |\n",
            "| loss_margin             | 0.007905606 |\n",
            "| loss_n_td               | 0.008383573 |\n",
            "| loss_td                 | 0.009066816 |\n",
            "| losses_all              | 0.005666569 |\n",
            "| max 100 episode reward  | 232         |\n",
            "| mean 100 episode reward | 18.1        |\n",
            "| min 100 episode reward  | 2           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1454808     |\n",
            "-----------------------------------------\n",
            " 73% 1459981/2000000 [2:37:23<54:33, 164.97it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0921        |\n",
            "| elapsed time            | 02:54:23      |\n",
            "| episodes                | 3740          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0030007076  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00022364373 |\n",
            "| loss_td                 | 0.019276094   |\n",
            "| losses_all              | 0.0053240834  |\n",
            "| max 100 episode reward  | 232           |\n",
            "| mean 100 episode reward | 18.3          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1459986       |\n",
            "-------------------------------------------\n",
            " 73% 1465653/2000000 [2:37:58<54:56, 162.11it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.092         |\n",
            "| elapsed time            | 02:54:59      |\n",
            "| episodes                | 3750          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0030029735  |\n",
            "| loss_margin             | 0.00713405    |\n",
            "| loss_n_td               | 0.00028351208 |\n",
            "| loss_td                 | 0.013564517   |\n",
            "| losses_all              | 0.0054355673  |\n",
            "| max 100 episode reward  | 232           |\n",
            "| mean 100 episode reward | 17.9          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1465659       |\n",
            "-------------------------------------------\n",
            " 74% 1470322/2000000 [2:38:27<53:38, 164.59it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0919       |\n",
            "| elapsed time            | 02:55:28     |\n",
            "| episodes                | 3760         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030040753 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0037789172 |\n",
            "| loss_td                 | 0.009457009  |\n",
            "| losses_all              | 0.0047665276 |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 15.8         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1470339      |\n",
            "------------------------------------------\n",
            " 74% 1475155/2000000 [2:38:58<52:09, 167.69it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0918       |\n",
            "| elapsed time            | 02:55:58     |\n",
            "| episodes                | 3770         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029976782 |\n",
            "| loss_margin             | 0.007829785  |\n",
            "| loss_n_td               | 0.0018235893 |\n",
            "| loss_td                 | 0.044444527  |\n",
            "| losses_all              | 0.007118352  |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 16           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1475171      |\n",
            "------------------------------------------\n",
            " 74% 1479057/2000000 [2:39:23<53:06, 163.47it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0917       |\n",
            "| elapsed time            | 02:56:23     |\n",
            "| episodes                | 3780         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.003000725  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 2.4461e-05   |\n",
            "| loss_td                 | 0.03331856   |\n",
            "| losses_all              | 0.0069093094 |\n",
            "| max 100 episode reward  | 42           |\n",
            "| mean 100 episode reward | 15           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1479070      |\n",
            "------------------------------------------\n",
            " 74% 1484509/2000000 [2:39:57<52:41, 163.04it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0915       |\n",
            "| elapsed time            | 02:56:57     |\n",
            "| episodes                | 3790         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0030025952 |\n",
            "| loss_margin             | 0.020791166  |\n",
            "| loss_n_td               | 0.0022156532 |\n",
            "| loss_td                 | 0.0119790565 |\n",
            "| losses_all              | 0.0062299743 |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 15.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1484510      |\n",
            "------------------------------------------\n",
            " 74% 1489789/2000000 [2:40:30<52:40, 161.42it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0914        |\n",
            "| elapsed time            | 02:57:31      |\n",
            "| episodes                | 3800          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.002994793   |\n",
            "| loss_margin             | 0.006288536   |\n",
            "| loss_n_td               | 0.00045964605 |\n",
            "| loss_td                 | 0.005840129   |\n",
            "| losses_all              | 0.0043252874  |\n",
            "| max 100 episode reward  | 43            |\n",
            "| mean 100 episode reward | 15.8          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1489805       |\n",
            "-------------------------------------------\n",
            " 75% 1495335/2000000 [2:41:05<50:08, 167.72it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0913       |\n",
            "| elapsed time            | 02:58:06     |\n",
            "| episodes                | 3810         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029848572 |\n",
            "| loss_margin             | 0.010993211  |\n",
            "| loss_n_td               | 0.0001249926 |\n",
            "| loss_td                 | 0.008247881  |\n",
            "| losses_all              | 0.005166323  |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 15.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1495347      |\n",
            "------------------------------------------\n",
            " 75% 1499670/2000000 [2:41:32<50:27, 165.24it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0912       |\n",
            "| elapsed time            | 02:58:33     |\n",
            "| episodes                | 3820         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029770418 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.062101755  |\n",
            "| losses_all              | 0.014439875  |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 15.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1499683      |\n",
            "------------------------------------------\n",
            " 75% 1499990/2000000 [2:41:35<52:29, 158.75it/s]saved checkpoint\n",
            " 75% 1504894/2000000 [2:42:05<50:21, 163.86it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.091        |\n",
            "| elapsed time            | 02:59:06     |\n",
            "| episodes                | 3830         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029747577 |\n",
            "| loss_margin             | 0.012251191  |\n",
            "| loss_n_td               | 0.0008857482 |\n",
            "| loss_td                 | 0.008458691  |\n",
            "| losses_all              | 0.005200973  |\n",
            "| max 100 episode reward  | 43           |\n",
            "| mean 100 episode reward | 15.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1504904      |\n",
            "------------------------------------------\n",
            " 76% 1510068/2000000 [2:42:37<47:59, 170.15it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0909       |\n",
            "| elapsed time            | 02:59:38     |\n",
            "| episodes                | 3840         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029703467 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0015186714 |\n",
            "| loss_td                 | 0.011667324  |\n",
            "| losses_all              | 0.005192308  |\n",
            "| max 100 episode reward  | 162          |\n",
            "| mean 100 episode reward | 17.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1510069      |\n",
            "------------------------------------------\n",
            " 76% 1514593/2000000 [2:43:06<50:15, 161.00it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0908       |\n",
            "| elapsed time            | 03:00:06     |\n",
            "| episodes                | 3850         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029709854 |\n",
            "| loss_margin             | 0.024747767  |\n",
            "| loss_n_td               | 0.0044268332 |\n",
            "| loss_td                 | 0.017906917  |\n",
            "| losses_all              | 0.008360707  |\n",
            "| max 100 episode reward  | 162          |\n",
            "| mean 100 episode reward | 17.1         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1514596      |\n",
            "------------------------------------------\n",
            " 76% 1519728/2000000 [2:43:37<47:02, 170.18it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0907       |\n",
            "| elapsed time            | 03:00:38     |\n",
            "| episodes                | 3860         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029638023 |\n",
            "| loss_margin             | 0.0067617297 |\n",
            "| loss_n_td               | 0.0016344255 |\n",
            "| loss_td                 | 0.010483937  |\n",
            "| losses_all              | 0.005141695  |\n",
            "| max 100 episode reward  | 162          |\n",
            "| mean 100 episode reward | 17.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1519736      |\n",
            "------------------------------------------\n",
            " 76% 1524571/2000000 [2:44:07<46:47, 169.32it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0906        |\n",
            "| elapsed time            | 03:01:08      |\n",
            "| episodes                | 3870          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029609308  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 2.9450008e-05 |\n",
            "| loss_td                 | 0.008131703   |\n",
            "| losses_all              | 0.0041255737  |\n",
            "| max 100 episode reward  | 162           |\n",
            "| mean 100 episode reward | 17.9          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1524579       |\n",
            "-------------------------------------------\n",
            " 77% 1530017/2000000 [2:44:41<46:47, 167.38it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0904        |\n",
            "| elapsed time            | 03:01:42      |\n",
            "| episodes                | 3880          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029656477  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00016713922 |\n",
            "| loss_td                 | 0.015466787   |\n",
            "| losses_all              | 0.0055779987  |\n",
            "| max 100 episode reward  | 162           |\n",
            "| mean 100 episode reward | 19            |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1530025       |\n",
            "-------------------------------------------\n",
            " 77% 1534694/2000000 [2:45:10<47:00, 164.95it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0903       |\n",
            "| elapsed time            | 03:02:11     |\n",
            "| episodes                | 3890         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029724767 |\n",
            "| loss_margin             | 0.018153984  |\n",
            "| loss_n_td               | 0.0025221524 |\n",
            "| loss_td                 | 0.013297953  |\n",
            "| losses_all              | 0.0065691285 |\n",
            "| max 100 episode reward  | 162          |\n",
            "| mean 100 episode reward | 19.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1534696      |\n",
            "------------------------------------------\n",
            " 77% 1540363/2000000 [2:45:45<48:12, 158.91it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0902       |\n",
            "| elapsed time            | 03:02:46     |\n",
            "| episodes                | 3900         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029701611 |\n",
            "| loss_margin             | 0.0020405967 |\n",
            "| loss_n_td               | 0.0018038086 |\n",
            "| loss_td                 | 0.02508262   |\n",
            "| losses_all              | 0.006152465  |\n",
            "| max 100 episode reward  | 162          |\n",
            "| mean 100 episode reward | 19.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1540371      |\n",
            "------------------------------------------\n",
            " 77% 1544801/2000000 [2:46:13<46:21, 163.68it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0901        |\n",
            "| elapsed time            | 03:03:14      |\n",
            "| episodes                | 3910          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029724364  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00042474945 |\n",
            "| loss_td                 | 0.010227091   |\n",
            "| losses_all              | 0.0047289487  |\n",
            "| max 100 episode reward  | 162           |\n",
            "| mean 100 episode reward | 19            |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1544807       |\n",
            "-------------------------------------------\n",
            " 78% 1550071/2000000 [2:46:46<44:37, 168.06it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.09          |\n",
            "| elapsed time            | 03:03:47      |\n",
            "| episodes                | 3920          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029631099  |\n",
            "| loss_margin             | 0.00078553706 |\n",
            "| loss_n_td               | 0.00042940752 |\n",
            "| loss_td                 | 0.011670869   |\n",
            "| losses_all              | 0.005269932   |\n",
            "| max 100 episode reward  | 162           |\n",
            "| mean 100 episode reward | 19.4          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1550084       |\n",
            "-------------------------------------------\n",
            " 78% 1555364/2000000 [2:47:19<44:31, 166.42it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0898       |\n",
            "| elapsed time            | 03:04:20     |\n",
            "| episodes                | 3930         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002965075  |\n",
            "| loss_margin             | 0.0022353008 |\n",
            "| loss_n_td               | 0.0013370158 |\n",
            "| loss_td                 | 0.017320363  |\n",
            "| losses_all              | 0.0053800414 |\n",
            "| max 100 episode reward  | 162          |\n",
            "| mean 100 episode reward | 19.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1555370      |\n",
            "------------------------------------------\n",
            " 78% 1559737/2000000 [2:47:46<44:49, 163.68it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0897       |\n",
            "| elapsed time            | 03:04:47     |\n",
            "| episodes                | 3940         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029622533 |\n",
            "| loss_margin             | 0.024239365  |\n",
            "| loss_n_td               | 0.0015246831 |\n",
            "| loss_td                 | 0.027351815  |\n",
            "| losses_all              | 0.007715442  |\n",
            "| max 100 episode reward  | 149          |\n",
            "| mean 100 episode reward | 17.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1559746      |\n",
            "------------------------------------------\n",
            " 78% 1564084/2000000 [2:48:14<43:07, 168.46it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0896        |\n",
            "| elapsed time            | 03:05:14      |\n",
            "| episodes                | 3950          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.002970108   |\n",
            "| loss_margin             | 0.00027191266 |\n",
            "| loss_n_td               | 0.0020508764  |\n",
            "| loss_td                 | 0.18911406    |\n",
            "| losses_all              | 0.010571849   |\n",
            "| max 100 episode reward  | 149           |\n",
            "| mean 100 episode reward | 17.2          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1564098       |\n",
            "-------------------------------------------\n",
            " 78% 1569111/2000000 [2:48:45<42:18, 169.75it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0895       |\n",
            "| elapsed time            | 03:05:45     |\n",
            "| episodes                | 3960         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029712569 |\n",
            "| loss_margin             | 0.0052211992 |\n",
            "| loss_n_td               | 0.0018540642 |\n",
            "| loss_td                 | 0.01917041   |\n",
            "| losses_all              | 0.005856878  |\n",
            "| max 100 episode reward  | 149          |\n",
            "| mean 100 episode reward | 17.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1569119      |\n",
            "------------------------------------------\n",
            " 79% 1573923/2000000 [2:49:15<42:17, 167.90it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0894       |\n",
            "| elapsed time            | 03:06:15     |\n",
            "| episodes                | 3970         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029742126 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0009637024 |\n",
            "| loss_td                 | 0.032825135  |\n",
            "| losses_all              | 0.006572839  |\n",
            "| max 100 episode reward  | 149          |\n",
            "| mean 100 episode reward | 17.1         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1573928      |\n",
            "------------------------------------------\n",
            " 79% 1579401/2000000 [2:49:48<42:36, 164.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0893       |\n",
            "| elapsed time            | 03:06:49     |\n",
            "| episodes                | 3980         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029769256 |\n",
            "| loss_margin             | 0.015379857  |\n",
            "| loss_n_td               | 0.0030949013 |\n",
            "| loss_td                 | 0.008745375  |\n",
            "| losses_all              | 0.005624345  |\n",
            "| max 100 episode reward  | 149          |\n",
            "| mean 100 episode reward | 16.9         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1579415      |\n",
            "------------------------------------------\n",
            " 79% 1585024/2000000 [2:50:23<40:34, 170.49it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0892       |\n",
            "| elapsed time            | 03:07:24     |\n",
            "| episodes                | 3990         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029774697 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.01038572   |\n",
            "| loss_td                 | 0.028534878  |\n",
            "| losses_all              | 0.0056901323 |\n",
            "| max 100 episode reward  | 51           |\n",
            "| mean 100 episode reward | 16.3         |\n",
            "| min 100 episode reward  | 5            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1585028      |\n",
            "------------------------------------------\n",
            " 79% 1589784/2000000 [2:50:53<40:13, 169.97it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0891        |\n",
            "| elapsed time            | 03:07:53      |\n",
            "| episodes                | 4000          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0029724545  |\n",
            "| loss_margin             | 0.014956102   |\n",
            "| loss_n_td               | 0.00065551366 |\n",
            "| loss_td                 | 0.008975463   |\n",
            "| losses_all              | 0.0055500194  |\n",
            "| max 100 episode reward  | 51            |\n",
            "| mean 100 episode reward | 16            |\n",
            "| min 100 episode reward  | 5             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1589788       |\n",
            "-------------------------------------------\n",
            " 80% 1594942/2000000 [2:51:25<41:02, 164.46it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.089        |\n",
            "| elapsed time            | 03:08:26     |\n",
            "| episodes                | 4010         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029693278 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.008149889  |\n",
            "| losses_all              | 0.0042914907 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 17.5         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1594945      |\n",
            "------------------------------------------\n",
            " 80% 1599992/2000000 [2:51:57<39:58, 166.75it/s]saved checkpoint\n",
            " 80% 1600501/2000000 [2:52:00<40:16, 165.29it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0889       |\n",
            "| elapsed time            | 03:09:01     |\n",
            "| episodes                | 4020         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002967378  |\n",
            "| loss_margin             | 0.007866975  |\n",
            "| loss_n_td               | 0.0009579285 |\n",
            "| loss_td                 | 0.01710579   |\n",
            "| losses_all              | 0.006530466  |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 17.8         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1600501      |\n",
            "------------------------------------------\n",
            " 80% 1605775/2000000 [2:52:33<39:08, 167.85it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0887       |\n",
            "| elapsed time            | 03:09:34     |\n",
            "| episodes                | 4030         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.00296348   |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0012262281 |\n",
            "| loss_td                 | 0.025442088  |\n",
            "| losses_all              | 0.0055973986 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 18.3         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1605786      |\n",
            "------------------------------------------\n",
            " 81% 1610513/2000000 [2:53:02<38:41, 167.75it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0886       |\n",
            "| elapsed time            | 03:10:03     |\n",
            "| episodes                | 4040         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029591757 |\n",
            "| loss_margin             | 0.0058982857 |\n",
            "| loss_n_td               | 0.0002862996 |\n",
            "| loss_td                 | 0.01102042   |\n",
            "| losses_all              | 0.0051054163 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 18.2         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1610529      |\n",
            "------------------------------------------\n",
            " 81% 1616277/2000000 [2:53:38<38:35, 165.72it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0885       |\n",
            "| elapsed time            | 03:10:39     |\n",
            "| episodes                | 4050         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029611373 |\n",
            "| loss_margin             | 0.006549295  |\n",
            "| loss_n_td               | 0.0003008606 |\n",
            "| loss_td                 | 0.005911679  |\n",
            "| losses_all              | 0.004465753  |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 18.8         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1616286      |\n",
            "------------------------------------------\n",
            " 81% 1621441/2000000 [2:54:10<38:15, 164.90it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0884       |\n",
            "| elapsed time            | 03:11:11     |\n",
            "| episodes                | 4060         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029578384 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0041106255 |\n",
            "| loss_td                 | 0.027775202  |\n",
            "| losses_all              | 0.0068941647 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 18.2         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1621455      |\n",
            "------------------------------------------\n",
            " 81% 1625826/2000000 [2:54:38<37:23, 166.79it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0883       |\n",
            "| elapsed time            | 03:11:38     |\n",
            "| episodes                | 4070         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002945985  |\n",
            "| loss_margin             | 0.0127658285 |\n",
            "| loss_n_td               | 0.0026161522 |\n",
            "| loss_td                 | 0.022114985  |\n",
            "| losses_all              | 0.0062940377 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 17.7         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1625841      |\n",
            "------------------------------------------\n",
            " 82% 1630070/2000000 [2:55:04<38:13, 161.32it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0882       |\n",
            "| elapsed time            | 03:12:05     |\n",
            "| episodes                | 4080         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029408669 |\n",
            "| loss_margin             | 0.011121837  |\n",
            "| loss_n_td               | 0.0015697848 |\n",
            "| loss_td                 | 0.012481808  |\n",
            "| losses_all              | 0.0060106684 |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 17.2         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1630087      |\n",
            "------------------------------------------\n",
            " 82% 1634874/2000000 [2:55:34<37:02, 164.27it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0881       |\n",
            "| elapsed time            | 03:12:35     |\n",
            "| episodes                | 4090         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029402056 |\n",
            "| loss_margin             | 0.0047158487 |\n",
            "| loss_n_td               | 0.0024742945 |\n",
            "| loss_td                 | 0.052140236  |\n",
            "| losses_all              | 0.008651026  |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 16.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1634882      |\n",
            "------------------------------------------\n",
            " 82% 1639620/2000000 [2:56:04<34:57, 171.80it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.088        |\n",
            "| elapsed time            | 03:13:04     |\n",
            "| episodes                | 4100         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029369658 |\n",
            "| loss_margin             | 0.0082114525 |\n",
            "| loss_n_td               | 0.0005062106 |\n",
            "| loss_td                 | 0.0058116345 |\n",
            "| losses_all              | 0.004505     |\n",
            "| max 100 episode reward  | 150          |\n",
            "| mean 100 episode reward | 16.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1639630      |\n",
            "------------------------------------------\n",
            " 82% 1643093/2000000 [2:56:26<35:39, 166.79it/s]saved best model\n",
            " 82% 1644888/2000000 [2:56:37<36:49, 160.72it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0879       |\n",
            "| elapsed time            | 03:13:38     |\n",
            "| episodes                | 4110         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029324852 |\n",
            "| loss_margin             | 0.017784659  |\n",
            "| loss_n_td               | 0.0011752857 |\n",
            "| loss_td                 | 0.008021654  |\n",
            "| losses_all              | 0.006011703  |\n",
            "| max 100 episode reward  | 287          |\n",
            "| mean 100 episode reward | 17.5         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1644903      |\n",
            "------------------------------------------\n",
            " 82% 1649653/2000000 [2:57:07<35:24, 164.89it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0878       |\n",
            "| elapsed time            | 03:14:07     |\n",
            "| episodes                | 4120         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029280777 |\n",
            "| loss_margin             | 0.0068765767 |\n",
            "| loss_n_td               | 0.0009210029 |\n",
            "| loss_td                 | 0.02102534   |\n",
            "| losses_all              | 0.005786961  |\n",
            "| max 100 episode reward  | 287          |\n",
            "| mean 100 episode reward | 16.8         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1649669      |\n",
            "------------------------------------------\n",
            " 83% 1654551/2000000 [2:57:37<34:13, 168.23it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0877       |\n",
            "| elapsed time            | 03:14:38     |\n",
            "| episodes                | 4130         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029198895 |\n",
            "| loss_margin             | 0.038908064  |\n",
            "| loss_n_td               | 0.0041530845 |\n",
            "| loss_td                 | 0.019131986  |\n",
            "| losses_all              | 0.007866137  |\n",
            "| max 100 episode reward  | 287          |\n",
            "| mean 100 episode reward | 16.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1654562      |\n",
            "------------------------------------------\n",
            " 83% 1659550/2000000 [2:58:08<33:37, 168.77it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0876       |\n",
            "| elapsed time            | 03:15:09     |\n",
            "| episodes                | 4140         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002916037  |\n",
            "| loss_margin             | 0.0013202131 |\n",
            "| loss_n_td               | 0.0035861367 |\n",
            "| loss_td                 | 0.013129554  |\n",
            "| losses_all              | 0.0053660516 |\n",
            "| max 100 episode reward  | 287          |\n",
            "| mean 100 episode reward | 16.8         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1659566      |\n",
            "------------------------------------------\n",
            " 83% 1665058/2000000 [2:58:42<33:04, 168.79it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0875       |\n",
            "| elapsed time            | 03:15:43     |\n",
            "| episodes                | 4150         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029138152 |\n",
            "| loss_margin             | 0.0041790307 |\n",
            "| loss_n_td               | 0.0034126376 |\n",
            "| loss_td                 | 0.023892038  |\n",
            "| losses_all              | 0.0066608693 |\n",
            "| max 100 episode reward  | 287          |\n",
            "| mean 100 episode reward | 16.9         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1665073      |\n",
            "------------------------------------------\n",
            " 83% 1669577/2000000 [2:59:10<33:43, 163.26it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0874       |\n",
            "| elapsed time            | 03:16:11     |\n",
            "| episodes                | 4160         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029121104 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0011113549 |\n",
            "| loss_td                 | 0.023817686  |\n",
            "| losses_all              | 0.006136412  |\n",
            "| max 100 episode reward  | 287          |\n",
            "| mean 100 episode reward | 17.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1669581      |\n",
            "------------------------------------------\n",
            " 84% 1670395/2000000 [2:59:16<34:35, 158.79it/s]saved best model\n",
            " 84% 1675047/2000000 [2:59:44<32:15, 167.87it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0873       |\n",
            "| elapsed time            | 03:16:44     |\n",
            "| episodes                | 4170         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029162874 |\n",
            "| loss_margin             | 0.013889089  |\n",
            "| loss_n_td               | 0.0025891343 |\n",
            "| loss_td                 | 0.011713253  |\n",
            "| losses_all              | 0.0057471646 |\n",
            "| max 100 episode reward  | 294          |\n",
            "| mean 100 episode reward | 20.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1675053      |\n",
            "------------------------------------------\n",
            " 84% 1679834/2000000 [3:00:14<32:11, 165.73it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0872        |\n",
            "| elapsed time            | 03:17:14      |\n",
            "| episodes                | 4180          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.002914469   |\n",
            "| loss_margin             | 0.005351085   |\n",
            "| loss_n_td               | 6.8391455e-05 |\n",
            "| loss_td                 | 0.024766501   |\n",
            "| losses_all              | 0.0055441884  |\n",
            "| max 100 episode reward  | 294           |\n",
            "| mean 100 episode reward | 20.6          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1679836       |\n",
            "-------------------------------------------\n",
            " 84% 1684205/2000000 [3:00:41<31:57, 164.68it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0871       |\n",
            "| elapsed time            | 03:17:41     |\n",
            "| episodes                | 4190         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029060396 |\n",
            "| loss_margin             | 0.0022308007 |\n",
            "| loss_n_td               | 0.001741553  |\n",
            "| loss_td                 | 0.026725858  |\n",
            "| losses_all              | 0.0063386904 |\n",
            "| max 100 episode reward  | 294          |\n",
            "| mean 100 episode reward | 20.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1684209      |\n",
            "------------------------------------------\n",
            " 84% 1689305/2000000 [3:01:12<31:14, 165.73it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0871       |\n",
            "| elapsed time            | 03:18:13     |\n",
            "| episodes                | 4200         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029101653 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 9.91885e-05  |\n",
            "| loss_td                 | 0.012937586  |\n",
            "| losses_all              | 0.0046280883 |\n",
            "| max 100 episode reward  | 294          |\n",
            "| mean 100 episode reward | 20.7         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1689311      |\n",
            "------------------------------------------\n",
            " 85% 1693665/2000000 [3:01:40<31:21, 162.81it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.087        |\n",
            "| elapsed time            | 03:18:41     |\n",
            "| episodes                | 4210         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029044421 |\n",
            "| loss_margin             | 0.03137846   |\n",
            "| loss_n_td               | 0.001816276  |\n",
            "| loss_td                 | 0.04656022   |\n",
            "| losses_all              | 0.008764125  |\n",
            "| max 100 episode reward  | 294          |\n",
            "| mean 100 episode reward | 17.7         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1693680      |\n",
            "------------------------------------------\n",
            " 85% 1698311/2000000 [3:02:09<29:45, 168.94it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0869       |\n",
            "| elapsed time            | 03:19:10     |\n",
            "| episodes                | 4220         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028974127 |\n",
            "| loss_margin             | 0.009617243  |\n",
            "| loss_n_td               | 0.0026862472 |\n",
            "| loss_td                 | 0.015126593  |\n",
            "| losses_all              | 0.005553809  |\n",
            "| max 100 episode reward  | 294          |\n",
            "| mean 100 episode reward | 18           |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1698325      |\n",
            "------------------------------------------\n",
            " 85% 1699996/2000000 [3:02:20<30:43, 162.71it/s]saved checkpoint\n",
            " 85% 1702518/2000000 [3:02:36<29:37, 167.31it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0868       |\n",
            "| elapsed time            | 03:19:36     |\n",
            "| episodes                | 4230         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0029008863 |\n",
            "| loss_margin             | 0.0149829835 |\n",
            "| loss_n_td               | 0.0012420057 |\n",
            "| loss_td                 | 0.017423902  |\n",
            "| losses_all              | 0.0061434526 |\n",
            "| max 100 episode reward  | 294          |\n",
            "| mean 100 episode reward | 17.6         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1702530      |\n",
            "------------------------------------------\n",
            " 85% 1707634/2000000 [3:03:07<29:12, 166.85it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0867       |\n",
            "| elapsed time            | 03:20:08     |\n",
            "| episodes                | 4240         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002889032  |\n",
            "| loss_margin             | 0.0007953346 |\n",
            "| loss_n_td               | 7.974364e-05 |\n",
            "| loss_td                 | 0.010371118  |\n",
            "| losses_all              | 0.004175784  |\n",
            "| max 100 episode reward  | 294          |\n",
            "| mean 100 episode reward | 17.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1707640      |\n",
            "------------------------------------------\n",
            " 86% 1712915/2000000 [3:03:40<28:29, 167.96it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0866       |\n",
            "| elapsed time            | 03:20:41     |\n",
            "| episodes                | 4250         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028864916 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0018009999 |\n",
            "| loss_td                 | 0.012578167  |\n",
            "| losses_all              | 0.004568669  |\n",
            "| max 100 episode reward  | 294          |\n",
            "| mean 100 episode reward | 16.8         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1712926      |\n",
            "------------------------------------------\n",
            " 86% 1718060/2000000 [3:04:12<27:36, 170.16it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0865        |\n",
            "| elapsed time            | 03:21:13      |\n",
            "| episodes                | 4260          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0028860692  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00081618567 |\n",
            "| loss_td                 | 0.009042997   |\n",
            "| losses_all              | 0.0045191552  |\n",
            "| max 100 episode reward  | 294           |\n",
            "| mean 100 episode reward | 16.4          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1718076       |\n",
            "-------------------------------------------\n",
            " 86% 1722965/2000000 [3:04:43<28:25, 162.46it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0864       |\n",
            "| elapsed time            | 03:21:43     |\n",
            "| episodes                | 4270         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002884187  |\n",
            "| loss_margin             | 0.010913774  |\n",
            "| loss_n_td               | 0.0016113588 |\n",
            "| loss_td                 | 0.023998175  |\n",
            "| losses_all              | 0.007410382  |\n",
            "| max 100 episode reward  | 58           |\n",
            "| mean 100 episode reward | 13.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1722978      |\n",
            "------------------------------------------\n",
            " 86% 1728211/2000000 [3:05:15<26:42, 169.64it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0863        |\n",
            "| elapsed time            | 03:22:16      |\n",
            "| episodes                | 4280          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0028816767  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 3.1003554e-05 |\n",
            "| loss_td                 | 0.0075754104  |\n",
            "| losses_all              | 0.0041449806  |\n",
            "| max 100 episode reward  | 58            |\n",
            "| mean 100 episode reward | 13.2          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1728214       |\n",
            "-------------------------------------------\n",
            " 87% 1732738/2000000 [3:05:43<26:30, 168.03it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0863       |\n",
            "| elapsed time            | 03:22:44     |\n",
            "| episodes                | 4290         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002880908  |\n",
            "| loss_margin             | 0.028916879  |\n",
            "| loss_n_td               | 0.013985727  |\n",
            "| loss_td                 | 0.016209781  |\n",
            "| losses_all              | 0.0071698152 |\n",
            "| max 100 episode reward  | 58           |\n",
            "| mean 100 episode reward | 13.5         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1732745      |\n",
            "------------------------------------------\n",
            " 87% 1738050/2000000 [3:06:16<26:00, 167.83it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0862       |\n",
            "| elapsed time            | 03:23:17     |\n",
            "| episodes                | 4300         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028756708 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0027894836 |\n",
            "| loss_td                 | 0.026141629  |\n",
            "| losses_all              | 0.005706738  |\n",
            "| max 100 episode reward  | 58           |\n",
            "| mean 100 episode reward | 13.9         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1738060      |\n",
            "------------------------------------------\n",
            " 87% 1743377/2000000 [3:06:50<26:57, 158.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0861       |\n",
            "| elapsed time            | 03:23:50     |\n",
            "| episodes                | 4310         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028699634 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0008291085 |\n",
            "| loss_td                 | 0.017497752  |\n",
            "| losses_all              | 0.004948239  |\n",
            "| max 100 episode reward  | 58           |\n",
            "| mean 100 episode reward | 14.4         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1743388      |\n",
            "------------------------------------------\n",
            " 87% 1748852/2000000 [3:07:24<24:30, 170.83it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.086         |\n",
            "| elapsed time            | 03:24:24      |\n",
            "| episodes                | 4320          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0028644714  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00032232198 |\n",
            "| loss_td                 | 0.010626997   |\n",
            "| losses_all              | 0.0046713036  |\n",
            "| max 100 episode reward  | 234           |\n",
            "| mean 100 episode reward | 16.9          |\n",
            "| min 100 episode reward  | 2             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1748854       |\n",
            "-------------------------------------------\n",
            " 88% 1753110/2000000 [3:07:50<24:45, 166.23it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0859       |\n",
            "| elapsed time            | 03:24:51     |\n",
            "| episodes                | 4330         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028666542 |\n",
            "| loss_margin             | 0.0028420798 |\n",
            "| loss_n_td               | 0.0015402954 |\n",
            "| loss_td                 | 0.014708383  |\n",
            "| losses_all              | 0.0047650165 |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 17           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1753117      |\n",
            "------------------------------------------\n",
            " 88% 1758411/2000000 [3:08:24<24:45, 162.60it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0858        |\n",
            "| elapsed time            | 03:25:24      |\n",
            "| episodes                | 4340          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.002868699   |\n",
            "| loss_margin             | 0.0028413832  |\n",
            "| loss_n_td               | 1.2244406e-06 |\n",
            "| loss_td                 | 0.008917828   |\n",
            "| losses_all              | 0.0044591296  |\n",
            "| max 100 episode reward  | 234           |\n",
            "| mean 100 episode reward | 16.6          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1758418       |\n",
            "-------------------------------------------\n",
            " 88% 1763229/2000000 [3:08:54<23:47, 165.86it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0857        |\n",
            "| elapsed time            | 03:25:54      |\n",
            "| episodes                | 4350          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0028636395  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00096148765 |\n",
            "| loss_td                 | 0.009309231   |\n",
            "| losses_all              | 0.004431054   |\n",
            "| max 100 episode reward  | 234           |\n",
            "| mean 100 episode reward | 16.6          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1763244       |\n",
            "-------------------------------------------\n",
            " 88% 1767645/2000000 [3:09:21<23:07, 167.48it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0856       |\n",
            "| elapsed time            | 03:26:21     |\n",
            "| episodes                | 4360         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028678256 |\n",
            "| loss_margin             | 0.004999511  |\n",
            "| loss_n_td               | 8.955802e-05 |\n",
            "| loss_td                 | 0.012044739  |\n",
            "| losses_all              | 0.0050853994 |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 16.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1767656      |\n",
            "------------------------------------------\n",
            " 89% 1772681/2000000 [3:09:52<24:13, 156.38it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.0855      |\n",
            "| elapsed time            | 03:26:53    |\n",
            "| episodes                | 4370        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.00285933  |\n",
            "| loss_margin             | 0.024056895 |\n",
            "| loss_n_td               | 0.001672934 |\n",
            "| loss_td                 | 0.023321128 |\n",
            "| losses_all              | 0.008536983 |\n",
            "| max 100 episode reward  | 234         |\n",
            "| mean 100 episode reward | 16.4        |\n",
            "| min 100 episode reward  | 4           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1772697     |\n",
            "-----------------------------------------\n",
            " 89% 1778220/2000000 [3:10:27<22:04, 167.50it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0855       |\n",
            "| elapsed time            | 03:27:27     |\n",
            "| episodes                | 4380         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002859766  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0044795508 |\n",
            "| loss_td                 | 0.0065799905 |\n",
            "| losses_all              | 0.004106747  |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 16.8         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1778228      |\n",
            "------------------------------------------\n",
            " 89% 1782565/2000000 [3:10:54<21:39, 167.35it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0854       |\n",
            "| elapsed time            | 03:27:55     |\n",
            "| episodes                | 4390         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028628695 |\n",
            "| loss_margin             | 0.0041182153 |\n",
            "| loss_n_td               | 0.0007369759 |\n",
            "| loss_td                 | 0.018737476  |\n",
            "| losses_all              | 0.0056188293 |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 16.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1782578      |\n",
            "------------------------------------------\n",
            " 89% 1787477/2000000 [3:11:25<21:27, 165.06it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0853       |\n",
            "| elapsed time            | 03:28:25     |\n",
            "| episodes                | 4400         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028579228 |\n",
            "| loss_margin             | 0.0059814975 |\n",
            "| loss_n_td               | 0.0023131727 |\n",
            "| loss_td                 | 0.012079419  |\n",
            "| losses_all              | 0.005096997  |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 16           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1787479      |\n",
            "------------------------------------------\n",
            " 90% 1793257/2000000 [3:12:01<21:03, 163.68it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0852       |\n",
            "| elapsed time            | 03:29:02     |\n",
            "| episodes                | 4410         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028572588 |\n",
            "| loss_margin             | 0.005332753  |\n",
            "| loss_n_td               | 0.0038659698 |\n",
            "| loss_td                 | 0.029919283  |\n",
            "| losses_all              | 0.005468475  |\n",
            "| max 100 episode reward  | 234          |\n",
            "| mean 100 episode reward | 17.1         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1793269      |\n",
            "------------------------------------------\n",
            " 90% 1798235/2000000 [3:12:32<19:57, 168.52it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0851        |\n",
            "| elapsed time            | 03:29:32      |\n",
            "| episodes                | 4420          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0028509905  |\n",
            "| loss_margin             | 0.034832057   |\n",
            "| loss_n_td               | 0.00025033008 |\n",
            "| loss_td                 | 0.012665671   |\n",
            "| losses_all              | 0.006485059   |\n",
            "| max 100 episode reward  | 93            |\n",
            "| mean 100 episode reward | 14.8          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1798249       |\n",
            "-------------------------------------------\n",
            " 90% 1799982/2000000 [3:12:43<20:19, 164.04it/s]saved checkpoint\n",
            " 90% 1802553/2000000 [3:12:59<20:03, 164.11it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.085       |\n",
            "| elapsed time            | 03:30:00    |\n",
            "| episodes                | 4430        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.002852016 |\n",
            "| loss_margin             | 0.033424586 |\n",
            "| loss_n_td               | 0.005910277 |\n",
            "| loss_td                 | 0.019220099 |\n",
            "| losses_all              | 0.007581557 |\n",
            "| max 100 episode reward  | 93          |\n",
            "| mean 100 episode reward | 14.9        |\n",
            "| min 100 episode reward  | 1           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1802568     |\n",
            "-----------------------------------------\n",
            " 90% 1807157/2000000 [3:13:28<19:11, 167.50it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.085        |\n",
            "| elapsed time            | 03:30:28     |\n",
            "| episodes                | 4440         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028419555 |\n",
            "| loss_margin             | 0.013416845  |\n",
            "| loss_n_td               | 6.189369e-06 |\n",
            "| loss_td                 | 0.20183602   |\n",
            "| losses_all              | 0.0118207    |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 14.7         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1807159      |\n",
            "------------------------------------------\n",
            " 91% 1812749/2000000 [3:14:02<18:57, 164.61it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0849       |\n",
            "| elapsed time            | 03:31:03     |\n",
            "| episodes                | 4450         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028495544 |\n",
            "| loss_margin             | 0.03450049   |\n",
            "| loss_n_td               | 0.0016646804 |\n",
            "| loss_td                 | 0.006747747  |\n",
            "| losses_all              | 0.0063103465 |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 15.3         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1812765      |\n",
            "------------------------------------------\n",
            " 91% 1817974/2000000 [3:14:35<18:06, 167.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0848       |\n",
            "| elapsed time            | 03:31:35     |\n",
            "| episodes                | 4460         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002853366  |\n",
            "| loss_margin             | 0.01348874   |\n",
            "| loss_n_td               | 0.0017429776 |\n",
            "| loss_td                 | 0.036377054  |\n",
            "| losses_all              | 0.007080619  |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 15.5         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1817974      |\n",
            "------------------------------------------\n",
            " 91% 1822543/2000000 [3:15:03<17:20, 170.52it/s]--------------------------------------------\n",
            "| % time spent exploring  | 10             |\n",
            "| demo sample rate        | 0.0847         |\n",
            "| elapsed time            | 03:32:03       |\n",
            "| episodes                | 4470           |\n",
            "| epsilon                 | 0.1            |\n",
            "| loss_l2                 | 0.002849792    |\n",
            "| loss_margin             | 0.018805627    |\n",
            "| loss_n_td               | 0.000110185436 |\n",
            "| loss_td                 | 0.0064100726   |\n",
            "| losses_all              | 0.004988528    |\n",
            "| max 100 episode reward  | 93             |\n",
            "| mean 100 episode reward | 15.4           |\n",
            "| min 100 episode reward  | 1              |\n",
            "| pre_train               | False          |\n",
            "| steps                   | 1822554        |\n",
            "--------------------------------------------\n",
            " 91% 1827115/2000000 [3:15:31<17:09, 168.01it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0846       |\n",
            "| elapsed time            | 03:32:32     |\n",
            "| episodes                | 4480         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028498326 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.012281756  |\n",
            "| losses_all              | 0.0044742473 |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 14.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1827116      |\n",
            "------------------------------------------\n",
            " 92% 1832058/2000000 [3:16:02<16:38, 168.20it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0845       |\n",
            "| elapsed time            | 03:33:02     |\n",
            "| episodes                | 4490         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028614348 |\n",
            "| loss_margin             | 0.02020172   |\n",
            "| loss_n_td               | 0.0019146104 |\n",
            "| loss_td                 | 0.017429685  |\n",
            "| losses_all              | 0.006542287  |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 15.1         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1832060      |\n",
            "------------------------------------------\n",
            " 92% 1837654/2000000 [3:16:36<16:19, 165.68it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0845        |\n",
            "| elapsed time            | 03:33:37      |\n",
            "| episodes                | 4500          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0028668053  |\n",
            "| loss_margin             | 0.0065191127  |\n",
            "| loss_n_td               | 0.00059074693 |\n",
            "| loss_td                 | 0.009093535   |\n",
            "| losses_all              | 0.004476115   |\n",
            "| max 100 episode reward  | 93            |\n",
            "| mean 100 episode reward | 15.2          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1837654       |\n",
            "-------------------------------------------\n",
            " 92% 1841872/2000000 [3:17:03<15:33, 169.44it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0844       |\n",
            "| elapsed time            | 03:34:04     |\n",
            "| episodes                | 4510         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028671222 |\n",
            "| loss_margin             | 0.008037582  |\n",
            "| loss_n_td               | 0.0015771054 |\n",
            "| loss_td                 | 0.026799317  |\n",
            "| losses_all              | 0.005652844  |\n",
            "| max 100 episode reward  | 56           |\n",
            "| mean 100 episode reward | 13.8         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1841887      |\n",
            "------------------------------------------\n",
            " 92% 1846689/2000000 [3:17:33<15:20, 166.48it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0843       |\n",
            "| elapsed time            | 03:34:34     |\n",
            "| episodes                | 4520         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002861697  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0018762314 |\n",
            "| loss_td                 | 0.0075522587 |\n",
            "| losses_all              | 0.003962283  |\n",
            "| max 100 episode reward  | 56           |\n",
            "| mean 100 episode reward | 13.3         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1846689      |\n",
            "------------------------------------------\n",
            " 93% 1851669/2000000 [3:18:04<14:50, 166.62it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0842       |\n",
            "| elapsed time            | 03:35:05     |\n",
            "| episodes                | 4530         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002855992  |\n",
            "| loss_margin             | 0.017876413  |\n",
            "| loss_n_td               | 0.0016785378 |\n",
            "| loss_td                 | 0.014303438  |\n",
            "| losses_all              | 0.0057185236 |\n",
            "| max 100 episode reward  | 56           |\n",
            "| mean 100 episode reward | 13.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1851685      |\n",
            "------------------------------------------\n",
            " 93% 1856671/2000000 [3:18:35<13:58, 171.03it/s]-----------------------------------------\n",
            "| % time spent exploring  | 10          |\n",
            "| demo sample rate        | 0.0842      |\n",
            "| elapsed time            | 03:35:35    |\n",
            "| episodes                | 4540        |\n",
            "| epsilon                 | 0.1         |\n",
            "| loss_l2                 | 0.002859552 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.0         |\n",
            "| loss_td                 | 0.020141339 |\n",
            "| losses_all              | 0.005217327 |\n",
            "| max 100 episode reward  | 56          |\n",
            "| mean 100 episode reward | 13.4        |\n",
            "| min 100 episode reward  | 4           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1856685     |\n",
            "-----------------------------------------\n",
            " 93% 1861342/2000000 [3:19:04<13:52, 166.50it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0841       |\n",
            "| elapsed time            | 03:36:04     |\n",
            "| episodes                | 4550         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028635955 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0038743862 |\n",
            "| loss_td                 | 0.016833816  |\n",
            "| losses_all              | 0.0055101635 |\n",
            "| max 100 episode reward  | 42           |\n",
            "| mean 100 episode reward | 12.5         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1861343      |\n",
            "------------------------------------------\n",
            " 93% 1866484/2000000 [3:19:35<13:05, 169.94it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.084        |\n",
            "| elapsed time            | 03:36:36     |\n",
            "| episodes                | 4560         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028616262 |\n",
            "| loss_margin             | 0.018591687  |\n",
            "| loss_n_td               | 0.0029243059 |\n",
            "| loss_td                 | 0.007917534  |\n",
            "| losses_all              | 0.005367533  |\n",
            "| max 100 episode reward  | 196          |\n",
            "| mean 100 episode reward | 14.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1866494      |\n",
            "------------------------------------------\n",
            " 94% 1871974/2000000 [3:20:09<12:44, 167.38it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0839       |\n",
            "| elapsed time            | 03:37:10     |\n",
            "| episodes                | 4570         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028569384 |\n",
            "| loss_margin             | 0.0424193    |\n",
            "| loss_n_td               | 0.004367588  |\n",
            "| loss_td                 | 0.015360609  |\n",
            "| losses_all              | 0.0075005516 |\n",
            "| max 100 episode reward  | 196          |\n",
            "| mean 100 episode reward | 15           |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1871987      |\n",
            "------------------------------------------\n",
            " 94% 1876693/2000000 [3:20:38<12:39, 162.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0838       |\n",
            "| elapsed time            | 03:37:39     |\n",
            "| episodes                | 4580         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002849861  |\n",
            "| loss_margin             | 0.030769832  |\n",
            "| loss_n_td               | 0.0035875523 |\n",
            "| loss_td                 | 0.010600534  |\n",
            "| losses_all              | 0.006120744  |\n",
            "| max 100 episode reward  | 196          |\n",
            "| mean 100 episode reward | 15.4         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1876700      |\n",
            "------------------------------------------\n",
            " 94% 1882137/2000000 [3:21:12<11:50, 165.85it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0837        |\n",
            "| elapsed time            | 03:38:12      |\n",
            "| episodes                | 4590          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.00284949    |\n",
            "| loss_margin             | 0.008609876   |\n",
            "| loss_n_td               | 0.00028878375 |\n",
            "| loss_td                 | 0.025977118   |\n",
            "| losses_all              | 0.006582441   |\n",
            "| max 100 episode reward  | 196           |\n",
            "| mean 100 episode reward | 15.4          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1882147       |\n",
            "-------------------------------------------\n",
            " 94% 1887190/2000000 [3:21:43<11:20, 165.85it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0837        |\n",
            "| elapsed time            | 03:38:44      |\n",
            "| episodes                | 4600          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0028441881  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00036272442 |\n",
            "| loss_td                 | 0.009714086   |\n",
            "| losses_all              | 0.00413948    |\n",
            "| max 100 episode reward  | 196           |\n",
            "| mean 100 episode reward | 15.2          |\n",
            "| min 100 episode reward  | 4             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1887194       |\n",
            "-------------------------------------------\n",
            " 95% 1891848/2000000 [3:22:13<10:35, 170.12it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0836       |\n",
            "| elapsed time            | 03:39:13     |\n",
            "| episodes                | 4610         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028443001 |\n",
            "| loss_margin             | 0.008422006  |\n",
            "| loss_n_td               | 0.0015043995 |\n",
            "| loss_td                 | 0.01588351   |\n",
            "| losses_all              | 0.0050463825 |\n",
            "| max 100 episode reward  | 196          |\n",
            "| mean 100 episode reward | 14.9         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1891850      |\n",
            "------------------------------------------\n",
            " 95% 1895942/2000000 [3:22:38<10:26, 166.11it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0835       |\n",
            "| elapsed time            | 03:39:39     |\n",
            "| episodes                | 4620         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028425136 |\n",
            "| loss_margin             | 0.013792656  |\n",
            "| loss_n_td               | 0.0003269519 |\n",
            "| loss_td                 | 0.021027166  |\n",
            "| losses_all              | 0.005670553  |\n",
            "| max 100 episode reward  | 196          |\n",
            "| mean 100 episode reward | 14.6         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1895944      |\n",
            "------------------------------------------\n",
            " 95% 1899994/2000000 [3:23:03<09:55, 167.84it/s]saved checkpoint\n",
            " 95% 1901126/2000000 [3:23:10<09:51, 167.14it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0835       |\n",
            "| elapsed time            | 03:40:11     |\n",
            "| episodes                | 4630         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028402905 |\n",
            "| loss_margin             | 0.020947175  |\n",
            "| loss_n_td               | 0.0025288372 |\n",
            "| loss_td                 | 0.007776807  |\n",
            "| losses_all              | 0.0056353146 |\n",
            "| max 100 episode reward  | 196          |\n",
            "| mean 100 episode reward | 14.8         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1901126      |\n",
            "------------------------------------------\n",
            " 95% 1905348/2000000 [3:23:37<09:12, 171.34it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0834       |\n",
            "| elapsed time            | 03:40:37     |\n",
            "| episodes                | 4640         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028415215 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.001129529  |\n",
            "| loss_td                 | 0.005800095  |\n",
            "| losses_all              | 0.0038243774 |\n",
            "| max 100 episode reward  | 196          |\n",
            "| mean 100 episode reward | 14.8         |\n",
            "| min 100 episode reward  | 4            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1905360      |\n",
            "------------------------------------------\n",
            " 95% 1909383/2000000 [3:24:02<09:05, 166.09it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0833        |\n",
            "| elapsed time            | 03:41:02      |\n",
            "| episodes                | 4650          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0028384367  |\n",
            "| loss_margin             | 0.0009166971  |\n",
            "| loss_n_td               | 0.00039897114 |\n",
            "| loss_td                 | 0.007825743   |\n",
            "| losses_all              | 0.0037936305  |\n",
            "| max 100 episode reward  | 196           |\n",
            "| mean 100 episode reward | 14.7          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1909397       |\n",
            "-------------------------------------------\n",
            " 96% 1913853/2000000 [3:24:30<08:47, 163.26it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0833       |\n",
            "| elapsed time            | 03:41:30     |\n",
            "| episodes                | 4660         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028274492 |\n",
            "| loss_margin             | 0.008051019  |\n",
            "| loss_n_td               | 0.014980095  |\n",
            "| loss_td                 | 0.021492412  |\n",
            "| losses_all              | 0.006205378  |\n",
            "| max 100 episode reward  | 52           |\n",
            "| mean 100 episode reward | 12.7         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1913863      |\n",
            "------------------------------------------\n",
            " 96% 1917833/2000000 [3:24:55<08:30, 160.91it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0832       |\n",
            "| elapsed time            | 03:41:55     |\n",
            "| episodes                | 4670         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028246453 |\n",
            "| loss_margin             | 0.0032052472 |\n",
            "| loss_n_td               | 0.0010167689 |\n",
            "| loss_td                 | 0.008779103  |\n",
            "| losses_all              | 0.004387718  |\n",
            "| max 100 episode reward  | 52           |\n",
            "| mean 100 episode reward | 12           |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1917846      |\n",
            "------------------------------------------\n",
            " 96% 1922605/2000000 [3:25:25<07:59, 161.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0831       |\n",
            "| elapsed time            | 03:42:26     |\n",
            "| episodes                | 4680         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028230452 |\n",
            "| loss_margin             | 0.0008394122 |\n",
            "| loss_n_td               | 0.0009185983 |\n",
            "| loss_td                 | 0.014063526  |\n",
            "| losses_all              | 0.0048658988 |\n",
            "| max 100 episode reward  | 39           |\n",
            "| mean 100 episode reward | 11.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1922608      |\n",
            "------------------------------------------\n",
            " 96% 1927376/2000000 [3:25:56<07:12, 167.87it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0831       |\n",
            "| elapsed time            | 03:42:56     |\n",
            "| episodes                | 4690         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028218045 |\n",
            "| loss_margin             | 0.04110314   |\n",
            "| loss_n_td               | 0.0012536419 |\n",
            "| loss_td                 | 0.009103547  |\n",
            "| losses_all              | 0.0067738844 |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 12.1         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1927382      |\n",
            "------------------------------------------\n",
            " 97% 1931855/2000000 [3:26:24<06:49, 166.22it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.083        |\n",
            "| elapsed time            | 03:43:25     |\n",
            "| episodes                | 4700         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028181514 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0          |\n",
            "| loss_td                 | 0.010065953  |\n",
            "| losses_all              | 0.0045611723 |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 11.8         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1931866      |\n",
            "------------------------------------------\n",
            " 97% 1936472/2000000 [3:26:54<06:26, 164.38it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0829       |\n",
            "| elapsed time            | 03:43:54     |\n",
            "| episodes                | 4710         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028172643 |\n",
            "| loss_margin             | 0.02864496   |\n",
            "| loss_n_td               | 0.004080725  |\n",
            "| loss_td                 | 0.022683803  |\n",
            "| losses_all              | 0.006724494  |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 11.7         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1936478      |\n",
            "------------------------------------------\n",
            " 97% 1940820/2000000 [3:27:22<05:55, 166.50it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0829       |\n",
            "| elapsed time            | 03:44:22     |\n",
            "| episodes                | 4720         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028099315 |\n",
            "| loss_margin             | 0.009947084  |\n",
            "| loss_n_td               | 0.0016126279 |\n",
            "| loss_td                 | 0.008945826  |\n",
            "| losses_all              | 0.0047383043 |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 11.8         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1940828      |\n",
            "------------------------------------------\n",
            " 97% 1945053/2000000 [3:27:49<05:39, 162.06it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0828       |\n",
            "| elapsed time            | 03:44:49     |\n",
            "| episodes                | 4730         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002808461  |\n",
            "| loss_margin             | 0.0061017238 |\n",
            "| loss_n_td               | 0.001128379  |\n",
            "| loss_td                 | 0.02912049   |\n",
            "| losses_all              | 0.0056980704 |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 11.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1945065      |\n",
            "------------------------------------------\n",
            " 97% 1949171/2000000 [3:28:15<05:04, 166.69it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0827       |\n",
            "| elapsed time            | 03:45:15     |\n",
            "| episodes                | 4740         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028045452 |\n",
            "| loss_margin             | 0.02013325   |\n",
            "| loss_n_td               | 0.0011954829 |\n",
            "| loss_td                 | 0.007822672  |\n",
            "| losses_all              | 0.0051441877 |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 11.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1949172      |\n",
            "------------------------------------------\n",
            " 98% 1954105/2000000 [3:28:46<04:49, 158.70it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0827       |\n",
            "| elapsed time            | 03:45:46     |\n",
            "| episodes                | 4750         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028065813 |\n",
            "| loss_margin             | 0.01307999   |\n",
            "| loss_n_td               | 0.0020188305 |\n",
            "| loss_td                 | 0.00818311   |\n",
            "| losses_all              | 0.0048730453 |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 11.9         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1954118      |\n",
            "------------------------------------------\n",
            " 98% 1958805/2000000 [3:29:15<04:16, 160.46it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0826       |\n",
            "| elapsed time            | 03:46:16     |\n",
            "| episodes                | 4760         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0028069615 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.000487495  |\n",
            "| loss_td                 | 0.016007543  |\n",
            "| losses_all              | 0.0045302054 |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 11.7         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1958805      |\n",
            "------------------------------------------\n",
            " 98% 1963455/2000000 [3:29:45<03:39, 166.21it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0825       |\n",
            "| elapsed time            | 03:46:45     |\n",
            "| episodes                | 4770         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0027949694 |\n",
            "| loss_margin             | 0.0121256    |\n",
            "| loss_n_td               | 0.0032024062 |\n",
            "| loss_td                 | 0.010202335  |\n",
            "| losses_all              | 0.0052222083 |\n",
            "| max 100 episode reward  | 93           |\n",
            "| mean 100 episode reward | 12.3         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1963455      |\n",
            "------------------------------------------\n",
            " 98% 1968661/2000000 [3:30:18<03:14, 160.89it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0825       |\n",
            "| elapsed time            | 03:47:18     |\n",
            "| episodes                | 4780         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.002796628  |\n",
            "| loss_margin             | 0.009313852  |\n",
            "| loss_n_td               | 0.0024672714 |\n",
            "| loss_td                 | 0.00961932   |\n",
            "| losses_all              | 0.0048147417 |\n",
            "| max 100 episode reward  | 148          |\n",
            "| mean 100 episode reward | 14.4         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1968664      |\n",
            "------------------------------------------\n",
            " 99% 1973124/2000000 [3:30:46<02:42, 165.60it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0824       |\n",
            "| elapsed time            | 03:47:46     |\n",
            "| episodes                | 4790         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0027914525 |\n",
            "| loss_margin             | 0.004904121  |\n",
            "| loss_n_td               | 0.0013051936 |\n",
            "| loss_td                 | 0.015779514  |\n",
            "| losses_all              | 0.0048908098 |\n",
            "| max 100 episode reward  | 148          |\n",
            "| mean 100 episode reward | 13.9         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1973129      |\n",
            "------------------------------------------\n",
            " 99% 1977406/2000000 [3:31:13<02:18, 162.87it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0824       |\n",
            "| elapsed time            | 03:48:13     |\n",
            "| episodes                | 4800         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0027900336 |\n",
            "| loss_margin             | 0.004770845  |\n",
            "| loss_n_td               | 0.0031721797 |\n",
            "| loss_td                 | 0.00881166   |\n",
            "| losses_all              | 0.004361988  |\n",
            "| max 100 episode reward  | 148          |\n",
            "| mean 100 episode reward | 13.6         |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1977407      |\n",
            "------------------------------------------\n",
            " 99% 1981864/2000000 [3:31:42<01:50, 164.50it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0823        |\n",
            "| elapsed time            | 03:48:42      |\n",
            "| episodes                | 4810          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0027813183  |\n",
            "| loss_margin             | 0.010308754   |\n",
            "| loss_n_td               | 0.00093117636 |\n",
            "| loss_td                 | 0.015520396   |\n",
            "| losses_all              | 0.005507487   |\n",
            "| max 100 episode reward  | 148           |\n",
            "| mean 100 episode reward | 14            |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1981879       |\n",
            "-------------------------------------------\n",
            " 99% 1987513/2000000 [3:32:18<01:20, 154.80it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.0822       |\n",
            "| elapsed time            | 03:49:18     |\n",
            "| episodes                | 4820         |\n",
            "| epsilon                 | 0.1          |\n",
            "| loss_l2                 | 0.0027841695 |\n",
            "| loss_margin             | 0.025145803  |\n",
            "| loss_n_td               | 0.0014638236 |\n",
            "| loss_td                 | 0.008244846  |\n",
            "| losses_all              | 0.0054960726 |\n",
            "| max 100 episode reward  | 155          |\n",
            "| mean 100 episode reward | 16           |\n",
            "| min 100 episode reward  | 3            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1987527      |\n",
            "------------------------------------------\n",
            "100% 1992065/2000000 [3:32:47<00:48, 162.42it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0822        |\n",
            "| elapsed time            | 03:49:48      |\n",
            "| episodes                | 4830          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0027818917  |\n",
            "| loss_margin             | 0.0051097386  |\n",
            "| loss_n_td               | 6.8007364e-05 |\n",
            "| loss_td                 | 0.008673387   |\n",
            "| losses_all              | 0.0041694473  |\n",
            "| max 100 episode reward  | 155           |\n",
            "| mean 100 episode reward | 16.4          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1992067       |\n",
            "-------------------------------------------\n",
            "100% 1997146/2000000 [3:33:20<00:17, 161.92it/s]-------------------------------------------\n",
            "| % time spent exploring  | 10            |\n",
            "| demo sample rate        | 0.0821        |\n",
            "| elapsed time            | 03:50:20      |\n",
            "| episodes                | 4840          |\n",
            "| epsilon                 | 0.1           |\n",
            "| loss_l2                 | 0.0027787774  |\n",
            "| loss_margin             | 0.00078801066 |\n",
            "| loss_n_td               | 0.0034961703  |\n",
            "| loss_td                 | 0.018656868   |\n",
            "| losses_all              | 0.0049450886  |\n",
            "| max 100 episode reward  | 155           |\n",
            "| mean 100 episode reward | 16.7          |\n",
            "| min 100 episode reward  | 3             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1997162       |\n",
            "-------------------------------------------\n",
            "100% 2000000/2000000 [3:33:38<00:00, 156.02it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u3ghxyr50fh",
        "colab_type": "code",
        "outputId": "ead79d37-cfc8-4761-e9a9-e79c1e703f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "!git status "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch master\n",
            "Your branch is up to date with 'origin/master'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
            "\n",
            "\t\u001b[31mmodified:   dqfd.py\u001b[m\n",
            "\t\u001b[31mmodified:   run_atari.py\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_9L_dwWbBoZ",
        "colab_type": "code",
        "outputId": "47f83db8-ff9c-4969-aa84-2f39485f5209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!git add . \n",
        "!git commit -m \"fix save video bug\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master b583877] fix save video bug\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A2hNQE_bMcN",
        "colab_type": "code",
        "outputId": "c14feaa6-d0d3-493c-b6a4-16d7c337fa5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "!git push"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 3, done.\n",
            "Delta compression using up to 4 threads.\n",
            "Compressing objects:  33% (1/3)   \rCompressing objects:  66% (2/3)   \rCompressing objects: 100% (3/3)   \rCompressing objects: 100% (3/3), done.\n",
            "Writing objects:  33% (1/3)   \rWriting objects:  66% (2/3)   \rWriting objects: 100% (3/3)   \rWriting objects: 100% (3/3), 304 bytes | 304.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/Kokkini/DQfD.git\n",
            "   f2ec658..b583877  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAZjuQCVbN-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}