{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQfD_main.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/Kokkini/DQfD/blob/master/DQfD_main.ipynb",
      "authorship_tag": "ABX9TyPdp7s1vq6GtYtmM1BhOd3+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kokkini/DQfD/blob/master/DQfD_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLKIVoRu16Fy",
        "colab_type": "code",
        "outputId": "831333c0-9f45-4a80-838d-e3479eb0d09a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "# !pip install stable-baselines[mpi]==2.10.0\n",
        "!pip install gym\n",
        "!pip install pynput"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Collecting pynput\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/0a/ea13c055a90b1aff5945e7eb330584f15e5282aead15a8f3cdb977a1534e/pynput-1.6.8-py2.py3-none-any.whl (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 2.2MB/s \n",
            "\u001b[?25hCollecting python-xlib>=0.17; \"linux\" in sys_platform\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/10/2eb938852a9bdf6745808f141c9fede76b1bd5a9530859bacc71985d29d9/python_xlib-0.27-py2.py3-none-any.whl (174kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pynput) (1.12.0)\n",
            "Installing collected packages: python-xlib, pynput\n",
            "Successfully installed pynput-1.6.8 python-xlib-0.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99IlmkkQ7mcr",
        "colab_type": "code",
        "outputId": "ee48f275-4e42-4fb5-df08-bc47bf4ae2d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun  6 05:29:49 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7VAg5r42H9q",
        "colab_type": "code",
        "outputId": "50701bb6-d101-4155-a0fa-ee125e182112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "from getpass import getpass\n",
        "\n",
        "def clone_with_token(repo_name, owner_name=\"Kokkini\", user_email=\"trannhatquang1104@gmail.com\", user_name=\"Kokkini\"):\n",
        "  GIT_TOKEN = getpass('insert token: ')\n",
        "  GIT_PATH = f\"https://{GIT_TOKEN}@github.com/{owner_name}/{repo_name}.git\"\n",
        "  !git config --global user.email \"{user_email}\"\n",
        "  !git config --global user.name \"{user_name}\"\n",
        "  !git clone \"{GIT_PATH}\"\n",
        "  GIT_TOKEN, GIT_PATH = \"\", \"\"\n",
        "clone_with_token(\"DQfD\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "insert token: ··········\n",
            "Cloning into 'DQfD'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Counting objects: 100% (269/269), done.\u001b[K\n",
            "remote: Compressing objects: 100% (221/221), done.\u001b[K\n",
            "remote: Total 269 (delta 162), reused 103 (delta 43), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (269/269), 260.47 KiB | 4.82 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tBPFxBF55tf",
        "colab_type": "code",
        "outputId": "7a686823-318a-4743-b396-42b1642e248d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd DQfD/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DQfD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1mT261H2VMr",
        "colab_type": "code",
        "outputId": "b771e7ed-7fad-427e-e3de-2c7f06a5f4d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_atari.py --pre_train_timesteps=1e5 --num_timesteps=4e6 --batch_size=64 --buffer_size=5e5 --lr=5e-5 --exploration_final_eps=0.01 --exploration_fraction=0.1 --save_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/models16\" --load_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/models16\" --demo_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/human.BreakoutNoFrameskip-v4.episodic.pkl\" --log_path=\"/content/drive/My Drive/Colab Notebooks/imitation_RL/logs16\" "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "| demo sample rate        | 0.389        |\n",
            "| elapsed time            | 00:36:08     |\n",
            "| episodes                | 3600         |\n",
            "| epsilon                 | 0.700671     |\n",
            "| loss_l2                 | 0.0074646613 |\n",
            "| loss_margin             | 0.0019435212 |\n",
            "| loss_n_td               | 0.004408391  |\n",
            "| loss_td                 | 0.01684281   |\n",
            "| losses_all              | 0.012830647  |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 0.33         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 120941       |\n",
            "------------------------------------------\n",
            "  3% 123997/4000000 [17:21<8:02:38, 133.85it/s]------------------------------------------\n",
            "| % time spent exploring  | 69           |\n",
            "| demo sample rate        | 0.385        |\n",
            "| elapsed time            | 00:36:35     |\n",
            "| episodes                | 3700         |\n",
            "| epsilon                 | 0.6931025    |\n",
            "| loss_l2                 | 0.0074258884 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0033980464 |\n",
            "| loss_td                 | 0.012791045  |\n",
            "| losses_all              | 0.011733485  |\n",
            "| max 100 episode reward  | 2            |\n",
            "| mean 100 episode reward | 0.23         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 123999       |\n",
            "------------------------------------------\n",
            "  3% 127185/4000000 [17:49<8:16:28, 130.01it/s]-----------------------------------------\n",
            "| % time spent exploring  | 68          |\n",
            "| demo sample rate        | 0.381       |\n",
            "| elapsed time            | 00:37:03    |\n",
            "| episodes                | 3800        |\n",
            "| epsilon                 | 0.6852122   |\n",
            "| loss_l2                 | 0.007378502 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.004561256 |\n",
            "| loss_td                 | 0.01669986  |\n",
            "| losses_all              | 0.01229537  |\n",
            "| max 100 episode reward  | 4           |\n",
            "| mean 100 episode reward | 0.25        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 127187      |\n",
            "-----------------------------------------\n",
            "  3% 130481/4000000 [18:18<8:00:10, 134.31it/s]------------------------------------------\n",
            "| % time spent exploring  | 67           |\n",
            "| demo sample rate        | 0.376        |\n",
            "| elapsed time            | 00:37:32     |\n",
            "| episodes                | 3900         |\n",
            "| epsilon                 | 0.6770521    |\n",
            "| loss_l2                 | 0.0073388177 |\n",
            "| loss_margin             | 0.0034868084 |\n",
            "| loss_n_td               | 0.0035858382 |\n",
            "| loss_td                 | 0.02135846   |\n",
            "| losses_all              | 0.013741687  |\n",
            "| max 100 episode reward  | 2            |\n",
            "| mean 100 episode reward | 0.27         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 130484       |\n",
            "------------------------------------------\n",
            "  3% 133919/4000000 [18:48<7:46:17, 138.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 66           |\n",
            "| demo sample rate        | 0.372        |\n",
            "| elapsed time            | 00:38:02     |\n",
            "| episodes                | 4000         |\n",
            "| epsilon                 | 0.66854304   |\n",
            "| loss_l2                 | 0.0073015518 |\n",
            "| loss_margin             | 0.008404406  |\n",
            "| loss_n_td               | 0.004939148  |\n",
            "| loss_td                 | 0.012640545  |\n",
            "| losses_all              | 0.012593288  |\n",
            "| max 100 episode reward  | 2            |\n",
            "| mean 100 episode reward | 0.31         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 133922       |\n",
            "------------------------------------------\n",
            "  3% 137251/4000000 [19:17<8:07:59, 131.93it/s]------------------------------------------\n",
            "| % time spent exploring  | 66           |\n",
            "| demo sample rate        | 0.368        |\n",
            "| elapsed time            | 00:38:32     |\n",
            "| episodes                | 4100         |\n",
            "| epsilon                 | 0.66027653   |\n",
            "| loss_l2                 | 0.0072605475 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.005898446  |\n",
            "| loss_td                 | 0.009810489  |\n",
            "| losses_all              | 0.01110641   |\n",
            "| max 100 episode reward  | 2            |\n",
            "| mean 100 episode reward | 0.31         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 137262       |\n",
            "------------------------------------------\n",
            "  4% 140681/4000000 [19:47<8:00:41, 133.81it/s]-----------------------------------------\n",
            "| % time spent exploring  | 65          |\n",
            "| demo sample rate        | 0.363       |\n",
            "| elapsed time            | 00:39:02    |\n",
            "| episodes                | 4200        |\n",
            "| epsilon                 | 0.6517799   |\n",
            "| loss_l2                 | 0.007223175 |\n",
            "| loss_margin             | 0.006421199 |\n",
            "| loss_n_td               | 0.008141592 |\n",
            "| loss_td                 | 0.031769417 |\n",
            "| losses_all              | 0.017514978 |\n",
            "| max 100 episode reward  | 4           |\n",
            "| mean 100 episode reward | 0.34        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 140695      |\n",
            "-----------------------------------------\n",
            "  4% 144293/4000000 [20:18<7:47:40, 137.41it/s]-----------------------------------------\n",
            "| % time spent exploring  | 64          |\n",
            "| demo sample rate        | 0.359       |\n",
            "| elapsed time            | 00:39:33    |\n",
            "| episodes                | 4300        |\n",
            "| epsilon                 | 0.64287484  |\n",
            "| loss_l2                 | 0.007188741 |\n",
            "| loss_margin             | 0.00113957  |\n",
            "| loss_n_td               | 0.003659214 |\n",
            "| loss_td                 | 0.0181144   |\n",
            "| losses_all              | 0.012435894 |\n",
            "| max 100 episode reward  | 4           |\n",
            "| mean 100 episode reward | 0.36        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 144293      |\n",
            "-----------------------------------------\n",
            "  4% 147420/4000000 [20:47<8:08:41, 131.39it/s]------------------------------------------\n",
            "| % time spent exploring  | 63           |\n",
            "| demo sample rate        | 0.355        |\n",
            "| elapsed time            | 00:40:01     |\n",
            "| episodes                | 4400         |\n",
            "| epsilon                 | 0.6351355    |\n",
            "| loss_l2                 | 0.0071525034 |\n",
            "| loss_margin             | 0.00802407   |\n",
            "| loss_n_td               | 0.0016382023 |\n",
            "| loss_td                 | 0.014511048  |\n",
            "| losses_all              | 0.01244093   |\n",
            "| max 100 episode reward  | 3            |\n",
            "| mean 100 episode reward | 0.2          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 147420       |\n",
            "------------------------------------------\n",
            "  4% 151266/4000000 [21:20<8:13:04, 130.09it/s]-------------------------------------------\n",
            "| % time spent exploring  | 62            |\n",
            "| demo sample rate        | 0.351         |\n",
            "| elapsed time            | 00:40:35      |\n",
            "| episodes                | 4500          |\n",
            "| epsilon                 | 0.6255869     |\n",
            "| loss_l2                 | 0.0071196146  |\n",
            "| loss_margin             | 0.00077142566 |\n",
            "| loss_n_td               | 0.0027931225  |\n",
            "| loss_td                 | 0.012728804   |\n",
            "| losses_all              | 0.0110780075  |\n",
            "| max 100 episode reward  | 4             |\n",
            "| mean 100 episode reward | 0.41          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 151278        |\n",
            "-------------------------------------------\n",
            "  4% 154564/4000000 [21:49<7:50:04, 136.34it/s]-----------------------------------------\n",
            "| % time spent exploring  | 61          |\n",
            "| demo sample rate        | 0.348       |\n",
            "| elapsed time            | 00:41:04    |\n",
            "| episodes                | 4600        |\n",
            "| epsilon                 | 0.61743927  |\n",
            "| loss_l2                 | 0.007082389 |\n",
            "| loss_margin             | 0.006207695 |\n",
            "| loss_n_td               | 0.005470406 |\n",
            "| loss_td                 | 0.04128936  |\n",
            "| losses_all              | 0.015925221 |\n",
            "| max 100 episode reward  | 2           |\n",
            "| mean 100 episode reward | 0.29        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 154570      |\n",
            "-----------------------------------------\n",
            "  4% 158814/4000000 [22:26<8:12:22, 130.02it/s]------------------------------------------\n",
            "| % time spent exploring  | 60           |\n",
            "| demo sample rate        | 0.343        |\n",
            "| elapsed time            | 00:41:41     |\n",
            "| episodes                | 4700         |\n",
            "| epsilon                 | 0.6069032    |\n",
            "| loss_l2                 | 0.0070359656 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0025984151 |\n",
            "| loss_td                 | 0.018525334  |\n",
            "| losses_all              | 0.011731343  |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 0.54         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 158827       |\n",
            "------------------------------------------\n",
            "  4% 162673/4000000 [23:00<7:58:48, 133.57it/s]------------------------------------------\n",
            "| % time spent exploring  | 59           |\n",
            "| demo sample rate        | 0.339        |\n",
            "| elapsed time            | 00:42:14     |\n",
            "| episodes                | 4800         |\n",
            "| epsilon                 | 0.5973794    |\n",
            "| loss_l2                 | 0.007000461  |\n",
            "| loss_margin             | 0.0015572794 |\n",
            "| loss_n_td               | 0.0014721242 |\n",
            "| loss_td                 | 0.014000535  |\n",
            "| losses_all              | 0.011187891  |\n",
            "| max 100 episode reward  | 3            |\n",
            "| mean 100 episode reward | 0.42         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 162675       |\n",
            "------------------------------------------\n",
            "  4% 166276/4000000 [23:32<8:01:36, 132.67it/s]------------------------------------------\n",
            "| % time spent exploring  | 58           |\n",
            "| demo sample rate        | 0.335        |\n",
            "| elapsed time            | 00:42:46     |\n",
            "| episodes                | 4900         |\n",
            "| epsilon                 | 0.58844465   |\n",
            "| loss_l2                 | 0.006965459  |\n",
            "| loss_margin             | 0.012346374  |\n",
            "| loss_n_td               | 0.0037025746 |\n",
            "| loss_td                 | 0.022432994  |\n",
            "| losses_all              | 0.013382627  |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 0.42         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 166285       |\n",
            "------------------------------------------\n",
            "  4% 170549/4000000 [24:08<7:50:48, 135.56it/s]------------------------------------------\n",
            "| % time spent exploring  | 57           |\n",
            "| demo sample rate        | 0.331        |\n",
            "| elapsed time            | 00:43:23     |\n",
            "| episodes                | 5000         |\n",
            "| epsilon                 | 0.5778739    |\n",
            "| loss_l2                 | 0.006927988  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0042321747 |\n",
            "| loss_td                 | 0.016452156  |\n",
            "| losses_all              | 0.011875961  |\n",
            "| max 100 episode reward  | 6            |\n",
            "| mean 100 episode reward | 0.59         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 170556       |\n",
            "------------------------------------------\n",
            "  4% 174645/4000000 [24:44<7:51:17, 135.28it/s]------------------------------------------\n",
            "| % time spent exploring  | 56           |\n",
            "| demo sample rate        | 0.327        |\n",
            "| elapsed time            | 00:43:59     |\n",
            "| episodes                | 5100         |\n",
            "| epsilon                 | 0.5677363    |\n",
            "| loss_l2                 | 0.0068963375 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0030565257 |\n",
            "| loss_td                 | 0.025871966  |\n",
            "| losses_all              | 0.0129904635 |\n",
            "| max 100 episode reward  | 3            |\n",
            "| mean 100 episode reward | 0.5          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 174652       |\n",
            "------------------------------------------\n",
            "  4% 178830/4000000 [25:20<8:01:15, 132.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 55           |\n",
            "| demo sample rate        | 0.324        |\n",
            "| elapsed time            | 00:44:35     |\n",
            "| episodes                | 5200         |\n",
            "| epsilon                 | 0.5573611    |\n",
            "| loss_l2                 | 0.0068610734 |\n",
            "| loss_margin             | 0.011163663  |\n",
            "| loss_n_td               | 0.0024762466 |\n",
            "| loss_td                 | 0.021498853  |\n",
            "| losses_all              | 0.014341835  |\n",
            "| max 100 episode reward  | 3            |\n",
            "| mean 100 episode reward | 0.53         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 178844       |\n",
            "------------------------------------------\n",
            "  5% 183075/4000000 [25:57<8:06:03, 130.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 54           |\n",
            "| demo sample rate        | 0.32         |\n",
            "| elapsed time            | 00:45:12     |\n",
            "| episodes                | 5300         |\n",
            "| epsilon                 | 0.5468696    |\n",
            "| loss_l2                 | 0.0068394444 |\n",
            "| loss_margin             | 0.0013680756 |\n",
            "| loss_n_td               | 0.0036038607 |\n",
            "| loss_td                 | 0.022508781  |\n",
            "| losses_all              | 0.01391685   |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 0.55         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 183083       |\n",
            "------------------------------------------\n",
            "  5% 187158/4000000 [26:33<7:48:22, 135.67it/s]------------------------------------------\n",
            "| % time spent exploring  | 53           |\n",
            "| demo sample rate        | 0.316        |\n",
            "| elapsed time            | 00:45:47     |\n",
            "| episodes                | 5400         |\n",
            "| epsilon                 | 0.53677404   |\n",
            "| loss_l2                 | 0.0068089687 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.000921845  |\n",
            "| loss_td                 | 0.0106216315 |\n",
            "| losses_all              | 0.010245582  |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 0.49         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 187162       |\n",
            "------------------------------------------\n",
            "  5% 191985/4000000 [27:14<8:03:19, 131.31it/s]------------------------------------------\n",
            "| % time spent exploring  | 52           |\n",
            "| demo sample rate        | 0.312        |\n",
            "| elapsed time            | 00:46:29     |\n",
            "| episodes                | 5500         |\n",
            "| epsilon                 | 0.52480245   |\n",
            "| loss_l2                 | 0.006773832  |\n",
            "| loss_margin             | 0.0087106265 |\n",
            "| loss_n_td               | 0.0031117338 |\n",
            "| loss_td                 | 0.020584064  |\n",
            "| losses_all              | 0.014110519  |\n",
            "| max 100 episode reward  | 6            |\n",
            "| mean 100 episode reward | 0.68         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 191999       |\n",
            "------------------------------------------\n",
            "  5% 197960/4000000 [28:04<7:31:38, 140.31it/s]------------------------------------------\n",
            "| % time spent exploring  | 51           |\n",
            "| demo sample rate        | 0.307        |\n",
            "| elapsed time            | 00:47:19     |\n",
            "| episodes                | 5600         |\n",
            "| epsilon                 | 0.5100391    |\n",
            "| loss_l2                 | 0.0067282226 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.002249543  |\n",
            "| loss_td                 | 0.022709284  |\n",
            "| losses_all              | 0.011392139  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 0.98         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 197964       |\n",
            "------------------------------------------\n",
            "  5% 199991/4000000 [28:22<7:58:28, 132.36it/s]saved checkpoint\n",
            "  5% 202909/4000000 [28:47<7:29:50, 140.68it/s]------------------------------------------\n",
            "| % time spent exploring  | 49           |\n",
            "| demo sample rate        | 0.303        |\n",
            "| elapsed time            | 00:48:02     |\n",
            "| episodes                | 5700         |\n",
            "| epsilon                 | 0.49778786   |\n",
            "| loss_l2                 | 0.00670078   |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0023227804 |\n",
            "| loss_td                 | 0.058232233  |\n",
            "| losses_all              | 0.017676229  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 0.73         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 202914       |\n",
            "------------------------------------------\n",
            "  5% 208129/4000000 [29:31<7:48:11, 134.98it/s]------------------------------------------\n",
            "| % time spent exploring  | 48           |\n",
            "| demo sample rate        | 0.299        |\n",
            "| elapsed time            | 00:48:46     |\n",
            "| episodes                | 5800         |\n",
            "| epsilon                 | 0.4848634    |\n",
            "| loss_l2                 | 0.006672492  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010114376 |\n",
            "| loss_td                 | 0.019837383  |\n",
            "| losses_all              | 0.011712067  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 0.81         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 208136       |\n",
            "------------------------------------------\n",
            "  5% 213185/4000000 [30:14<7:59:47, 131.54it/s]-------------------------------------------\n",
            "| % time spent exploring  | 47            |\n",
            "| demo sample rate        | 0.295         |\n",
            "| elapsed time            | 00:49:29      |\n",
            "| episodes                | 5900          |\n",
            "| epsilon                 | 0.4723572     |\n",
            "| loss_l2                 | 0.0066499435  |\n",
            "| loss_margin             | 0.00064465404 |\n",
            "| loss_n_td               | 0.0006024495  |\n",
            "| loss_td                 | 0.034824625   |\n",
            "| losses_all              | 0.013463475   |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 0.82          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 213189        |\n",
            "-------------------------------------------\n",
            "  5% 219094/4000000 [31:04<8:26:02, 124.53it/s]------------------------------------------\n",
            "| % time spent exploring  | 45           |\n",
            "| demo sample rate        | 0.291        |\n",
            "| elapsed time            | 00:50:18     |\n",
            "| episodes                | 6000         |\n",
            "| epsilon                 | 0.45772254   |\n",
            "| loss_l2                 | 0.0066146306 |\n",
            "| loss_margin             | 0.0024471842 |\n",
            "| loss_n_td               | 0.0029712063 |\n",
            "| loss_td                 | 0.017818864  |\n",
            "| losses_all              | 0.012130763  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 0.99         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 219102       |\n",
            "------------------------------------------\n",
            "  6% 225027/4000000 [31:53<7:22:43, 142.11it/s]------------------------------------------\n",
            "| % time spent exploring  | 44           |\n",
            "| demo sample rate        | 0.287        |\n",
            "| elapsed time            | 00:51:08     |\n",
            "| episodes                | 6100         |\n",
            "| epsilon                 | 0.44304827   |\n",
            "| loss_l2                 | 0.0065956507 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0008338563 |\n",
            "| loss_td                 | 0.02102483   |\n",
            "| losses_all              | 0.01180435   |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.12         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 225031       |\n",
            "------------------------------------------\n",
            "  6% 230657/4000000 [32:41<7:36:04, 137.75it/s]-------------------------------------------\n",
            "| % time spent exploring  | 42            |\n",
            "| demo sample rate        | 0.283         |\n",
            "| elapsed time            | 00:51:56      |\n",
            "| episodes                | 6200          |\n",
            "| epsilon                 | 0.4291165     |\n",
            "| loss_l2                 | 0.006574348   |\n",
            "| loss_margin             | 0.00018749759 |\n",
            "| loss_n_td               | 0.0023599234  |\n",
            "| loss_td                 | 0.04126754    |\n",
            "| losses_all              | 0.01606516    |\n",
            "| max 100 episode reward  | 5             |\n",
            "| mean 100 episode reward | 0.88          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 230660        |\n",
            "-------------------------------------------\n",
            "  6% 236858/4000000 [33:33<7:44:38, 134.98it/s]------------------------------------------\n",
            "| % time spent exploring  | 41           |\n",
            "| demo sample rate        | 0.279        |\n",
            "| elapsed time            | 00:52:47     |\n",
            "| episodes                | 6300         |\n",
            "| epsilon                 | 0.4137418    |\n",
            "| loss_l2                 | 0.006549897  |\n",
            "| loss_margin             | 0.017944604  |\n",
            "| loss_n_td               | 0.0035257712 |\n",
            "| loss_td                 | 0.023273334  |\n",
            "| losses_all              | 0.016748352  |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 1.11         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 236872       |\n",
            "------------------------------------------\n",
            "  6% 242761/4000000 [34:22<7:41:43, 135.62it/s]-----------------------------------------\n",
            "| % time spent exploring  | 39          |\n",
            "| demo sample rate        | 0.275       |\n",
            "| elapsed time            | 00:53:37    |\n",
            "| episodes                | 6400        |\n",
            "| epsilon                 | 0.39914426  |\n",
            "| loss_l2                 | 0.0065313   |\n",
            "| loss_margin             | 0.008053577 |\n",
            "| loss_n_td               | 0.020868758 |\n",
            "| loss_td                 | 0.021667477 |\n",
            "| losses_all              | 0.01514123  |\n",
            "| max 100 episode reward  | 5           |\n",
            "| mean 100 episode reward | 1.03        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 242770      |\n",
            "-----------------------------------------\n",
            "  6% 249089/4000000 [35:14<7:17:38, 142.84it/s]------------------------------------------\n",
            "| % time spent exploring  | 38           |\n",
            "| demo sample rate        | 0.271        |\n",
            "| elapsed time            | 00:54:29     |\n",
            "| episodes                | 6500         |\n",
            "| epsilon                 | 0.38350472   |\n",
            "| loss_l2                 | 0.006505297  |\n",
            "| loss_margin             | 0.0020107646 |\n",
            "| loss_n_td               | 0.0027561984 |\n",
            "| loss_td                 | 0.025233692  |\n",
            "| losses_all              | 0.014585488  |\n",
            "| max 100 episode reward  | 4            |\n",
            "| mean 100 episode reward | 1.14         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 249089       |\n",
            "------------------------------------------\n",
            "  6% 256289/4000000 [36:13<7:20:31, 141.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 36           |\n",
            "| demo sample rate        | 0.267        |\n",
            "| elapsed time            | 00:55:28     |\n",
            "| episodes                | 6600         |\n",
            "| epsilon                 | 0.36567977   |\n",
            "| loss_l2                 | 0.006486809  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0017571994 |\n",
            "| loss_td                 | 0.016264204  |\n",
            "| losses_all              | 0.011136132  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.41         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 256291       |\n",
            "------------------------------------------\n",
            "  7% 260113/4000000 [36:45<7:23:37, 140.51it/s]saved best model\n",
            "  7% 262671/4000000 [37:07<7:25:21, 139.86it/s]------------------------------------------\n",
            "| % time spent exploring  | 34           |\n",
            "| demo sample rate        | 0.263        |\n",
            "| elapsed time            | 00:56:21     |\n",
            "| episodes                | 6700         |\n",
            "| epsilon                 | 0.349867     |\n",
            "| loss_l2                 | 0.0064716362 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0016920306 |\n",
            "| loss_td                 | 0.022171881  |\n",
            "| losses_all              | 0.012946278  |\n",
            "| max 100 episode reward  | 8            |\n",
            "| mean 100 episode reward | 1.27         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 262680       |\n",
            "------------------------------------------\n",
            "  7% 269677/4000000 [38:04<7:34:41, 136.73it/s]saved best model\n",
            "  7% 269764/4000000 [38:05<7:59:42, 129.60it/s]------------------------------------------\n",
            "| % time spent exploring  | 33           |\n",
            "| demo sample rate        | 0.259        |\n",
            "| elapsed time            | 00:57:20     |\n",
            "| episodes                | 6800         |\n",
            "| epsilon                 | 0.3323168    |\n",
            "| loss_l2                 | 0.0064515905 |\n",
            "| loss_margin             | 0.008560628  |\n",
            "| loss_n_td               | 0.0044572894 |\n",
            "| loss_td                 | 0.02726984   |\n",
            "| losses_all              | 0.014690423  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.76         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 269771       |\n",
            "------------------------------------------\n",
            "  7% 277397/4000000 [39:06<7:19:06, 141.29it/s]------------------------------------------\n",
            "| % time spent exploring  | 31           |\n",
            "| demo sample rate        | 0.255        |\n",
            "| elapsed time            | 00:58:21     |\n",
            "| episodes                | 6900         |\n",
            "| epsilon                 | 0.31342757   |\n",
            "| loss_l2                 | 0.0064416733 |\n",
            "| loss_margin             | 0.016085297  |\n",
            "| loss_n_td               | 0.0033026184 |\n",
            "| loss_td                 | 0.021299832  |\n",
            "| losses_all              | 0.01584556   |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 1.81         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 277403       |\n",
            "------------------------------------------\n",
            "  7% 285582/4000000 [40:12<7:21:35, 140.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 29           |\n",
            "| demo sample rate        | 0.25         |\n",
            "| elapsed time            | 00:59:27     |\n",
            "| episodes                | 7000         |\n",
            "| epsilon                 | 0.2931697    |\n",
            "| loss_l2                 | 0.0064196796 |\n",
            "| loss_margin             | 0.008459356  |\n",
            "| loss_n_td               | 0.025696797  |\n",
            "| loss_td                 | 0.02685028   |\n",
            "| losses_all              | 0.017852355  |\n",
            "| max 100 episode reward  | 8            |\n",
            "| mean 100 episode reward | 1.8          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 285588       |\n",
            "------------------------------------------\n",
            "  7% 292947/4000000 [41:12<7:30:30, 137.14it/s]------------------------------------------\n",
            "| % time spent exploring  | 27           |\n",
            "| demo sample rate        | 0.247        |\n",
            "| elapsed time            | 01:00:27     |\n",
            "| episodes                | 7100         |\n",
            "| epsilon                 | 0.27494627   |\n",
            "| loss_l2                 | 0.006408796  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0005931077 |\n",
            "| loss_td                 | 0.027696982  |\n",
            "| losses_all              | 0.012981802  |\n",
            "| max 100 episode reward  | 5            |\n",
            "| mean 100 episode reward | 1.95         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 292951       |\n",
            "------------------------------------------\n",
            "  7% 299991/4000000 [42:10<7:21:58, 139.52it/s]saved checkpoint\n",
            "  8% 300777/4000000 [42:17<7:41:58, 133.46it/s]-----------------------------------------\n",
            "| % time spent exploring  | 25          |\n",
            "| demo sample rate        | 0.243       |\n",
            "| elapsed time            | 01:01:31    |\n",
            "| episodes                | 7200        |\n",
            "| epsilon                 | 0.25554723  |\n",
            "| loss_l2                 | 0.006395499 |\n",
            "| loss_margin             | 0.003873961 |\n",
            "| loss_n_td               | 0.004054553 |\n",
            "| loss_td                 | 0.032008156 |\n",
            "| losses_all              | 0.015024428 |\n",
            "| max 100 episode reward  | 7           |\n",
            "| mean 100 episode reward | 2.02        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 300789      |\n",
            "-----------------------------------------\n",
            "  8% 307241/4000000 [43:10<7:28:38, 137.18it/s]saved best model\n",
            "  8% 308285/4000000 [43:18<7:16:54, 140.83it/s]-----------------------------------------\n",
            "| % time spent exploring  | 23          |\n",
            "| demo sample rate        | 0.239       |\n",
            "| elapsed time            | 01:02:33    |\n",
            "| episodes                | 7300        |\n",
            "| epsilon                 | 0.2369872   |\n",
            "| loss_l2                 | 0.006382553 |\n",
            "| loss_margin             | 0.013559675 |\n",
            "| loss_n_td               | 0.008718956 |\n",
            "| loss_td                 | 0.024633434 |\n",
            "| losses_all              | 0.016127966 |\n",
            "| max 100 episode reward  | 12          |\n",
            "| mean 100 episode reward | 1.88        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 308288      |\n",
            "-----------------------------------------\n",
            "  8% 317145/4000000 [44:30<7:25:03, 137.92it/s]------------------------------------------\n",
            "| % time spent exploring  | 21           |\n",
            "| demo sample rate        | 0.235        |\n",
            "| elapsed time            | 01:03:45     |\n",
            "| episodes                | 7400         |\n",
            "| epsilon                 | 0.2150389    |\n",
            "| loss_l2                 | 0.0063738804 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0018470616 |\n",
            "| loss_td                 | 0.014661094  |\n",
            "| losses_all              | 0.010657135  |\n",
            "| max 100 episode reward  | 7            |\n",
            "| mean 100 episode reward | 2.35         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 317156       |\n",
            "------------------------------------------\n",
            "  8% 326000/4000000 [45:42<7:10:02, 142.39it/s]------------------------------------------\n",
            "| % time spent exploring  | 19           |\n",
            "| demo sample rate        | 0.231        |\n",
            "| elapsed time            | 01:04:57     |\n",
            "| episodes                | 7500         |\n",
            "| epsilon                 | 0.19313763   |\n",
            "| loss_l2                 | 0.0063607604 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.006079749  |\n",
            "| loss_td                 | 0.024234932  |\n",
            "| losses_all              | 0.0143047795 |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 2.62         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 326005       |\n",
            "------------------------------------------\n",
            "  8% 330645/4000000 [46:20<7:11:15, 141.81it/s]saved best model\n",
            "  8% 334675/4000000 [46:53<7:14:09, 140.71it/s]------------------------------------------\n",
            "| % time spent exploring  | 17           |\n",
            "| demo sample rate        | 0.228        |\n",
            "| elapsed time            | 01:06:08     |\n",
            "| episodes                | 7600         |\n",
            "| epsilon                 | 0.17164968   |\n",
            "| loss_l2                 | 0.0063456586 |\n",
            "| loss_margin             | 0.000925418  |\n",
            "| loss_n_td               | 0.015097408  |\n",
            "| loss_td                 | 0.02661523   |\n",
            "| losses_all              | 0.014894542  |\n",
            "| max 100 episode reward  | 17           |\n",
            "| mean 100 episode reward | 2.56         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 334687       |\n",
            "------------------------------------------\n",
            "  9% 343817/4000000 [48:07<7:09:38, 141.83it/s]------------------------------------------\n",
            "| % time spent exploring  | 14           |\n",
            "| demo sample rate        | 0.224        |\n",
            "| elapsed time            | 01:07:22     |\n",
            "| episodes                | 7700         |\n",
            "| epsilon                 | 0.1490158    |\n",
            "| loss_l2                 | 0.0063237525 |\n",
            "| loss_margin             | 0.0072192177 |\n",
            "| loss_n_td               | 0.0072484273 |\n",
            "| loss_td                 | 0.027708791  |\n",
            "| losses_all              | 0.014363205  |\n",
            "| max 100 episode reward  | 10           |\n",
            "| mean 100 episode reward | 2.54         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 343832       |\n",
            "------------------------------------------\n",
            "  9% 352869/4000000 [49:21<7:15:25, 139.60it/s]------------------------------------------\n",
            "| % time spent exploring  | 12           |\n",
            "| demo sample rate        | 0.22         |\n",
            "| elapsed time            | 01:08:36     |\n",
            "| episodes                | 7800         |\n",
            "| epsilon                 | 0.1266121    |\n",
            "| loss_l2                 | 0.006306214  |\n",
            "| loss_margin             | 0.0055522285 |\n",
            "| loss_n_td               | 0.0017902508 |\n",
            "| loss_td                 | 0.039071634  |\n",
            "| losses_all              | 0.015892904  |\n",
            "| max 100 episode reward  | 9            |\n",
            "| mean 100 episode reward | 2.44         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 352884       |\n",
            "------------------------------------------\n",
            "  9% 362157/4000000 [50:36<7:02:55, 143.36it/s]------------------------------------------\n",
            "| % time spent exploring  | 10           |\n",
            "| demo sample rate        | 0.217        |\n",
            "| elapsed time            | 01:09:51     |\n",
            "| episodes                | 7900         |\n",
            "| epsilon                 | 0.10364658   |\n",
            "| loss_l2                 | 0.0062847896 |\n",
            "| loss_margin             | 0.0037775934 |\n",
            "| loss_n_td               | 0.0066977404 |\n",
            "| loss_td                 | 0.028955318  |\n",
            "| losses_all              | 0.014237355  |\n",
            "| max 100 episode reward  | 11           |\n",
            "| mean 100 episode reward | 2.74         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 362163       |\n",
            "------------------------------------------\n",
            "  9% 368297/4000000 [51:26<7:23:39, 136.43it/s]saved best model\n",
            "  9% 371569/4000000 [51:53<7:35:55, 132.64it/s]-------------------------------------------\n",
            "| % time spent exploring  | 8             |\n",
            "| demo sample rate        | 0.214         |\n",
            "| elapsed time            | 01:11:08      |\n",
            "| episodes                | 8000          |\n",
            "| epsilon                 | 0.080361776   |\n",
            "| loss_l2                 | 0.0062593785  |\n",
            "| loss_margin             | 0.0006979015  |\n",
            "| loss_n_td               | 0.00078877405 |\n",
            "| loss_td                 | 0.032319576   |\n",
            "| losses_all              | 0.014404349   |\n",
            "| max 100 episode reward  | 18            |\n",
            "| mean 100 episode reward | 3.05          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 371571        |\n",
            "-------------------------------------------\n",
            " 10% 382289/4000000 [53:19<6:59:42, 143.66it/s]-----------------------------------------\n",
            "| % time spent exploring  | 5           |\n",
            "| demo sample rate        | 0.21        |\n",
            "| elapsed time            | 01:12:34    |\n",
            "| episodes                | 8100        |\n",
            "| epsilon                 | 0.053805023 |\n",
            "| loss_l2                 | 0.006245887 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.00645579  |\n",
            "| loss_td                 | 0.02298396  |\n",
            "| losses_all              | 0.014415274 |\n",
            "| max 100 episode reward  | 13          |\n",
            "| mean 100 episode reward | 3.73        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 382301      |\n",
            "-----------------------------------------\n",
            " 10% 393013/4000000 [54:45<7:21:10, 136.26it/s]-------------------------------------------\n",
            "| % time spent exploring  | 2             |\n",
            "| demo sample rate        | 0.206         |\n",
            "| elapsed time            | 01:14:00      |\n",
            "| episodes                | 8200          |\n",
            "| epsilon                 | 0.02726065    |\n",
            "| loss_l2                 | 0.0062199826  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00062651304 |\n",
            "| loss_td                 | 0.026471619   |\n",
            "| losses_all              | 0.013471237   |\n",
            "| max 100 episode reward  | 15            |\n",
            "| mean 100 episode reward | 3.9           |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 393026        |\n",
            "-------------------------------------------\n",
            " 10% 398053/4000000 [55:26<6:49:53, 146.46it/s]saved best model\n",
            " 10% 399993/4000000 [55:42<7:02:44, 141.93it/s]saved checkpoint\n",
            " 10% 404361/4000000 [56:16<7:19:58, 136.21it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.203        |\n",
            "| elapsed time            | 01:15:31     |\n",
            "| episodes                | 8300         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.006192961  |\n",
            "| loss_margin             | 0.010757379  |\n",
            "| loss_n_td               | 0.0023117387 |\n",
            "| loss_td                 | 0.015726883  |\n",
            "| losses_all              | 0.011670417  |\n",
            "| max 100 episode reward  | 22           |\n",
            "| mean 100 episode reward | 4.41         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 404367       |\n",
            "------------------------------------------\n",
            " 10% 415648/4000000 [57:47<7:01:26, 141.75it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.199        |\n",
            "| elapsed time            | 01:17:02     |\n",
            "| episodes                | 8400         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0061697187 |\n",
            "| loss_margin             | 0.0035895333 |\n",
            "| loss_n_td               | 0.0035310162 |\n",
            "| loss_td                 | 0.029429544  |\n",
            "| losses_all              | 0.013728041  |\n",
            "| max 100 episode reward  | 21           |\n",
            "| mean 100 episode reward | 4.39         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 415653       |\n",
            "------------------------------------------\n",
            " 11% 426129/4000000 [59:12<7:01:49, 141.21it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.196        |\n",
            "| elapsed time            | 01:18:27     |\n",
            "| episodes                | 8500         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0061513977 |\n",
            "| loss_margin             | 0.0035113953 |\n",
            "| loss_n_td               | 0.004206609  |\n",
            "| loss_td                 | 0.030246567  |\n",
            "| losses_all              | 0.013377542  |\n",
            "| max 100 episode reward  | 12           |\n",
            "| mean 100 episode reward | 3.13         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 426133       |\n",
            "------------------------------------------\n",
            " 11% 437485/4000000 [1:00:42<7:09:34, 138.22it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.193        |\n",
            "| elapsed time            | 01:19:57     |\n",
            "| episodes                | 8600         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.006136914  |\n",
            "| loss_margin             | 0.005843589  |\n",
            "| loss_n_td               | 0.0010930719 |\n",
            "| loss_td                 | 0.022644412  |\n",
            "| losses_all              | 0.012417007  |\n",
            "| max 100 episode reward  | 19           |\n",
            "| mean 100 episode reward | 4.64         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 437492       |\n",
            "------------------------------------------\n",
            " 11% 447813/4000000 [1:02:07<7:46:16, 126.97it/s]saved best model\n",
            " 11% 449341/4000000 [1:02:20<7:29:58, 131.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.19         |\n",
            "| elapsed time            | 01:21:35     |\n",
            "| episodes                | 8700         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.006107496  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0039715646 |\n",
            "| loss_td                 | 0.022174088  |\n",
            "| losses_all              | 0.012434687  |\n",
            "| max 100 episode reward  | 23           |\n",
            "| mean 100 episode reward | 4.41         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 449352       |\n",
            "------------------------------------------\n",
            " 12% 461199/4000000 [1:03:56<7:01:34, 139.90it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.187        |\n",
            "| elapsed time            | 01:23:11     |\n",
            "| episodes                | 8800         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0060814074 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010605429 |\n",
            "| loss_td                 | 0.018182095  |\n",
            "| losses_all              | 0.010542061  |\n",
            "| max 100 episode reward  | 17           |\n",
            "| mean 100 episode reward | 4.22         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 461205       |\n",
            "------------------------------------------\n",
            " 12% 461932/4000000 [1:04:02<6:57:28, 141.25it/s]saved best model\n",
            " 12% 473129/4000000 [1:05:32<7:07:27, 137.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.184        |\n",
            "| elapsed time            | 01:24:47     |\n",
            "| episodes                | 8900         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0060599693 |\n",
            "| loss_margin             | 0.0058857873 |\n",
            "| loss_n_td               | 0.0020123841 |\n",
            "| loss_td                 | 0.029482577  |\n",
            "| losses_all              | 0.014445156  |\n",
            "| max 100 episode reward  | 133          |\n",
            "| mean 100 episode reward | 5.53         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 473136       |\n",
            "------------------------------------------\n",
            " 12% 486601/4000000 [1:07:19<7:17:10, 133.94it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.181       |\n",
            "| elapsed time            | 01:26:34    |\n",
            "| episodes                | 9000        |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.00603277  |\n",
            "| loss_margin             | 0.013188962 |\n",
            "| loss_n_td               | 0.005103446 |\n",
            "| loss_td                 | 0.029071845 |\n",
            "| losses_all              | 0.015323408 |\n",
            "| max 100 episode reward  | 25          |\n",
            "| mean 100 episode reward | 4.91        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 486614      |\n",
            "-----------------------------------------\n",
            " 12% 498534/4000000 [1:08:55<7:03:53, 137.67it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.178        |\n",
            "| elapsed time            | 01:28:10     |\n",
            "| episodes                | 9100         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.006009979  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0049691624 |\n",
            "| loss_td                 | 0.01597431   |\n",
            "| losses_all              | 0.010540541  |\n",
            "| max 100 episode reward  | 22           |\n",
            "| mean 100 episode reward | 4.75         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 498536       |\n",
            "------------------------------------------\n",
            " 12% 499986/4000000 [1:09:08<7:24:30, 131.23it/s]saved checkpoint\n",
            " 13% 501305/4000000 [1:09:18<7:17:17, 133.35it/s]saved best model\n",
            " 13% 511489/4000000 [1:10:39<7:07:40, 135.95it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.175       |\n",
            "| elapsed time            | 01:29:54    |\n",
            "| episodes                | 9200        |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.005977289 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.003907038 |\n",
            "| loss_td                 | 0.014985774 |\n",
            "| losses_all              | 0.010250785 |\n",
            "| max 100 episode reward  | 227         |\n",
            "| mean 100 episode reward | 8.26        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 511498      |\n",
            "-----------------------------------------\n",
            " 13% 523321/4000000 [1:12:14<6:53:19, 140.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.173        |\n",
            "| elapsed time            | 01:31:29     |\n",
            "| episodes                | 9300         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005952534  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0009682165 |\n",
            "| loss_td                 | 0.021095527  |\n",
            "| losses_all              | 0.011042522  |\n",
            "| max 100 episode reward  | 23           |\n",
            "| mean 100 episode reward | 4.71         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 523330       |\n",
            "------------------------------------------\n",
            " 13% 535389/4000000 [1:13:53<6:56:42, 138.57it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.17         |\n",
            "| elapsed time            | 01:33:08     |\n",
            "| episodes                | 9400         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0059352783 |\n",
            "| loss_margin             | 0.0037026294 |\n",
            "| loss_n_td               | 0.0025995113 |\n",
            "| loss_td                 | 0.016494496  |\n",
            "| losses_all              | 0.010802666  |\n",
            "| max 100 episode reward  | 23           |\n",
            "| mean 100 episode reward | 4            |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 535398       |\n",
            "------------------------------------------\n",
            " 14% 547837/4000000 [1:15:32<6:42:31, 142.94it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.168        |\n",
            "| elapsed time            | 01:34:47     |\n",
            "| episodes                | 9500         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0059230095 |\n",
            "| loss_margin             | 0.0036893077 |\n",
            "| loss_n_td               | 0.0027168745 |\n",
            "| loss_td                 | 0.01803031   |\n",
            "| losses_all              | 0.011297438  |\n",
            "| max 100 episode reward  | 25           |\n",
            "| mean 100 episode reward | 5.09         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 547850       |\n",
            "------------------------------------------\n",
            " 14% 560709/4000000 [1:17:15<7:05:28, 134.72it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.166        |\n",
            "| elapsed time            | 01:36:30     |\n",
            "| episodes                | 9600         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005895489  |\n",
            "| loss_margin             | 0.008108009  |\n",
            "| loss_n_td               | 0.0018296272 |\n",
            "| loss_td                 | 0.012555523  |\n",
            "| losses_all              | 0.01095447   |\n",
            "| max 100 episode reward  | 222          |\n",
            "| mean 100 episode reward | 8.05         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 560722       |\n",
            "------------------------------------------\n",
            " 14% 574145/4000000 [1:19:03<6:42:55, 141.71it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.163        |\n",
            "| elapsed time            | 01:38:18     |\n",
            "| episodes                | 9700         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.00587982   |\n",
            "| loss_margin             | 0.018446308  |\n",
            "| loss_n_td               | 0.0048205457 |\n",
            "| loss_td                 | 0.013796017  |\n",
            "| losses_all              | 0.013014302  |\n",
            "| max 100 episode reward  | 31           |\n",
            "| mean 100 episode reward | 4.76         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 574160       |\n",
            "------------------------------------------\n",
            " 15% 587121/4000000 [1:20:48<6:41:03, 141.83it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.161        |\n",
            "| elapsed time            | 01:40:03     |\n",
            "| episodes                | 9800         |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0058695055 |\n",
            "| loss_margin             | 0.010839172  |\n",
            "| loss_n_td               | 0.0004946144 |\n",
            "| loss_td                 | 0.013059482  |\n",
            "| losses_all              | 0.010884119  |\n",
            "| max 100 episode reward  | 23           |\n",
            "| mean 100 episode reward | 4.3          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 587121       |\n",
            "------------------------------------------\n",
            " 15% 599987/4000000 [1:22:33<7:07:34, 132.53it/s]saved checkpoint\n",
            " 15% 600077/4000000 [1:22:33<7:34:33, 124.66it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.159         |\n",
            "| elapsed time            | 01:41:49      |\n",
            "| episodes                | 9900          |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0058484897  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00068672653 |\n",
            "| loss_td                 | 0.024110256   |\n",
            "| losses_all              | 0.01263497    |\n",
            "| max 100 episode reward  | 29            |\n",
            "| mean 100 episode reward | 4.61          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 600081        |\n",
            "-------------------------------------------\n",
            " 15% 612569/4000000 [1:24:17<6:48:33, 138.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.157        |\n",
            "| elapsed time            | 01:43:32     |\n",
            "| episodes                | 10000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0058206897 |\n",
            "| loss_margin             | 0.0016475953 |\n",
            "| loss_n_td               | 0.0071190023 |\n",
            "| loss_td                 | 0.028847247  |\n",
            "| losses_all              | 0.013776167  |\n",
            "| max 100 episode reward  | 20           |\n",
            "| mean 100 episode reward | 4.29         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 612577       |\n",
            "------------------------------------------\n",
            " 16% 622798/4000000 [1:25:40<6:52:17, 136.52it/s]saved best model\n",
            " 16% 625889/4000000 [1:26:04<6:37:34, 141.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.155        |\n",
            "| elapsed time            | 01:45:19     |\n",
            "| episodes                | 10100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0057991245 |\n",
            "| loss_margin             | 0.002531942  |\n",
            "| loss_n_td               | 0.001681413  |\n",
            "| loss_td                 | 0.035090502  |\n",
            "| losses_all              | 0.013928467  |\n",
            "| max 100 episode reward  | 356          |\n",
            "| mean 100 episode reward | 8.04         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 625893       |\n",
            "------------------------------------------\n",
            " 16% 638596/4000000 [1:27:47<6:37:29, 140.94it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.154         |\n",
            "| elapsed time            | 01:47:02      |\n",
            "| episodes                | 10200         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0057843504  |\n",
            "| loss_margin             | 0.0019499101  |\n",
            "| loss_n_td               | 0.00020109667 |\n",
            "| loss_td                 | 0.019432286   |\n",
            "| losses_all              | 0.010274      |\n",
            "| max 100 episode reward  | 24            |\n",
            "| mean 100 episode reward | 5.02          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 638606        |\n",
            "-------------------------------------------\n",
            " 16% 649284/4000000 [1:29:14<6:38:30, 140.14it/s]saved best model\n",
            " 16% 652675/4000000 [1:29:40<6:42:06, 138.74it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.152       |\n",
            "| elapsed time            | 01:48:55    |\n",
            "| episodes                | 10300       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.005759364 |\n",
            "| loss_margin             | 0.01037202  |\n",
            "| loss_n_td               | 0.002620553 |\n",
            "| loss_td                 | 0.01784385  |\n",
            "| losses_all              | 0.011740493 |\n",
            "| max 100 episode reward  | 366         |\n",
            "| mean 100 episode reward | 10.1        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 652677      |\n",
            "-----------------------------------------\n",
            " 17% 666830/4000000 [1:31:34<6:28:48, 142.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.15         |\n",
            "| elapsed time            | 01:50:49     |\n",
            "| episodes                | 10400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005736555  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0021087553 |\n",
            "| loss_td                 | 0.019625662  |\n",
            "| losses_all              | 0.009750752  |\n",
            "| max 100 episode reward  | 133          |\n",
            "| mean 100 episode reward | 6.82         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 666830       |\n",
            "------------------------------------------\n",
            " 17% 679620/4000000 [1:33:17<6:48:20, 135.52it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.148        |\n",
            "| elapsed time            | 01:52:32     |\n",
            "| episodes                | 10500        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0057226704 |\n",
            "| loss_margin             | 0.0022541694 |\n",
            "| loss_n_td               | 0.014961298  |\n",
            "| loss_td                 | 0.018896617  |\n",
            "| losses_all              | 0.012423059  |\n",
            "| max 100 episode reward  | 133          |\n",
            "| mean 100 episode reward | 5.65         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 679629       |\n",
            "------------------------------------------\n",
            " 17% 694172/4000000 [1:35:13<6:23:32, 143.65it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.147       |\n",
            "| elapsed time            | 01:54:28    |\n",
            "| episodes                | 10600       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.005705809 |\n",
            "| loss_margin             | 0.013234247 |\n",
            "| loss_n_td               | 0.024437452 |\n",
            "| loss_td                 | 0.024872068 |\n",
            "| losses_all              | 0.015297814 |\n",
            "| max 100 episode reward  | 238         |\n",
            "| mean 100 episode reward | 9.66        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 694177      |\n",
            "-----------------------------------------\n",
            " 17% 699997/4000000 [1:35:59<6:33:40, 139.71it/s]saved checkpoint\n",
            " 18% 709264/4000000 [1:37:13<6:38:42, 137.56it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.145         |\n",
            "| elapsed time            | 01:56:28      |\n",
            "| episodes                | 10700         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.005689675   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00018596146 |\n",
            "| loss_td                 | 0.014630051   |\n",
            "| losses_all              | 0.009445699   |\n",
            "| max 100 episode reward  | 183           |\n",
            "| mean 100 episode reward | 8.67          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 709275        |\n",
            "-------------------------------------------\n",
            " 18% 724073/4000000 [1:39:12<6:49:11, 133.43it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.143        |\n",
            "| elapsed time            | 01:58:27     |\n",
            "| episodes                | 10800        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0056637777 |\n",
            "| loss_margin             | 0.0029301606 |\n",
            "| loss_n_td               | 0.057963327  |\n",
            "| loss_td                 | 0.025598623  |\n",
            "| losses_all              | 0.018594887  |\n",
            "| max 100 episode reward  | 222          |\n",
            "| mean 100 episode reward | 10.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 724073       |\n",
            "------------------------------------------\n",
            " 18% 737897/4000000 [1:41:03<6:28:20, 140.00it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.142        |\n",
            "| elapsed time            | 02:00:18     |\n",
            "| episodes                | 10900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0056570014 |\n",
            "| loss_margin             | 0.0035793316 |\n",
            "| loss_n_td               | 0.03751192   |\n",
            "| loss_td                 | 0.03784406   |\n",
            "| losses_all              | 0.014878257  |\n",
            "| max 100 episode reward  | 218          |\n",
            "| mean 100 episode reward | 8.32         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 737897       |\n",
            "------------------------------------------\n",
            " 19% 753021/4000000 [1:43:02<6:21:00, 142.03it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.141       |\n",
            "| elapsed time            | 02:02:17    |\n",
            "| episodes                | 11000       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.005643122 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.004328249 |\n",
            "| loss_td                 | 0.043346982 |\n",
            "| losses_all              | 0.016646437 |\n",
            "| max 100 episode reward  | 30          |\n",
            "| mean 100 episode reward | 5.92        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 753028      |\n",
            "-----------------------------------------\n",
            " 19% 767805/4000000 [1:45:01<6:48:08, 131.99it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.139       |\n",
            "| elapsed time            | 02:04:16    |\n",
            "| episodes                | 11100       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.005631556 |\n",
            "| loss_margin             | 0.003979396 |\n",
            "| loss_n_td               | 0.001272734 |\n",
            "| loss_td                 | 0.01228047  |\n",
            "| losses_all              | 0.008938242 |\n",
            "| max 100 episode reward  | 139         |\n",
            "| mean 100 episode reward | 8.21        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 767811      |\n",
            "-----------------------------------------\n",
            " 20% 782328/4000000 [1:46:58<6:36:30, 135.25it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.138        |\n",
            "| elapsed time            | 02:06:13     |\n",
            "| episodes                | 11200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0056117624 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0003087523 |\n",
            "| loss_td                 | 0.017845027  |\n",
            "| losses_all              | 0.009910466  |\n",
            "| max 100 episode reward  | 22           |\n",
            "| mean 100 episode reward | 6.76         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 782332       |\n",
            "------------------------------------------\n",
            " 20% 797113/4000000 [1:48:59<6:22:22, 139.61it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.137        |\n",
            "| elapsed time            | 02:08:14     |\n",
            "| episodes                | 11300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005589997  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0051621376 |\n",
            "| loss_td                 | 0.0446518    |\n",
            "| losses_all              | 0.013826216  |\n",
            "| max 100 episode reward  | 32           |\n",
            "| mean 100 episode reward | 6.77         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 797116       |\n",
            "------------------------------------------\n",
            " 20% 799993/4000000 [1:49:22<6:39:24, 133.53it/s]saved checkpoint\n",
            " 20% 811350/4000000 [1:50:54<6:34:08, 134.83it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.135        |\n",
            "| elapsed time            | 02:10:09     |\n",
            "| episodes                | 11400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0055589173 |\n",
            "| loss_margin             | 0.013901289  |\n",
            "| loss_n_td               | 0.019832125  |\n",
            "| loss_td                 | 0.010931451  |\n",
            "| losses_all              | 0.012440775  |\n",
            "| max 100 episode reward  | 146          |\n",
            "| mean 100 episode reward | 7.84         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 811355       |\n",
            "------------------------------------------\n",
            " 21% 825429/4000000 [1:52:48<6:38:24, 132.80it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.134         |\n",
            "| elapsed time            | 02:12:03      |\n",
            "| episodes                | 11500         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.005538842   |\n",
            "| loss_margin             | 0.00047070254 |\n",
            "| loss_n_td               | 0.00045912806 |\n",
            "| loss_td                 | 0.016471816   |\n",
            "| losses_all              | 0.009733992   |\n",
            "| max 100 episode reward  | 286           |\n",
            "| mean 100 episode reward | 15.9          |\n",
            "| min 100 episode reward  | 1             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 825438        |\n",
            "-------------------------------------------\n",
            " 21% 840572/4000000 [1:54:50<6:26:41, 136.17it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.133       |\n",
            "| elapsed time            | 02:14:05    |\n",
            "| episodes                | 11600       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.005500151 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.0         |\n",
            "| loss_td                 | 0.024058316 |\n",
            "| losses_all              | 0.01094792  |\n",
            "| max 100 episode reward  | 133         |\n",
            "| mean 100 episode reward | 7.49        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 840581      |\n",
            "-----------------------------------------\n",
            " 21% 854689/4000000 [1:56:43<6:09:43, 141.78it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.132        |\n",
            "| elapsed time            | 02:15:58     |\n",
            "| episodes                | 11700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0054703555 |\n",
            "| loss_margin             | 0.0009727068 |\n",
            "| loss_n_td               | 0.0013184986 |\n",
            "| loss_td                 | 0.03997113   |\n",
            "| losses_all              | 0.012709979  |\n",
            "| max 100 episode reward  | 203          |\n",
            "| mean 100 episode reward | 9.11         |\n",
            "| min 100 episode reward  | 1            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 854698       |\n",
            "------------------------------------------\n",
            " 22% 869753/4000000 [1:58:44<6:37:47, 131.15it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.131         |\n",
            "| elapsed time            | 02:17:59      |\n",
            "| episodes                | 11800         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0054456047  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00026243032 |\n",
            "| loss_td                 | 0.023378048   |\n",
            "| losses_all              | 0.010448573   |\n",
            "| max 100 episode reward  | 361           |\n",
            "| mean 100 episode reward | 12.6          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 869767        |\n",
            "-------------------------------------------\n",
            " 22% 884157/4000000 [2:00:40<6:26:08, 134.49it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.13         |\n",
            "| elapsed time            | 02:19:55     |\n",
            "| episodes                | 11900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005432613  |\n",
            "| loss_margin             | 0.0047740005 |\n",
            "| loss_n_td               | 8.631744e-06 |\n",
            "| loss_td                 | 0.00898428   |\n",
            "| losses_all              | 0.008620421  |\n",
            "| max 100 episode reward  | 218          |\n",
            "| mean 100 episode reward | 9.33         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 884158       |\n",
            "------------------------------------------\n",
            " 22% 898890/4000000 [2:02:38<6:14:00, 138.19it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.129        |\n",
            "| elapsed time            | 02:21:53     |\n",
            "| episodes                | 12000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005419646  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0072690165 |\n",
            "| loss_td                 | 0.03728427   |\n",
            "| losses_all              | 0.012348095  |\n",
            "| max 100 episode reward  | 137          |\n",
            "| mean 100 episode reward | 7.05         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 898896       |\n",
            "------------------------------------------\n",
            " 22% 899997/4000000 [2:02:47<6:00:21, 143.38it/s]saved checkpoint\n",
            " 23% 914252/4000000 [2:04:41<6:13:00, 137.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.128        |\n",
            "| elapsed time            | 02:23:56     |\n",
            "| episodes                | 12100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0054151104 |\n",
            "| loss_margin             | 0.0034645395 |\n",
            "| loss_n_td               | 0.016644431  |\n",
            "| loss_td                 | 0.014792756  |\n",
            "| losses_all              | 0.011228018  |\n",
            "| max 100 episode reward  | 218          |\n",
            "| mean 100 episode reward | 8.68         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 914265       |\n",
            "------------------------------------------\n",
            " 23% 928325/4000000 [2:06:33<6:22:35, 133.81it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.127        |\n",
            "| elapsed time            | 02:25:48     |\n",
            "| episodes                | 12200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0054070996 |\n",
            "| loss_margin             | 0.002751466  |\n",
            "| loss_n_td               | 0.0008266578 |\n",
            "| loss_td                 | 0.07237848   |\n",
            "| losses_all              | 0.014684016  |\n",
            "| max 100 episode reward  | 255          |\n",
            "| mean 100 episode reward | 9.81         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 928330       |\n",
            "------------------------------------------\n",
            " 24% 942875/4000000 [2:08:28<6:00:19, 141.41it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.126       |\n",
            "| elapsed time            | 02:27:43    |\n",
            "| episodes                | 12300       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.005408724 |\n",
            "| loss_margin             | 0.013574913 |\n",
            "| loss_n_td               | 0.007627178 |\n",
            "| loss_td                 | 0.022399055 |\n",
            "| losses_all              | 0.013369965 |\n",
            "| max 100 episode reward  | 22          |\n",
            "| mean 100 episode reward | 5.94        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 942884      |\n",
            "-----------------------------------------\n",
            " 24% 958185/4000000 [2:10:30<6:08:23, 137.62it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.125         |\n",
            "| elapsed time            | 02:29:45      |\n",
            "| episodes                | 12400         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0053997124  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00091703155 |\n",
            "| loss_td                 | 0.017049123   |\n",
            "| losses_all              | 0.009208931   |\n",
            "| max 100 episode reward  | 24            |\n",
            "| mean 100 episode reward | 7.16          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 958196        |\n",
            "-------------------------------------------\n",
            " 24% 971765/4000000 [2:12:18<6:16:29, 134.05it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.125        |\n",
            "| elapsed time            | 02:31:34     |\n",
            "| episodes                | 12500        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0054025883 |\n",
            "| loss_margin             | 0.002022     |\n",
            "| loss_n_td               | 0.002655325  |\n",
            "| loss_td                 | 0.039916724  |\n",
            "| losses_all              | 0.012742388  |\n",
            "| max 100 episode reward  | 176          |\n",
            "| mean 100 episode reward | 7.81         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 971779       |\n",
            "------------------------------------------\n",
            " 25% 986852/4000000 [2:14:19<6:17:30, 133.03it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.124        |\n",
            "| elapsed time            | 02:33:34     |\n",
            "| episodes                | 12600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005412027  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0023792894 |\n",
            "| loss_td                 | 0.04048417   |\n",
            "| losses_all              | 0.0133052    |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 10.5         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 986864       |\n",
            "------------------------------------------\n",
            " 25% 999997/4000000 [2:16:05<6:05:57, 136.63it/s]saved checkpoint\n",
            " 25% 1001181/4000000 [2:16:14<5:53:11, 141.51it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.123        |\n",
            "| elapsed time            | 02:35:29     |\n",
            "| episodes                | 12700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005399774  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010456992 |\n",
            "| loss_td                 | 0.014834034  |\n",
            "| losses_all              | 0.008599071  |\n",
            "| max 100 episode reward  | 23           |\n",
            "| mean 100 episode reward | 5.81         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1001183      |\n",
            "------------------------------------------\n",
            " 25% 1016309/4000000 [2:18:14<6:04:45, 136.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.122        |\n",
            "| elapsed time            | 02:37:29     |\n",
            "| episodes                | 12800        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005408219  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0014155954 |\n",
            "| loss_td                 | 0.01665943   |\n",
            "| losses_all              | 0.0089767    |\n",
            "| max 100 episode reward  | 260          |\n",
            "| mean 100 episode reward | 10.6         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1016311      |\n",
            "------------------------------------------\n",
            " 26% 1031045/4000000 [2:20:11<5:47:42, 142.31it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.121       |\n",
            "| elapsed time            | 02:39:27    |\n",
            "| episodes                | 12900       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.005394655 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.015902124 |\n",
            "| loss_td                 | 0.026941631 |\n",
            "| losses_all              | 0.012886483 |\n",
            "| max 100 episode reward  | 324         |\n",
            "| mean 100 episode reward | 10.5        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1031045     |\n",
            "-----------------------------------------\n",
            " 26% 1046537/4000000 [2:22:14<5:58:57, 137.13it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.121        |\n",
            "| elapsed time            | 02:41:29     |\n",
            "| episodes                | 13000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0053970185 |\n",
            "| loss_margin             | 0.005837083  |\n",
            "| loss_n_td               | 0.028894264  |\n",
            "| loss_td                 | 0.01575122   |\n",
            "| losses_all              | 0.012183441  |\n",
            "| max 100 episode reward  | 255          |\n",
            "| mean 100 episode reward | 9.47         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1046550      |\n",
            "------------------------------------------\n",
            " 27% 1061941/4000000 [2:24:15<5:51:32, 139.29it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.12         |\n",
            "| elapsed time            | 02:43:30     |\n",
            "| episodes                | 13100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005401294  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0009819393 |\n",
            "| loss_td                 | 0.035487603  |\n",
            "| losses_all              | 0.0118240975 |\n",
            "| max 100 episode reward  | 222          |\n",
            "| mean 100 episode reward | 10.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1061946      |\n",
            "------------------------------------------\n",
            " 27% 1077397/4000000 [2:26:17<5:39:09, 143.62it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.119         |\n",
            "| elapsed time            | 02:45:33      |\n",
            "| episodes                | 13200         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0054082917  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00036482923 |\n",
            "| loss_td                 | 0.03054058    |\n",
            "| losses_all              | 0.011188777   |\n",
            "| max 100 episode reward  | 326           |\n",
            "| mean 100 episode reward | 9.54          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1077398       |\n",
            "-------------------------------------------\n",
            " 27% 1092585/4000000 [2:28:17<5:50:40, 138.18it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.119        |\n",
            "| elapsed time            | 02:47:32     |\n",
            "| episodes                | 13300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0054201665 |\n",
            "| loss_margin             | 0.0010625934 |\n",
            "| loss_n_td               | 0.017698063  |\n",
            "| loss_td                 | 0.029584378  |\n",
            "| losses_all              | 0.013815889  |\n",
            "| max 100 episode reward  | 19           |\n",
            "| mean 100 episode reward | 6.93         |\n",
            "| min 100 episode reward  | 2            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1092597      |\n",
            "------------------------------------------\n",
            " 27% 1099997/4000000 [2:29:16<5:37:59, 143.00it/s]saved checkpoint\n",
            " 28% 1107995/4000000 [2:30:21<5:54:58, 135.79it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.118        |\n",
            "| elapsed time            | 02:49:36     |\n",
            "| episodes                | 13400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005423643  |\n",
            "| loss_margin             | 0.0064773317 |\n",
            "| loss_n_td               | 0.0008037788 |\n",
            "| loss_td                 | 0.019171944  |\n",
            "| losses_all              | 0.01144832   |\n",
            "| max 100 episode reward  | 222          |\n",
            "| mean 100 episode reward | 9.98         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1107995      |\n",
            "------------------------------------------\n",
            " 28% 1122161/4000000 [2:32:16<5:48:19, 137.70it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.117        |\n",
            "| elapsed time            | 02:51:31     |\n",
            "| episodes                | 13500        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005427622  |\n",
            "| loss_margin             | 0.0018881634 |\n",
            "| loss_n_td               | 0.0038640741 |\n",
            "| loss_td                 | 0.010802949  |\n",
            "| losses_all              | 0.008107242  |\n",
            "| max 100 episode reward  | 235          |\n",
            "| mean 100 episode reward | 14.5         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1122162      |\n",
            "------------------------------------------\n",
            " 28% 1136417/4000000 [2:34:10<5:52:27, 135.41it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.117        |\n",
            "| elapsed time            | 02:53:25     |\n",
            "| episodes                | 13600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0054420275 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0039618537 |\n",
            "| loss_td                 | 0.01298878   |\n",
            "| losses_all              | 0.009502195  |\n",
            "| max 100 episode reward  | 199          |\n",
            "| mean 100 episode reward | 7.83         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1136425      |\n",
            "------------------------------------------\n",
            " 29% 1151608/4000000 [2:36:11<5:40:20, 139.49it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.116        |\n",
            "| elapsed time            | 02:55:27     |\n",
            "| episodes                | 13700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005460535  |\n",
            "| loss_margin             | 0.0006291568 |\n",
            "| loss_n_td               | 0.0006559029 |\n",
            "| loss_td                 | 0.06794819   |\n",
            "| losses_all              | 0.01511644   |\n",
            "| max 100 episode reward  | 222          |\n",
            "| mean 100 episode reward | 12.5         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1151618      |\n",
            "------------------------------------------\n",
            " 29% 1166637/4000000 [2:38:11<5:42:26, 137.90it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.115         |\n",
            "| elapsed time            | 02:57:26      |\n",
            "| episodes                | 13800         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.00548405    |\n",
            "| loss_margin             | 0.0064366423  |\n",
            "| loss_n_td               | 0.00014665585 |\n",
            "| loss_td                 | 0.12818399    |\n",
            "| losses_all              | 0.021152088   |\n",
            "| max 100 episode reward  | 146           |\n",
            "| mean 100 episode reward | 10.8          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1166648       |\n",
            "-------------------------------------------\n",
            " 29% 1179689/4000000 [2:39:59<5:38:06, 139.03it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.115         |\n",
            "| elapsed time            | 02:59:14      |\n",
            "| episodes                | 13900         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0055138343  |\n",
            "| loss_margin             | 2.6963651e-05 |\n",
            "| loss_n_td               | 0.000449013   |\n",
            "| loss_td                 | 0.026707169   |\n",
            "| losses_all              | 0.011571305   |\n",
            "| max 100 episode reward  | 159           |\n",
            "| mean 100 episode reward | 8.63          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1179700       |\n",
            "-------------------------------------------\n",
            " 30% 1194128/4000000 [2:41:55<5:30:06, 141.67it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.114         |\n",
            "| elapsed time            | 03:01:11      |\n",
            "| episodes                | 14000         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.005543961   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 1.5853073e-05 |\n",
            "| loss_td                 | 0.06825653    |\n",
            "| losses_all              | 0.016333083   |\n",
            "| max 100 episode reward  | 222           |\n",
            "| mean 100 episode reward | 10.5          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1194142       |\n",
            "-------------------------------------------\n",
            " 30% 1199997/4000000 [2:42:43<5:30:42, 141.11it/s]saved checkpoint\n",
            " 30% 1207989/4000000 [2:43:48<5:51:33, 132.36it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.114        |\n",
            "| elapsed time            | 03:03:03     |\n",
            "| episodes                | 14100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005552468  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 9.522888e-05 |\n",
            "| loss_td                 | 0.014613647  |\n",
            "| losses_all              | 0.008949162  |\n",
            "| max 100 episode reward  | 318          |\n",
            "| mean 100 episode reward | 10           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1207999      |\n",
            "------------------------------------------\n",
            " 31% 1225103/4000000 [2:46:06<5:37:56, 136.85it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.113         |\n",
            "| elapsed time            | 03:05:21      |\n",
            "| episodes                | 14200         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.005570788   |\n",
            "| loss_margin             | 0.00097496435 |\n",
            "| loss_n_td               | 0.0040016766  |\n",
            "| loss_td                 | 0.01707931    |\n",
            "| losses_all              | 0.009707723   |\n",
            "| max 100 episode reward  | 257           |\n",
            "| mean 100 episode reward | 15.6          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1225106       |\n",
            "-------------------------------------------\n",
            " 31% 1239870/4000000 [2:48:06<5:34:41, 137.44it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.113        |\n",
            "| elapsed time            | 03:07:21     |\n",
            "| episodes                | 14300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0055721872 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.002156131  |\n",
            "| loss_td                 | 0.030221457  |\n",
            "| losses_all              | 0.011876351  |\n",
            "| max 100 episode reward  | 244          |\n",
            "| mean 100 episode reward | 9.48         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1239871      |\n",
            "------------------------------------------\n",
            " 31% 1255798/4000000 [2:50:14<5:38:20, 135.18it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.112        |\n",
            "| elapsed time            | 03:09:29     |\n",
            "| episodes                | 14400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005587771  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0003180077 |\n",
            "| loss_td                 | 0.09890899   |\n",
            "| losses_all              | 0.018156046  |\n",
            "| max 100 episode reward  | 222          |\n",
            "| mean 100 episode reward | 13           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1255798      |\n",
            "------------------------------------------\n",
            " 32% 1269372/4000000 [2:52:04<5:22:54, 140.94it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.112         |\n",
            "| elapsed time            | 03:11:19      |\n",
            "| episodes                | 14500         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.005608242   |\n",
            "| loss_margin             | 0.0018815771  |\n",
            "| loss_n_td               | 0.00029971008 |\n",
            "| loss_td                 | 0.01062696    |\n",
            "| losses_all              | 0.008276423   |\n",
            "| max 100 episode reward  | 236           |\n",
            "| mean 100 episode reward | 12.1          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1269383       |\n",
            "-------------------------------------------\n",
            " 32% 1284439/4000000 [2:54:05<5:24:12, 139.60it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.111        |\n",
            "| elapsed time            | 03:13:21     |\n",
            "| episodes                | 14600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0056368564 |\n",
            "| loss_margin             | 0.0038011596 |\n",
            "| loss_n_td               | 0.018333787  |\n",
            "| loss_td                 | 0.06424126   |\n",
            "| losses_all              | 0.019782953  |\n",
            "| max 100 episode reward  | 216          |\n",
            "| mean 100 episode reward | 10.2         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1284443      |\n",
            "------------------------------------------\n",
            " 32% 1299906/4000000 [2:56:10<5:50:44, 128.30it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.111        |\n",
            "| elapsed time            | 03:15:25     |\n",
            "| episodes                | 14700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005661192  |\n",
            "| loss_margin             | 0.006649684  |\n",
            "| loss_n_td               | 0.0013271939 |\n",
            "| loss_td                 | 0.085089065  |\n",
            "| losses_all              | 0.02126061   |\n",
            "| max 100 episode reward  | 257          |\n",
            "| mean 100 episode reward | 12.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1299908      |\n",
            "------------------------------------------\n",
            " 32% 1299989/4000000 [2:56:11<8:41:54, 86.22it/s]saved checkpoint\n",
            " 33% 1314610/4000000 [2:58:08<5:35:10, 133.53it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.11         |\n",
            "| elapsed time            | 03:17:23     |\n",
            "| episodes                | 14800        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005685836  |\n",
            "| loss_margin             | 0.01856463   |\n",
            "| loss_n_td               | 0.0011118134 |\n",
            "| loss_td                 | 0.027498389  |\n",
            "| losses_all              | 0.012866278  |\n",
            "| max 100 episode reward  | 175          |\n",
            "| mean 100 episode reward | 12.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1314610      |\n",
            "------------------------------------------\n",
            " 33% 1329241/4000000 [3:00:05<5:11:04, 143.10it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.11        |\n",
            "| elapsed time            | 03:19:20    |\n",
            "| episodes                | 14900       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.005708474 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.0         |\n",
            "| loss_td                 | 0.020682914 |\n",
            "| losses_all              | 0.010182418 |\n",
            "| max 100 episode reward  | 137         |\n",
            "| mean 100 episode reward | 9.85        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1329256     |\n",
            "-----------------------------------------\n",
            " 34% 1344977/4000000 [3:02:11<5:14:58, 140.49it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.109        |\n",
            "| elapsed time            | 03:21:26     |\n",
            "| episodes                | 15000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005735885  |\n",
            "| loss_margin             | 0.0026958697 |\n",
            "| loss_n_td               | 0.0008722319 |\n",
            "| loss_td                 | 0.015767805  |\n",
            "| losses_all              | 0.009514306  |\n",
            "| max 100 episode reward  | 319          |\n",
            "| mean 100 episode reward | 10.6         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1344977      |\n",
            "------------------------------------------\n",
            " 34% 1360774/4000000 [3:04:15<5:20:26, 137.27it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.109        |\n",
            "| elapsed time            | 03:23:30     |\n",
            "| episodes                | 15100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0057720416 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.000552246  |\n",
            "| loss_td                 | 0.06167301   |\n",
            "| losses_all              | 0.013794364  |\n",
            "| max 100 episode reward  | 325          |\n",
            "| mean 100 episode reward | 13.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1360786      |\n",
            "------------------------------------------\n",
            " 34% 1375912/4000000 [3:06:16<5:07:49, 142.07it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.109         |\n",
            "| elapsed time            | 03:25:31      |\n",
            "| episodes                | 15200         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0057825996  |\n",
            "| loss_margin             | 7.9561025e-05 |\n",
            "| loss_n_td               | 0.0025726429  |\n",
            "| loss_td                 | 0.025064306   |\n",
            "| losses_all              | 0.011712419   |\n",
            "| max 100 episode reward  | 20            |\n",
            "| mean 100 episode reward | 6.54          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1375922       |\n",
            "-------------------------------------------\n",
            " 35% 1391617/4000000 [3:08:21<5:13:58, 138.46it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.108        |\n",
            "| elapsed time            | 03:27:36     |\n",
            "| episodes                | 15300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0058151367 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 4.919611e-05 |\n",
            "| loss_td                 | 0.03567265   |\n",
            "| losses_all              | 0.015172645  |\n",
            "| max 100 episode reward  | 324          |\n",
            "| mean 100 episode reward | 19.5         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1391618      |\n",
            "------------------------------------------\n",
            " 35% 1399993/4000000 [3:09:28<5:19:47, 135.50it/s]saved checkpoint\n",
            " 35% 1406453/4000000 [3:10:19<5:24:50, 133.07it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.108        |\n",
            "| elapsed time            | 03:29:34     |\n",
            "| episodes                | 15400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005842559  |\n",
            "| loss_margin             | 0.004041087  |\n",
            "| loss_n_td               | 0.0012217594 |\n",
            "| loss_td                 | 0.054674048  |\n",
            "| losses_all              | 0.014398286  |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 15.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1406455      |\n",
            "------------------------------------------\n",
            " 36% 1421666/4000000 [3:12:20<5:16:24, 135.82it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.107        |\n",
            "| elapsed time            | 03:31:35     |\n",
            "| episodes                | 15500        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.005875276  |\n",
            "| loss_margin             | 0.0013197213 |\n",
            "| loss_n_td               | 0.0010370003 |\n",
            "| loss_td                 | 0.042741403  |\n",
            "| losses_all              | 0.014041388  |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 13.7         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1421674      |\n",
            "------------------------------------------\n",
            " 36% 1438017/4000000 [3:14:28<5:15:32, 135.32it/s]saved best model\n",
            " 36% 1438077/4000000 [3:14:29<5:34:54, 127.49it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.107         |\n",
            "| elapsed time            | 03:33:44      |\n",
            "| episodes                | 15600         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0059145684  |\n",
            "| loss_margin             | 0.005520882   |\n",
            "| loss_n_td               | 0.00033705757 |\n",
            "| loss_td                 | 0.025151247   |\n",
            "| losses_all              | 0.010730929   |\n",
            "| max 100 episode reward  | 373           |\n",
            "| mean 100 episode reward | 18.9          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1438092       |\n",
            "-------------------------------------------\n",
            " 36% 1453877/4000000 [3:16:35<5:12:27, 135.81it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.106       |\n",
            "| elapsed time            | 03:35:50    |\n",
            "| episodes                | 15700       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.005961497 |\n",
            "| loss_margin             | 0.010107873 |\n",
            "| loss_n_td               | 0.018733284 |\n",
            "| loss_td                 | 0.012325296 |\n",
            "| losses_all              | 0.011557771 |\n",
            "| max 100 episode reward  | 288         |\n",
            "| mean 100 episode reward | 16.2        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1453884     |\n",
            "-----------------------------------------\n",
            " 37% 1470125/4000000 [3:18:44<5:05:37, 137.96it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.106         |\n",
            "| elapsed time            | 03:37:59      |\n",
            "| episodes                | 15800         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0060095475  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00075725396 |\n",
            "| loss_td                 | 0.045258645   |\n",
            "| losses_all              | 0.013128487   |\n",
            "| max 100 episode reward  | 222           |\n",
            "| mean 100 episode reward | 11            |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1470125       |\n",
            "-------------------------------------------\n",
            " 37% 1485518/4000000 [3:20:47<5:06:15, 136.84it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.106        |\n",
            "| elapsed time            | 03:40:02     |\n",
            "| episodes                | 15900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0060588317 |\n",
            "| loss_margin             | 0.010730362  |\n",
            "| loss_n_td               | 0.005134371  |\n",
            "| loss_td                 | 0.037417457  |\n",
            "| losses_all              | 0.013761228  |\n",
            "| max 100 episode reward  | 255          |\n",
            "| mean 100 episode reward | 14           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1485520      |\n",
            "------------------------------------------\n",
            " 38% 1500000/4000000 [3:22:44<18:04:32, 38.42it/s]saved checkpoint\n",
            " 38% 1501733/4000000 [3:22:58<5:13:02, 133.01it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.105        |\n",
            "| elapsed time            | 03:42:13     |\n",
            "| episodes                | 16000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.006108076  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0006940528 |\n",
            "| loss_td                 | 0.032311454  |\n",
            "| losses_all              | 0.013991136  |\n",
            "| max 100 episode reward  | 339          |\n",
            "| mean 100 episode reward | 17.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1501733      |\n",
            "------------------------------------------\n",
            " 38% 1517690/4000000 [3:25:05<4:59:04, 138.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.105        |\n",
            "| elapsed time            | 03:44:20     |\n",
            "| episodes                | 16100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0061575375 |\n",
            "| loss_margin             | 0.0018573739 |\n",
            "| loss_n_td               | 0.0010168541 |\n",
            "| loss_td                 | 0.051186576  |\n",
            "| losses_all              | 0.013819202  |\n",
            "| max 100 episode reward  | 318          |\n",
            "| mean 100 episode reward | 17.5         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1517696      |\n",
            "------------------------------------------\n",
            " 38% 1532633/4000000 [3:27:06<5:21:03, 128.08it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.104        |\n",
            "| elapsed time            | 03:46:21     |\n",
            "| episodes                | 16200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0061979196 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.013464009  |\n",
            "| loss_td                 | 0.05118917   |\n",
            "| losses_all              | 0.013960592  |\n",
            "| max 100 episode reward  | 261          |\n",
            "| mean 100 episode reward | 15.2         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1532636      |\n",
            "------------------------------------------\n",
            " 39% 1547441/4000000 [3:29:06<4:50:47, 140.56it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.104        |\n",
            "| elapsed time            | 03:48:21     |\n",
            "| episodes                | 16300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.006257434  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0013769079 |\n",
            "| loss_td                 | 0.019738141  |\n",
            "| losses_all              | 0.011324232  |\n",
            "| max 100 episode reward  | 261          |\n",
            "| mean 100 episode reward | 15.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1547441      |\n",
            "------------------------------------------\n",
            " 39% 1561125/4000000 [3:30:57<5:00:47, 135.13it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.104        |\n",
            "| elapsed time            | 03:50:12     |\n",
            "| episodes                | 16400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.006299066  |\n",
            "| loss_margin             | 0.003923595  |\n",
            "| loss_n_td               | 0.010250147  |\n",
            "| loss_td                 | 0.032885965  |\n",
            "| losses_all              | 0.0132769905 |\n",
            "| max 100 episode reward  | 139          |\n",
            "| mean 100 episode reward | 6.33         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1561135      |\n",
            "------------------------------------------\n",
            " 39% 1577893/4000000 [3:33:11<5:01:51, 133.73it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.103        |\n",
            "| elapsed time            | 03:52:26     |\n",
            "| episodes                | 16500        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.006347787  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0021258702 |\n",
            "| loss_td                 | 0.030137924  |\n",
            "| losses_all              | 0.0111342    |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 15.9         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1577906      |\n",
            "------------------------------------------\n",
            " 40% 1593817/4000000 [3:35:17<4:44:33, 140.93it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.103        |\n",
            "| elapsed time            | 03:54:32     |\n",
            "| episodes                | 16600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0063894694 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0010335976 |\n",
            "| loss_td                 | 0.038254924  |\n",
            "| losses_all              | 0.012730251  |\n",
            "| max 100 episode reward  | 222          |\n",
            "| mean 100 episode reward | 14.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1593828      |\n",
            "------------------------------------------\n",
            " 40% 1599992/4000000 [3:36:07<11:27:02, 58.22it/s]saved checkpoint\n",
            " 40% 1609522/4000000 [3:37:23<4:40:13, 142.17it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.102         |\n",
            "| elapsed time            | 03:56:38      |\n",
            "| episodes                | 16700         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.006442      |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00086374837 |\n",
            "| loss_td                 | 0.021112878   |\n",
            "| losses_all              | 0.010431087   |\n",
            "| max 100 episode reward  | 366           |\n",
            "| mean 100 episode reward | 13.2          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1609534       |\n",
            "-------------------------------------------\n",
            " 41% 1625357/4000000 [3:39:31<4:57:58, 132.82it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.102        |\n",
            "| elapsed time            | 03:58:46     |\n",
            "| episodes                | 16800        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0065013235 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0004146571 |\n",
            "| loss_td                 | 0.025022522  |\n",
            "| losses_all              | 0.011142377  |\n",
            "| max 100 episode reward  | 33           |\n",
            "| mean 100 episode reward | 7.55         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1625359      |\n",
            "------------------------------------------\n",
            " 41% 1639768/4000000 [3:41:27<4:52:07, 134.66it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.102         |\n",
            "| elapsed time            | 04:00:42      |\n",
            "| episodes                | 16900         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0065397625  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00036327355 |\n",
            "| loss_td                 | 0.02176506    |\n",
            "| losses_all              | 0.010911584   |\n",
            "| max 100 episode reward  | 232           |\n",
            "| mean 100 episode reward | 8.02          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1639779       |\n",
            "-------------------------------------------\n",
            " 41% 1656271/4000000 [3:43:40<4:48:22, 135.46it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 04:02:56     |\n",
            "| episodes                | 17000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0065808636 |\n",
            "| loss_margin             | 0.008444864  |\n",
            "| loss_n_td               | 7.818317e-05 |\n",
            "| loss_td                 | 0.069989435  |\n",
            "| losses_all              | 0.0172957    |\n",
            "| max 100 episode reward  | 182          |\n",
            "| mean 100 episode reward | 13.7         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1656281      |\n",
            "------------------------------------------\n",
            " 42% 1672148/4000000 [3:45:49<4:34:55, 141.12it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 04:05:04     |\n",
            "| episodes                | 17100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0065965354 |\n",
            "| loss_margin             | 0.0023563858 |\n",
            "| loss_n_td               | 0.002078403  |\n",
            "| loss_td                 | 0.054112796  |\n",
            "| losses_all              | 0.016498752  |\n",
            "| max 100 episode reward  | 261          |\n",
            "| mean 100 episode reward | 17.5         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1672155      |\n",
            "------------------------------------------\n",
            " 42% 1687335/4000000 [3:47:54<5:04:53, 126.42it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.101        |\n",
            "| elapsed time            | 04:07:09     |\n",
            "| episodes                | 17200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0066196397 |\n",
            "| loss_margin             | 0.0047042407 |\n",
            "| loss_n_td               | 2.391729e-05 |\n",
            "| loss_td                 | 0.04693781   |\n",
            "| losses_all              | 0.015402548  |\n",
            "| max 100 episode reward  | 325          |\n",
            "| mean 100 episode reward | 10.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1687338      |\n",
            "------------------------------------------\n",
            " 42% 1699985/4000000 [3:49:38<4:53:36, 130.56it/s]saved checkpoint\n",
            " 43% 1702526/4000000 [3:49:58<4:45:49, 133.97it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.1          |\n",
            "| elapsed time            | 04:09:13     |\n",
            "| episodes                | 17300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.00665874   |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0003386673 |\n",
            "| loss_td                 | 0.028781231  |\n",
            "| losses_all              | 0.012063081  |\n",
            "| max 100 episode reward  | 276          |\n",
            "| mean 100 episode reward | 14.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1702533      |\n",
            "------------------------------------------\n",
            " 43% 1718760/4000000 [3:52:11<4:32:14, 139.66it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.1           |\n",
            "| elapsed time            | 04:11:26      |\n",
            "| episodes                | 17400         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0067010336  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00054310414 |\n",
            "| loss_td                 | 0.08733432    |\n",
            "| losses_all              | 0.018978126   |\n",
            "| max 100 episode reward  | 245           |\n",
            "| mean 100 episode reward | 13.2          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1718762       |\n",
            "-------------------------------------------\n",
            " 43% 1734414/4000000 [3:54:19<4:40:36, 134.56it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0998       |\n",
            "| elapsed time            | 04:13:34     |\n",
            "| episodes                | 17500        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0067488463 |\n",
            "| loss_margin             | 0.0029865503 |\n",
            "| loss_n_td               | 0.0016627226 |\n",
            "| loss_td                 | 0.12840173   |\n",
            "| losses_all              | 0.02364123   |\n",
            "| max 100 episode reward  | 291          |\n",
            "| mean 100 episode reward | 15           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1734420      |\n",
            "------------------------------------------\n",
            " 44% 1751119/4000000 [3:56:35<4:37:01, 135.30it/s]--------------------------------------------\n",
            "| % time spent exploring  | 1              |\n",
            "| demo sample rate        | 0.0995         |\n",
            "| elapsed time            | 04:15:51       |\n",
            "| episodes                | 17600          |\n",
            "| epsilon                 | 0.01           |\n",
            "| loss_l2                 | 0.0068004467   |\n",
            "| loss_margin             | 1.41225755e-05 |\n",
            "| loss_n_td               | 0.017260265    |\n",
            "| loss_td                 | 0.063587956    |\n",
            "| losses_all              | 0.018425398    |\n",
            "| max 100 episode reward  | 319            |\n",
            "| mean 100 episode reward | 18.1           |\n",
            "| min 100 episode reward  | 0              |\n",
            "| pre_train               | False          |\n",
            "| steps                   | 1751128        |\n",
            "--------------------------------------------\n",
            " 44% 1765417/4000000 [3:58:34<4:42:27, 131.86it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0992        |\n",
            "| elapsed time            | 04:17:49      |\n",
            "| episodes                | 17700         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.006840998   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00096948975 |\n",
            "| loss_td                 | 0.102039546   |\n",
            "| losses_all              | 0.02260962    |\n",
            "| max 100 episode reward  | 333           |\n",
            "| mean 100 episode reward | 14.1          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1765421       |\n",
            "-------------------------------------------\n",
            " 45% 1782693/4000000 [4:00:53<4:37:06, 133.36it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0988        |\n",
            "| elapsed time            | 04:20:08      |\n",
            "| episodes                | 17800         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0068748593  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00018785504 |\n",
            "| loss_td                 | 0.037100494   |\n",
            "| losses_all              | 0.012558237   |\n",
            "| max 100 episode reward  | 301           |\n",
            "| mean 100 episode reward | 28.8          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1782701       |\n",
            "-------------------------------------------\n",
            " 45% 1796997/4000000 [4:02:52<4:42:24, 130.01it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0986       |\n",
            "| elapsed time            | 04:22:07     |\n",
            "| episodes                | 17900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0068978076 |\n",
            "| loss_margin             | 0.0010189414 |\n",
            "| loss_n_td               | 0.0021736715 |\n",
            "| loss_td                 | 0.036188766  |\n",
            "| losses_all              | 0.014902914  |\n",
            "| max 100 episode reward  | 265          |\n",
            "| mean 100 episode reward | 13.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1796999      |\n",
            "------------------------------------------\n",
            " 45% 1799996/4000000 [4:03:17<4:40:34, 130.69it/s]saved checkpoint\n",
            " 45% 1810536/4000000 [4:04:45<4:32:20, 133.99it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0983       |\n",
            "| elapsed time            | 04:24:01     |\n",
            "| episodes                | 18000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0069263633 |\n",
            "| loss_margin             | 0.0018794611 |\n",
            "| loss_n_td               | 0.0023574664 |\n",
            "| loss_td                 | 0.14322753   |\n",
            "| losses_all              | 0.025305806  |\n",
            "| max 100 episode reward  | 269          |\n",
            "| mean 100 episode reward | 11.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1810542      |\n",
            "------------------------------------------\n",
            " 46% 1824169/4000000 [4:06:39<4:25:03, 136.81it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0981        |\n",
            "| elapsed time            | 04:25:54      |\n",
            "| episodes                | 18100         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.006955204   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00023333111 |\n",
            "| loss_td                 | 0.038223192   |\n",
            "| losses_all              | 0.012877988   |\n",
            "| max 100 episode reward  | 261           |\n",
            "| mean 100 episode reward | 7.68          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1824178       |\n",
            "-------------------------------------------\n",
            " 46% 1840439/4000000 [4:08:51<4:34:51, 130.95it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0978        |\n",
            "| elapsed time            | 04:28:07      |\n",
            "| episodes                | 18200         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.006977241   |\n",
            "| loss_margin             | 0.00066009164 |\n",
            "| loss_n_td               | 0.0017833961  |\n",
            "| loss_td                 | 0.08124106    |\n",
            "| losses_all              | 0.01878084    |\n",
            "| max 100 episode reward  | 288           |\n",
            "| mean 100 episode reward | 24.2          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1840448       |\n",
            "-------------------------------------------\n",
            " 46% 1856641/4000000 [4:11:04<4:26:26, 134.07it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0975       |\n",
            "| elapsed time            | 04:30:19     |\n",
            "| episodes                | 18300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0070008724 |\n",
            "| loss_margin             | 0.001379665  |\n",
            "| loss_n_td               | 0.0025797244 |\n",
            "| loss_td                 | 0.051259585  |\n",
            "| losses_all              | 0.014677109  |\n",
            "| max 100 episode reward  | 222          |\n",
            "| mean 100 episode reward | 14.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1856655      |\n",
            "------------------------------------------\n",
            " 47% 1870524/4000000 [4:12:59<4:13:09, 140.20it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0972        |\n",
            "| elapsed time            | 04:32:14      |\n",
            "| episodes                | 18400         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007018635   |\n",
            "| loss_margin             | 0.00024284096 |\n",
            "| loss_n_td               | 0.014347603   |\n",
            "| loss_td                 | 0.08554001    |\n",
            "| losses_all              | 0.019247785   |\n",
            "| max 100 episode reward  | 361           |\n",
            "| mean 100 episode reward | 13.9          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1870526       |\n",
            "-------------------------------------------\n",
            " 47% 1885251/4000000 [4:15:01<4:26:33, 132.23it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0969        |\n",
            "| elapsed time            | 04:34:16      |\n",
            "| episodes                | 18500         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007059262   |\n",
            "| loss_margin             | 0.003132902   |\n",
            "| loss_n_td               | 0.00012722376 |\n",
            "| loss_td                 | 0.03427371    |\n",
            "| losses_all              | 0.014090396   |\n",
            "| max 100 episode reward  | 273           |\n",
            "| mean 100 episode reward | 14.2          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1885264       |\n",
            "-------------------------------------------\n",
            " 47% 1899968/4000000 [4:17:02<4:27:18, 130.94it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0967       |\n",
            "| elapsed time            | 04:36:18     |\n",
            "| episodes                | 18600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007094228  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0007050307 |\n",
            "| loss_td                 | 0.20577796   |\n",
            "| losses_all              | 0.025938833  |\n",
            "| max 100 episode reward  | 360          |\n",
            "| mean 100 episode reward | 19.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1899979      |\n",
            "------------------------------------------\n",
            " 47% 1899994/4000000 [4:17:04<13:02:08, 44.75it/s]saved checkpoint\n",
            " 48% 1915668/4000000 [4:19:12<4:16:28, 135.45it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0964        |\n",
            "| elapsed time            | 04:38:27      |\n",
            "| episodes                | 18700         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007119831   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00087558903 |\n",
            "| loss_td                 | 0.08317118    |\n",
            "| losses_all              | 0.0186416     |\n",
            "| max 100 episode reward  | 369           |\n",
            "| mean 100 episode reward | 19.6          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 1915678       |\n",
            "-------------------------------------------\n",
            " 48% 1932629/4000000 [4:21:29<4:20:05, 132.48it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0961       |\n",
            "| elapsed time            | 04:40:44     |\n",
            "| episodes                | 18800        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0071542296 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0002618458 |\n",
            "| loss_td                 | 0.04913338   |\n",
            "| losses_all              | 0.015023926  |\n",
            "| max 100 episode reward  | 342          |\n",
            "| mean 100 episode reward | 20.2         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1932630      |\n",
            "------------------------------------------\n",
            " 49% 1947277/4000000 [4:23:30<4:26:10, 128.53it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0959      |\n",
            "| elapsed time            | 04:42:45    |\n",
            "| episodes                | 18900       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.007172429 |\n",
            "| loss_margin             | 0.002333343 |\n",
            "| loss_n_td               | 0.011750989 |\n",
            "| loss_td                 | 0.056400806 |\n",
            "| losses_all              | 0.016007315 |\n",
            "| max 100 episode reward  | 318         |\n",
            "| mean 100 episode reward | 12.4        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1947277     |\n",
            "-----------------------------------------\n",
            " 49% 1963344/4000000 [4:25:41<4:01:47, 140.38it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0956       |\n",
            "| elapsed time            | 04:44:56     |\n",
            "| episodes                | 19000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007183447  |\n",
            "| loss_margin             | 0.004344117  |\n",
            "| loss_n_td               | 0.0034439652 |\n",
            "| loss_td                 | 0.07664173   |\n",
            "| losses_all              | 0.017807364  |\n",
            "| max 100 episode reward  | 318          |\n",
            "| mean 100 episode reward | 21.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1963347      |\n",
            "------------------------------------------\n",
            " 49% 1978265/4000000 [4:27:44<4:08:49, 135.42it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0954      |\n",
            "| elapsed time            | 04:46:59    |\n",
            "| episodes                | 19100       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.007221647 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.02560215  |\n",
            "| loss_td                 | 0.05580432  |\n",
            "| losses_all              | 0.017477255 |\n",
            "| max 100 episode reward  | 222         |\n",
            "| mean 100 episode reward | 13.2        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 1978270     |\n",
            "-----------------------------------------\n",
            " 50% 1991928/4000000 [4:29:38<4:06:41, 135.67it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0952       |\n",
            "| elapsed time            | 04:48:53     |\n",
            "| episodes                | 19200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0072463034 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0014674221 |\n",
            "| loss_td                 | 0.0755723    |\n",
            "| losses_all              | 0.017309967  |\n",
            "| max 100 episode reward  | 239          |\n",
            "| mean 100 episode reward | 16.5         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 1991933      |\n",
            "------------------------------------------\n",
            " 50% 1999995/4000000 [4:30:45<4:23:08, 126.68it/s]saved checkpoint\n",
            " 50% 2005524/4000000 [4:31:29<4:03:54, 136.29it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.095        |\n",
            "| elapsed time            | 04:50:45     |\n",
            "| episodes                | 19300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007277536  |\n",
            "| loss_margin             | 0.0008575432 |\n",
            "| loss_n_td               | 0.0016422184 |\n",
            "| loss_td                 | 0.05147785   |\n",
            "| losses_all              | 0.016744478  |\n",
            "| max 100 episode reward  | 224          |\n",
            "| mean 100 episode reward | 7.46         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2005536      |\n",
            "------------------------------------------\n",
            " 51% 2022520/4000000 [4:33:46<4:03:40, 135.26it/s]saved best model\n",
            " 51% 2022788/4000000 [4:33:49<3:51:20, 142.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0947       |\n",
            "| elapsed time            | 04:53:04     |\n",
            "| episodes                | 19400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0073047825 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.018480306  |\n",
            "| loss_td                 | 0.07680672   |\n",
            "| losses_all              | 0.018117087  |\n",
            "| max 100 episode reward  | 374          |\n",
            "| mean 100 episode reward | 20.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2022794      |\n",
            "------------------------------------------\n",
            " 51% 2040649/4000000 [4:36:12<3:53:29, 139.86it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0944        |\n",
            "| elapsed time            | 04:55:27      |\n",
            "| episodes                | 19500         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0073458226  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00033588108 |\n",
            "| loss_td                 | 0.054461077   |\n",
            "| losses_all              | 0.01650494    |\n",
            "| max 100 episode reward  | 299           |\n",
            "| mean 100 episode reward | 20.4          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2040654       |\n",
            "-------------------------------------------\n",
            " 51% 2055607/4000000 [4:38:14<3:54:21, 138.27it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0942       |\n",
            "| elapsed time            | 04:57:29     |\n",
            "| episodes                | 19600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007387224  |\n",
            "| loss_margin             | 0.0010886341 |\n",
            "| loss_n_td               | 0.001678435  |\n",
            "| loss_td                 | 0.114210784  |\n",
            "| losses_all              | 0.018745502  |\n",
            "| max 100 episode reward  | 351          |\n",
            "| mean 100 episode reward | 13.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2055612      |\n",
            "------------------------------------------\n",
            " 52% 2071417/4000000 [4:40:23<3:48:29, 140.67it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0939       |\n",
            "| elapsed time            | 04:59:38     |\n",
            "| episodes                | 19700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.00740546   |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 5.731749e-05 |\n",
            "| loss_td                 | 0.058454204  |\n",
            "| losses_all              | 0.015000215  |\n",
            "| max 100 episode reward  | 222          |\n",
            "| mean 100 episode reward | 13           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2071421      |\n",
            "------------------------------------------\n",
            " 52% 2086389/4000000 [4:42:24<3:43:12, 142.89it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0937       |\n",
            "| elapsed time            | 05:01:39     |\n",
            "| episodes                | 19800        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0074395626 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.010444919  |\n",
            "| loss_td                 | 0.094578505  |\n",
            "| losses_all              | 0.020043124  |\n",
            "| max 100 episode reward  | 146          |\n",
            "| mean 100 episode reward | 9.08         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2086398      |\n",
            "------------------------------------------\n",
            " 52% 2099987/4000000 [4:44:14<4:01:02, 131.38it/s]saved checkpoint\n",
            " 53% 2100882/4000000 [4:44:21<3:56:41, 133.73it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0935       |\n",
            "| elapsed time            | 05:03:36     |\n",
            "| episodes                | 19900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0074722674 |\n",
            "| loss_margin             | 0.0073272847 |\n",
            "| loss_n_td               | 0.0008258343 |\n",
            "| loss_td                 | 0.04635273   |\n",
            "| losses_all              | 0.014581045  |\n",
            "| max 100 episode reward  | 261          |\n",
            "| mean 100 episode reward | 12.5         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2100885      |\n",
            "------------------------------------------\n",
            " 53% 2114077/4000000 [4:46:09<3:45:57, 139.11it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0933       |\n",
            "| elapsed time            | 05:05:24     |\n",
            "| episodes                | 20000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0074984576 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0037267315 |\n",
            "| loss_td                 | 0.096772626  |\n",
            "| losses_all              | 0.018581748  |\n",
            "| max 100 episode reward  | 223          |\n",
            "| mean 100 episode reward | 8.2          |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2114088      |\n",
            "------------------------------------------\n",
            " 53% 2128509/4000000 [4:48:05<3:43:58, 139.27it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0931       |\n",
            "| elapsed time            | 05:07:20     |\n",
            "| episodes                | 20100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007528199  |\n",
            "| loss_margin             | 0.004667662  |\n",
            "| loss_n_td               | 0.0002644513 |\n",
            "| loss_td                 | 0.046383552  |\n",
            "| losses_all              | 0.013897957  |\n",
            "| max 100 episode reward  | 137          |\n",
            "| mean 100 episode reward | 10.7         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2128517      |\n",
            "------------------------------------------\n",
            " 54% 2142588/4000000 [4:49:58<3:52:17, 133.27it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0929       |\n",
            "| elapsed time            | 05:09:13     |\n",
            "| episodes                | 20200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0075405114 |\n",
            "| loss_margin             | 0.011089966  |\n",
            "| loss_n_td               | 0.0014194475 |\n",
            "| loss_td                 | 0.07461108   |\n",
            "| losses_all              | 0.02060701   |\n",
            "| max 100 episode reward  | 298          |\n",
            "| mean 100 episode reward | 12.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2142598      |\n",
            "------------------------------------------\n",
            " 54% 2158461/4000000 [4:52:04<3:40:02, 139.48it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0927        |\n",
            "| elapsed time            | 05:11:19      |\n",
            "| episodes                | 20300         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0075775622  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00023295588 |\n",
            "| loss_td                 | 0.08000628    |\n",
            "| losses_all              | 0.01570537    |\n",
            "| max 100 episode reward  | 222           |\n",
            "| mean 100 episode reward | 11.7          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2158473       |\n",
            "-------------------------------------------\n",
            " 54% 2173509/4000000 [4:54:04<3:49:49, 132.45it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0925        |\n",
            "| elapsed time            | 05:13:20      |\n",
            "| episodes                | 20400         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0075994027  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00051771937 |\n",
            "| loss_td                 | 0.1866969     |\n",
            "| losses_all              | 0.02152857    |\n",
            "| max 100 episode reward  | 253           |\n",
            "| mean 100 episode reward | 15.4          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2173521       |\n",
            "-------------------------------------------\n",
            " 55% 2188369/4000000 [4:56:04<3:37:33, 138.79it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0923        |\n",
            "| elapsed time            | 05:15:19      |\n",
            "| episodes                | 20500         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.00761604    |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 3.6227877e-06 |\n",
            "| loss_td                 | 0.08255346    |\n",
            "| losses_all              | 0.018821113   |\n",
            "| max 100 episode reward  | 234           |\n",
            "| mean 100 episode reward | 15.6          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2188369       |\n",
            "-------------------------------------------\n",
            " 55% 2199992/4000000 [4:57:40<4:41:49, 106.45it/s]saved checkpoint\n",
            " 55% 2201725/4000000 [4:57:53<3:46:07, 132.54it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0921       |\n",
            "| elapsed time            | 05:17:08     |\n",
            "| episodes                | 20600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0076242373 |\n",
            "| loss_margin             | 0.018771376  |\n",
            "| loss_n_td               | 0.0005795114 |\n",
            "| loss_td                 | 0.2797081    |\n",
            "| losses_all              | 0.028227953  |\n",
            "| max 100 episode reward  | 232          |\n",
            "| mean 100 episode reward | 8.74         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2201733      |\n",
            "------------------------------------------\n",
            " 55% 2215133/4000000 [4:59:42<3:34:29, 138.69it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0919       |\n",
            "| elapsed time            | 05:18:57     |\n",
            "| episodes                | 20700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0076500205 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.00293354   |\n",
            "| loss_td                 | 0.1456733    |\n",
            "| losses_all              | 0.025067296  |\n",
            "| max 100 episode reward  | 322          |\n",
            "| mean 100 episode reward | 7.92         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2215133      |\n",
            "------------------------------------------\n",
            " 56% 2229137/4000000 [5:01:35<3:35:07, 137.19it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0917        |\n",
            "| elapsed time            | 05:20:50      |\n",
            "| episodes                | 20800         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0076711504  |\n",
            "| loss_margin             | 0.00067541376 |\n",
            "| loss_n_td               | 0.010047385   |\n",
            "| loss_td                 | 0.05635948    |\n",
            "| losses_all              | 0.015453627   |\n",
            "| max 100 episode reward  | 316           |\n",
            "| mean 100 episode reward | 8.92          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2229143       |\n",
            "-------------------------------------------\n",
            " 56% 2244177/4000000 [5:03:35<3:27:51, 140.78it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0915       |\n",
            "| elapsed time            | 05:22:51     |\n",
            "| episodes                | 20900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007693342  |\n",
            "| loss_margin             | 0.0029568924 |\n",
            "| loss_n_td               | 0.0034985323 |\n",
            "| loss_td                 | 0.09427868   |\n",
            "| losses_all              | 0.020274844  |\n",
            "| max 100 episode reward  | 329          |\n",
            "| mean 100 episode reward | 10.9         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2244178      |\n",
            "------------------------------------------\n",
            " 56% 2258928/4000000 [5:05:33<3:36:31, 134.01it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0914       |\n",
            "| elapsed time            | 05:24:49     |\n",
            "| episodes                | 21000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007711336  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0046140957 |\n",
            "| loss_td                 | 0.06767448   |\n",
            "| losses_all              | 0.018033553  |\n",
            "| max 100 episode reward  | 236          |\n",
            "| mean 100 episode reward | 12.7         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2258932      |\n",
            "------------------------------------------\n",
            " 57% 2274921/4000000 [5:07:40<3:22:49, 141.75it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0912       |\n",
            "| elapsed time            | 05:26:55     |\n",
            "| episodes                | 21100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007722957  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0003393374 |\n",
            "| loss_td                 | 0.12038481   |\n",
            "| losses_all              | 0.02177645   |\n",
            "| max 100 episode reward  | 336          |\n",
            "| mean 100 episode reward | 22.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2274934      |\n",
            "------------------------------------------\n",
            " 57% 2289413/4000000 [5:09:36<3:22:29, 140.79it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.091       |\n",
            "| elapsed time            | 05:28:51    |\n",
            "| episodes                | 21200       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.007744008 |\n",
            "| loss_margin             | 0.011978855 |\n",
            "| loss_n_td               | 0.010767733 |\n",
            "| loss_td                 | 0.07487895  |\n",
            "| losses_all              | 0.021018993 |\n",
            "| max 100 episode reward  | 133         |\n",
            "| mean 100 episode reward | 7.69        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 2289420     |\n",
            "-----------------------------------------\n",
            " 57% 2299993/4000000 [5:11:00<3:35:25, 131.53it/s]saved checkpoint\n",
            " 58% 2304834/4000000 [5:11:38<3:24:21, 138.26it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0908       |\n",
            "| elapsed time            | 05:30:53     |\n",
            "| episodes                | 21300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0077707027 |\n",
            "| loss_margin             | 0.0001699403 |\n",
            "| loss_n_td               | 0.018939178  |\n",
            "| loss_td                 | 0.16183165   |\n",
            "| losses_all              | 0.025229286  |\n",
            "| max 100 episode reward  | 244          |\n",
            "| mean 100 episode reward | 12.6         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2304834      |\n",
            "------------------------------------------\n",
            " 58% 2319253/4000000 [5:13:34<3:29:51, 133.48it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0906       |\n",
            "| elapsed time            | 05:32:49     |\n",
            "| episodes                | 21400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007782427  |\n",
            "| loss_margin             | 0.0038522016 |\n",
            "| loss_n_td               | 0.010852004  |\n",
            "| loss_td                 | 0.07438563   |\n",
            "| losses_all              | 0.019363193  |\n",
            "| max 100 episode reward  | 236          |\n",
            "| mean 100 episode reward | 15.2         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2319253      |\n",
            "------------------------------------------\n",
            " 58% 2336429/4000000 [5:15:53<3:42:21, 124.69it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0904        |\n",
            "| elapsed time            | 05:35:08      |\n",
            "| episodes                | 21500         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0078080883  |\n",
            "| loss_margin             | 0.011690222   |\n",
            "| loss_n_td               | 0.00015073088 |\n",
            "| loss_td                 | 0.050285712   |\n",
            "| losses_all              | 0.015250644   |\n",
            "| max 100 episode reward  | 343           |\n",
            "| mean 100 episode reward | 17.4          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2336432       |\n",
            "-------------------------------------------\n",
            " 59% 2351524/4000000 [5:17:57<3:27:42, 132.28it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0902        |\n",
            "| elapsed time            | 05:37:12      |\n",
            "| episodes                | 21600         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007825802   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00074446807 |\n",
            "| loss_td                 | 0.2029952     |\n",
            "| losses_all              | 0.028421886   |\n",
            "| max 100 episode reward  | 285           |\n",
            "| mean 100 episode reward | 13.5          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2351533       |\n",
            "-------------------------------------------\n",
            " 59% 2365829/4000000 [5:19:54<3:31:04, 129.03it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0901      |\n",
            "| elapsed time            | 05:39:09    |\n",
            "| episodes                | 21700       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.007848089 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.01891308  |\n",
            "| loss_td                 | 0.10625871  |\n",
            "| losses_all              | 0.028225783 |\n",
            "| max 100 episode reward  | 143         |\n",
            "| mean 100 episode reward | 7.64        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 2365838     |\n",
            "-----------------------------------------\n",
            " 59% 2379617/4000000 [5:21:47<3:28:00, 129.83it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0899      |\n",
            "| elapsed time            | 05:41:02    |\n",
            "| episodes                | 21800       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.007871368 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 2.75111e-06 |\n",
            "| loss_td                 | 0.12995705  |\n",
            "| losses_all              | 0.023479063 |\n",
            "| max 100 episode reward  | 366         |\n",
            "| mean 100 episode reward | 18.8        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 2379624     |\n",
            "-----------------------------------------\n",
            " 60% 2393899/4000000 [5:23:45<3:24:38, 130.81it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0898       |\n",
            "| elapsed time            | 05:43:00     |\n",
            "| episodes                | 21900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007886499  |\n",
            "| loss_margin             | 0.0013180953 |\n",
            "| loss_n_td               | 0.0014682483 |\n",
            "| loss_td                 | 0.052270345  |\n",
            "| losses_all              | 0.014654852  |\n",
            "| max 100 episode reward  | 236          |\n",
            "| mean 100 episode reward | 13.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2393900      |\n",
            "------------------------------------------\n",
            " 60% 2399993/4000000 [5:24:36<3:41:12, 120.55it/s]saved checkpoint\n",
            " 60% 2409736/4000000 [5:25:53<3:15:13, 135.76it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0896        |\n",
            "| elapsed time            | 05:45:08      |\n",
            "| episodes                | 22000         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0078969905  |\n",
            "| loss_margin             | 0.00023682415 |\n",
            "| loss_n_td               | 0.00031188483 |\n",
            "| loss_td                 | 0.09636137    |\n",
            "| losses_all              | 0.019152578   |\n",
            "| max 100 episode reward  | 324           |\n",
            "| mean 100 episode reward | 24.2          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2409745       |\n",
            "-------------------------------------------\n",
            " 61% 2424889/4000000 [5:27:54<3:16:19, 133.71it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0894        |\n",
            "| elapsed time            | 05:47:09      |\n",
            "| episodes                | 22100         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007905806   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00024219166 |\n",
            "| loss_td                 | 0.26797885    |\n",
            "| losses_all              | 0.04077571    |\n",
            "| max 100 episode reward  | 327           |\n",
            "| mean 100 episode reward | 20.2          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2424894       |\n",
            "-------------------------------------------\n",
            " 61% 2439865/4000000 [5:29:54<3:07:19, 138.81it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0893       |\n",
            "| elapsed time            | 05:49:09     |\n",
            "| episodes                | 22200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007909267  |\n",
            "| loss_margin             | 0.0010335632 |\n",
            "| loss_n_td               | 0.0002730355 |\n",
            "| loss_td                 | 0.05916244   |\n",
            "| losses_all              | 0.017330188  |\n",
            "| max 100 episode reward  | 269          |\n",
            "| mean 100 episode reward | 17           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2439869      |\n",
            "------------------------------------------\n",
            " 61% 2455861/4000000 [5:32:02<2:58:38, 144.07it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0891       |\n",
            "| elapsed time            | 05:51:17     |\n",
            "| episodes                | 22300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007935165  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0013798944 |\n",
            "| loss_td                 | 0.1265004    |\n",
            "| losses_all              | 0.020245519  |\n",
            "| max 100 episode reward  | 366          |\n",
            "| mean 100 episode reward | 23.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2455876      |\n",
            "------------------------------------------\n",
            " 62% 2471793/4000000 [5:34:09<3:11:45, 132.82it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0889       |\n",
            "| elapsed time            | 05:53:24     |\n",
            "| episodes                | 22400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007946338  |\n",
            "| loss_margin             | 0.006741047  |\n",
            "| loss_n_td               | 0.0012049021 |\n",
            "| loss_td                 | 0.07579349   |\n",
            "| losses_all              | 0.017268006  |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 27.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2471795      |\n",
            "------------------------------------------\n",
            " 62% 2477447/4000000 [5:34:53<2:58:00, 142.55it/s]saved best model\n",
            " 62% 2488373/4000000 [5:36:20<3:11:47, 131.36it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0887        |\n",
            "| elapsed time            | 05:55:36      |\n",
            "| episodes                | 22500         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007948751   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00022816446 |\n",
            "| loss_td                 | 0.06111107    |\n",
            "| losses_all              | 0.014656105   |\n",
            "| max 100 episode reward  | 378           |\n",
            "| mean 100 episode reward | 15.9          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2488383       |\n",
            "-------------------------------------------\n",
            " 62% 2499993/4000000 [5:37:54<2:55:46, 142.22it/s]saved checkpoint\n",
            " 63% 2503908/4000000 [5:38:27<3:05:42, 134.27it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0886        |\n",
            "| elapsed time            | 05:57:42      |\n",
            "| episodes                | 22600         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007953194   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00079471746 |\n",
            "| loss_td                 | 0.09280917    |\n",
            "| losses_all              | 0.019426025   |\n",
            "| max 100 episode reward  | 325           |\n",
            "| mean 100 episode reward | 25.7          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2503916       |\n",
            "-------------------------------------------\n",
            " 63% 2520038/4000000 [5:40:36<2:59:58, 137.05it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0884       |\n",
            "| elapsed time            | 05:59:51     |\n",
            "| episodes                | 22700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007974314  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 6.682395e-05 |\n",
            "| loss_td                 | 0.24377275   |\n",
            "| losses_all              | 0.036205918  |\n",
            "| max 100 episode reward  | 289          |\n",
            "| mean 100 episode reward | 18           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2520044      |\n",
            "------------------------------------------\n",
            " 63% 2535619/4000000 [5:42:43<3:00:16, 135.38it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0883        |\n",
            "| elapsed time            | 06:01:58      |\n",
            "| episodes                | 22800         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0079995375  |\n",
            "| loss_margin             | 0.012436073   |\n",
            "| loss_n_td               | 0.00010771962 |\n",
            "| loss_td                 | 0.098923795   |\n",
            "| losses_all              | 0.020304225   |\n",
            "| max 100 episode reward  | 329           |\n",
            "| mean 100 episode reward | 24.4          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2535623       |\n",
            "-------------------------------------------\n",
            " 64% 2550494/4000000 [5:44:46<3:03:11, 131.87it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0881       |\n",
            "| elapsed time            | 06:04:01     |\n",
            "| episodes                | 22900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0080177905 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0019518465 |\n",
            "| loss_td                 | 0.17608753   |\n",
            "| losses_all              | 0.026236381  |\n",
            "| max 100 episode reward  | 363          |\n",
            "| mean 100 episode reward | 19.7         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2550505      |\n",
            "------------------------------------------\n",
            " 64% 2567881/4000000 [5:47:10<2:57:05, 134.78it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0879        |\n",
            "| elapsed time            | 06:06:25      |\n",
            "| episodes                | 23000         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008038103   |\n",
            "| loss_margin             | 0.000233192   |\n",
            "| loss_n_td               | 0.00067986164 |\n",
            "| loss_td                 | 0.09051509    |\n",
            "| losses_all              | 0.018908821   |\n",
            "| max 100 episode reward  | 346           |\n",
            "| mean 100 episode reward | 29.8          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2567892       |\n",
            "-------------------------------------------\n",
            " 65% 2584109/4000000 [5:49:24<3:01:31, 130.00it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0878        |\n",
            "| elapsed time            | 06:08:39      |\n",
            "| episodes                | 23100         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008052778   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00036554012 |\n",
            "| loss_td                 | 0.13279495    |\n",
            "| losses_all              | 0.019994523   |\n",
            "| max 100 episode reward  | 352           |\n",
            "| mean 100 episode reward | 23.7          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2584124       |\n",
            "-------------------------------------------\n",
            " 65% 2598518/4000000 [5:51:24<2:54:27, 133.89it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0876        |\n",
            "| elapsed time            | 06:10:39      |\n",
            "| episodes                | 23200         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008051266   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00012593559 |\n",
            "| loss_td                 | 0.069733456   |\n",
            "| losses_all              | 0.018944483   |\n",
            "| max 100 episode reward  | 366           |\n",
            "| mean 100 episode reward | 14.1          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2598526       |\n",
            "-------------------------------------------\n",
            " 65% 2599999/4000000 [5:51:36<3:01:53, 128.28it/s]saved checkpoint\n",
            " 65% 2613242/4000000 [5:53:27<2:54:01, 132.81it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0875      |\n",
            "| elapsed time            | 06:12:42    |\n",
            "| episodes                | 23300       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.008071469 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.004060754 |\n",
            "| loss_td                 | 0.06430073  |\n",
            "| losses_all              | 0.017405853 |\n",
            "| max 100 episode reward  | 269         |\n",
            "| mean 100 episode reward | 26          |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 2613254     |\n",
            "-----------------------------------------\n",
            " 66% 2629110/4000000 [5:55:34<2:43:03, 140.13it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0873       |\n",
            "| elapsed time            | 06:14:49     |\n",
            "| episodes                | 23400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.00806718   |\n",
            "| loss_margin             | 0.0037905201 |\n",
            "| loss_n_td               | 6.906983e-05 |\n",
            "| loss_td                 | 0.12524317   |\n",
            "| losses_all              | 0.023036828  |\n",
            "| max 100 episode reward  | 342          |\n",
            "| mean 100 episode reward | 23.9         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2629123      |\n",
            "------------------------------------------\n",
            " 66% 2644245/4000000 [5:57:35<2:47:32, 134.87it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0872      |\n",
            "| elapsed time            | 06:16:50    |\n",
            "| episodes                | 23500       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.008059856 |\n",
            "| loss_margin             | 0.004007114 |\n",
            "| loss_n_td               | 0.002619178 |\n",
            "| loss_td                 | 0.11973278  |\n",
            "| losses_all              | 0.022142017 |\n",
            "| max 100 episode reward  | 356         |\n",
            "| mean 100 episode reward | 17.9        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 2644253     |\n",
            "-----------------------------------------\n",
            " 66% 2658341/4000000 [5:59:28<2:37:25, 142.04it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.087        |\n",
            "| elapsed time            | 06:18:44     |\n",
            "| episodes                | 23600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008051478  |\n",
            "| loss_margin             | 0.013775375  |\n",
            "| loss_n_td               | 0.0012756069 |\n",
            "| loss_td                 | 0.16929945   |\n",
            "| losses_all              | 0.030056916  |\n",
            "| max 100 episode reward  | 347          |\n",
            "| mean 100 episode reward | 18.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2658354      |\n",
            "------------------------------------------\n",
            " 67% 2673471/4000000 [6:01:29<2:38:16, 139.68it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0869       |\n",
            "| elapsed time            | 06:20:44     |\n",
            "| episodes                | 23700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0080448035 |\n",
            "| loss_margin             | 0.005676519  |\n",
            "| loss_n_td               | 0.0026011    |\n",
            "| loss_td                 | 0.089148365  |\n",
            "| losses_all              | 0.018290542  |\n",
            "| max 100 episode reward  | 332          |\n",
            "| mean 100 episode reward | 21.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2673481      |\n",
            "------------------------------------------\n",
            " 67% 2687419/4000000 [6:03:22<2:33:38, 142.39it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0868        |\n",
            "| elapsed time            | 06:22:37      |\n",
            "| episodes                | 23800         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008035908   |\n",
            "| loss_margin             | 0.013421867   |\n",
            "| loss_n_td               | 0.00045964544 |\n",
            "| loss_td                 | 0.056239482   |\n",
            "| losses_all              | 0.015130145   |\n",
            "| max 100 episode reward  | 314           |\n",
            "| mean 100 episode reward | 21.8          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2687422       |\n",
            "-------------------------------------------\n",
            " 67% 2699987/4000000 [6:05:03<2:37:43, 137.38it/s]saved checkpoint\n",
            " 68% 2700585/4000000 [6:05:08<2:34:45, 139.94it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0867       |\n",
            "| elapsed time            | 06:24:23     |\n",
            "| episodes                | 23900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.00803331   |\n",
            "| loss_margin             | 0.011658311  |\n",
            "| loss_n_td               | 0.0033854633 |\n",
            "| loss_td                 | 0.20301867   |\n",
            "| losses_all              | 0.027447473  |\n",
            "| max 100 episode reward  | 222          |\n",
            "| mean 100 episode reward | 10.6         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2700598      |\n",
            "------------------------------------------\n",
            " 68% 2713473/4000000 [6:06:52<2:34:17, 138.97it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0865        |\n",
            "| elapsed time            | 06:26:07      |\n",
            "| episodes                | 24000         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008035801   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00013983356 |\n",
            "| loss_td                 | 0.07585256    |\n",
            "| losses_all              | 0.016876709   |\n",
            "| max 100 episode reward  | 365           |\n",
            "| mean 100 episode reward | 13.8          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2713486       |\n",
            "-------------------------------------------\n",
            " 68% 2727848/4000000 [6:08:48<2:29:10, 142.14it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0864        |\n",
            "| elapsed time            | 06:28:03      |\n",
            "| episodes                | 24100         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008039345   |\n",
            "| loss_margin             | 0.0041140206  |\n",
            "| loss_n_td               | 0.00040944444 |\n",
            "| loss_td                 | 0.0865376     |\n",
            "| losses_all              | 0.018795697   |\n",
            "| max 100 episode reward  | 378           |\n",
            "| mean 100 episode reward | 16.8          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2727861       |\n",
            "-------------------------------------------\n",
            " 69% 2742931/4000000 [6:10:50<2:36:08, 134.18it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0863       |\n",
            "| elapsed time            | 06:30:05     |\n",
            "| episodes                | 24200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008045994  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0058769966 |\n",
            "| loss_td                 | 0.27084428   |\n",
            "| losses_all              | 0.03034725   |\n",
            "| max 100 episode reward  | 361          |\n",
            "| mean 100 episode reward | 16.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2742940      |\n",
            "------------------------------------------\n",
            " 69% 2759245/4000000 [6:13:00<2:36:04, 132.50it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0861       |\n",
            "| elapsed time            | 06:32:16     |\n",
            "| episodes                | 24300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008043452  |\n",
            "| loss_margin             | 0.0029614344 |\n",
            "| loss_n_td               | 0.0004955443 |\n",
            "| loss_td                 | 0.13205495   |\n",
            "| losses_all              | 0.022256345  |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 21.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2759248      |\n",
            "------------------------------------------\n",
            " 69% 2773325/4000000 [6:14:55<2:26:35, 139.46it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.086        |\n",
            "| elapsed time            | 06:34:10     |\n",
            "| episodes                | 24400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008065223  |\n",
            "| loss_margin             | 0.0019368306 |\n",
            "| loss_n_td               | 0.024167236  |\n",
            "| loss_td                 | 0.05542455   |\n",
            "| losses_all              | 0.016276937  |\n",
            "| max 100 episode reward  | 281          |\n",
            "| mean 100 episode reward | 14.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2773332      |\n",
            "------------------------------------------\n",
            " 70% 2787969/4000000 [6:16:53<2:26:15, 138.11it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0859       |\n",
            "| elapsed time            | 06:36:08     |\n",
            "| episodes                | 24500        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008070966  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0015327642 |\n",
            "| loss_td                 | 0.07682      |\n",
            "| losses_all              | 0.017414043  |\n",
            "| max 100 episode reward  | 356          |\n",
            "| mean 100 episode reward | 16.7         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2787976      |\n",
            "------------------------------------------\n",
            " 70% 2799995/4000000 [6:18:30<2:22:56, 139.91it/s]saved checkpoint\n",
            " 70% 2803387/4000000 [6:18:58<2:29:04, 133.78it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0857        |\n",
            "| elapsed time            | 06:38:13      |\n",
            "| episodes                | 24600         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008077686   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 6.0833496e-05 |\n",
            "| loss_td                 | 0.11060388    |\n",
            "| losses_all              | 0.020695008   |\n",
            "| max 100 episode reward  | 339           |\n",
            "| mean 100 episode reward | 24.1          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2803397       |\n",
            "-------------------------------------------\n",
            " 70% 2818461/4000000 [6:20:59<2:25:31, 135.32it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0856       |\n",
            "| elapsed time            | 06:40:14     |\n",
            "| episodes                | 24700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008087075  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0038003395 |\n",
            "| loss_td                 | 0.2010575    |\n",
            "| losses_all              | 0.024014454  |\n",
            "| max 100 episode reward  | 336          |\n",
            "| mean 100 episode reward | 21.6         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2818464      |\n",
            "------------------------------------------\n",
            " 71% 2833978/4000000 [6:23:06<2:32:36, 127.35it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0855       |\n",
            "| elapsed time            | 06:42:21     |\n",
            "| episodes                | 24800        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0081009995 |\n",
            "| loss_margin             | 0.0012508072 |\n",
            "| loss_n_td               | 0.00411468   |\n",
            "| loss_td                 | 0.10642071   |\n",
            "| losses_all              | 0.020987732  |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 24.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2833989      |\n",
            "------------------------------------------\n",
            " 71% 2848675/4000000 [6:25:10<2:17:18, 139.75it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0854      |\n",
            "| elapsed time            | 06:44:25    |\n",
            "| episodes                | 24900       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.008115299 |\n",
            "| loss_margin             | 0.027018232 |\n",
            "| loss_n_td               | 0.015560675 |\n",
            "| loss_td                 | 0.11417938  |\n",
            "| losses_all              | 0.020578828 |\n",
            "| max 100 episode reward  | 355         |\n",
            "| mean 100 episode reward | 24.4        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 2848682     |\n",
            "-----------------------------------------\n",
            " 72% 2864037/4000000 [6:27:17<2:29:12, 126.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0852       |\n",
            "| elapsed time            | 06:46:33     |\n",
            "| episodes                | 25000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008107422  |\n",
            "| loss_margin             | 0.0020401385 |\n",
            "| loss_n_td               | 0.008674865  |\n",
            "| loss_td                 | 0.122319356  |\n",
            "| losses_all              | 0.020724151  |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 24.9         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2864041      |\n",
            "------------------------------------------\n",
            " 72% 2878529/4000000 [6:29:16<2:14:25, 139.05it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0851      |\n",
            "| elapsed time            | 06:48:32    |\n",
            "| episodes                | 25100       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.00811202  |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.02200277  |\n",
            "| loss_td                 | 0.096649505 |\n",
            "| losses_all              | 0.020007495 |\n",
            "| max 100 episode reward  | 366         |\n",
            "| mean 100 episode reward | 23.7        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 2878537     |\n",
            "-----------------------------------------\n",
            " 72% 2893273/4000000 [6:31:14<2:21:07, 130.71it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.085        |\n",
            "| elapsed time            | 06:50:30     |\n",
            "| episodes                | 25200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0081163375 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0132473    |\n",
            "| loss_td                 | 0.06670943   |\n",
            "| losses_all              | 0.01669845   |\n",
            "| max 100 episode reward  | 342          |\n",
            "| mean 100 episode reward | 17.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2893280      |\n",
            "------------------------------------------\n",
            " 72% 2899989/4000000 [6:32:09<2:14:52, 135.92it/s]saved checkpoint\n",
            " 73% 2909021/4000000 [6:33:20<2:12:30, 137.22it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0848       |\n",
            "| elapsed time            | 06:52:35     |\n",
            "| episodes                | 25300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008113607  |\n",
            "| loss_margin             | 0.0006501898 |\n",
            "| loss_n_td               | 0.011636807  |\n",
            "| loss_td                 | 0.093880326  |\n",
            "| losses_all              | 0.016819607  |\n",
            "| max 100 episode reward  | 378          |\n",
            "| mean 100 episode reward | 27           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2909033      |\n",
            "------------------------------------------\n",
            " 73% 2922900/4000000 [6:35:13<2:12:39, 135.32it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0847        |\n",
            "| elapsed time            | 06:54:28      |\n",
            "| episodes                | 25400         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008123126   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00015602136 |\n",
            "| loss_td                 | 0.07228024    |\n",
            "| losses_all              | 0.016534518   |\n",
            "| max 100 episode reward  | 343           |\n",
            "| mean 100 episode reward | 16.4          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2922909       |\n",
            "-------------------------------------------\n",
            " 73% 2937491/4000000 [6:37:10<2:08:42, 137.58it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0846        |\n",
            "| elapsed time            | 06:56:25      |\n",
            "| episodes                | 25500         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008131161   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00011349644 |\n",
            "| loss_td                 | 0.10301787    |\n",
            "| losses_all              | 0.015902396   |\n",
            "| max 100 episode reward  | 236           |\n",
            "| mean 100 episode reward | 17.9          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 2937501       |\n",
            "-------------------------------------------\n",
            " 74% 2950757/4000000 [6:38:58<2:10:04, 134.45it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0845      |\n",
            "| elapsed time            | 06:58:13    |\n",
            "| episodes                | 25600       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.008137434 |\n",
            "| loss_margin             | 0.005381331 |\n",
            "| loss_n_td               | 0.002692564 |\n",
            "| loss_td                 | 0.10706708  |\n",
            "| losses_all              | 0.018910214 |\n",
            "| max 100 episode reward  | 366         |\n",
            "| mean 100 episode reward | 11.1        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 2950761     |\n",
            "-----------------------------------------\n",
            " 74% 2966413/4000000 [6:41:03<2:05:04, 137.72it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0844       |\n",
            "| elapsed time            | 07:00:19     |\n",
            "| episodes                | 25700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.00814026   |\n",
            "| loss_margin             | 0.0028334446 |\n",
            "| loss_n_td               | 0.011339474  |\n",
            "| loss_td                 | 0.072536424  |\n",
            "| losses_all              | 0.027237402  |\n",
            "| max 100 episode reward  | 340          |\n",
            "| mean 100 episode reward | 18.5         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2966423      |\n",
            "------------------------------------------\n",
            " 74% 2979993/4000000 [6:42:53<2:05:14, 135.73it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0843       |\n",
            "| elapsed time            | 07:02:09     |\n",
            "| episodes                | 25800        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008140017  |\n",
            "| loss_margin             | 0.0068589244 |\n",
            "| loss_n_td               | 0.0006209879 |\n",
            "| loss_td                 | 0.0890342    |\n",
            "| losses_all              | 0.020391919  |\n",
            "| max 100 episode reward  | 342          |\n",
            "| mean 100 episode reward | 21.6         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2980008      |\n",
            "------------------------------------------\n",
            " 75% 2995180/4000000 [6:44:56<2:06:55, 131.94it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0842       |\n",
            "| elapsed time            | 07:04:12     |\n",
            "| episodes                | 25900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0081346035 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0031955973 |\n",
            "| loss_td                 | 0.1253666    |\n",
            "| losses_all              | 0.017249364  |\n",
            "| max 100 episode reward  | 327          |\n",
            "| mean 100 episode reward | 25.9         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 2995186      |\n",
            "------------------------------------------\n",
            " 75% 2999997/4000000 [6:45:37<2:10:57, 127.26it/s]saved checkpoint\n",
            " 75% 3010080/4000000 [6:47:00<1:55:14, 143.17it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.084        |\n",
            "| elapsed time            | 07:06:15     |\n",
            "| episodes                | 26000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008126613  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0003963345 |\n",
            "| loss_td                 | 0.14763173   |\n",
            "| losses_all              | 0.029722152  |\n",
            "| max 100 episode reward  | 378          |\n",
            "| mean 100 episode reward | 21.9         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3010092      |\n",
            "------------------------------------------\n",
            " 76% 3024861/4000000 [6:49:03<2:07:23, 127.57it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0839       |\n",
            "| elapsed time            | 07:08:18     |\n",
            "| episodes                | 26100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0081400825 |\n",
            "| loss_margin             | 0.0011096541 |\n",
            "| loss_n_td               | 0.0029815803 |\n",
            "| loss_td                 | 0.05439017   |\n",
            "| losses_all              | 0.014465753  |\n",
            "| max 100 episode reward  | 361          |\n",
            "| mean 100 episode reward | 22           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3024870      |\n",
            "------------------------------------------\n",
            " 76% 3039381/4000000 [6:51:04<2:01:43, 131.52it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0838       |\n",
            "| elapsed time            | 07:10:19     |\n",
            "| episodes                | 26200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008158195  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0032837298 |\n",
            "| loss_td                 | 0.08104302   |\n",
            "| losses_all              | 0.022123326  |\n",
            "| max 100 episode reward  | 313          |\n",
            "| mean 100 episode reward | 12.9         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3039393      |\n",
            "------------------------------------------\n",
            " 76% 3053909/4000000 [6:53:06<2:02:27, 128.76it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0837       |\n",
            "| elapsed time            | 07:12:21     |\n",
            "| episodes                | 26300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008158076  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0001662111 |\n",
            "| loss_td                 | 0.13509265   |\n",
            "| losses_all              | 0.019436946  |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 17.7         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3053909      |\n",
            "------------------------------------------\n",
            " 77% 3069306/4000000 [6:55:15<2:14:46, 115.10it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0836        |\n",
            "| elapsed time            | 07:14:31      |\n",
            "| episodes                | 26400         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008162466   |\n",
            "| loss_margin             | 0.00054304674 |\n",
            "| loss_n_td               | 0.00038846055 |\n",
            "| loss_td                 | 0.11181582    |\n",
            "| losses_all              | 0.016706953   |\n",
            "| max 100 episode reward  | 307           |\n",
            "| mean 100 episode reward | 22.5          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3069318       |\n",
            "-------------------------------------------\n",
            " 77% 3084177/4000000 [6:57:22<1:53:31, 134.45it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0835        |\n",
            "| elapsed time            | 07:16:37      |\n",
            "| episodes                | 26500         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008143948   |\n",
            "| loss_margin             | 0.0005538501  |\n",
            "| loss_n_td               | 0.00081326184 |\n",
            "| loss_td                 | 0.049779564   |\n",
            "| losses_all              | 0.014309326   |\n",
            "| max 100 episode reward  | 257           |\n",
            "| mean 100 episode reward | 13.4          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3084191       |\n",
            "-------------------------------------------\n",
            " 77% 3099547/4000000 [6:59:31<1:54:32, 131.02it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0834        |\n",
            "| elapsed time            | 07:18:46      |\n",
            "| episodes                | 26600         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0081413025  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00030045104 |\n",
            "| loss_td                 | 0.078195065   |\n",
            "| losses_all              | 0.017743096   |\n",
            "| max 100 episode reward  | 265           |\n",
            "| mean 100 episode reward | 20.3          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3099555       |\n",
            "-------------------------------------------\n",
            " 77% 3099997/4000000 [6:59:36<2:04:28, 120.50it/s]saved checkpoint\n",
            " 78% 3115099/4000000 [7:01:39<1:50:10, 133.86it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0833       |\n",
            "| elapsed time            | 07:20:54     |\n",
            "| episodes                | 26700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008136969  |\n",
            "| loss_margin             | 0.0024307743 |\n",
            "| loss_n_td               | 0.0017828582 |\n",
            "| loss_td                 | 0.08617337   |\n",
            "| losses_all              | 0.01727821   |\n",
            "| max 100 episode reward  | 343          |\n",
            "| mean 100 episode reward | 24.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3115111      |\n",
            "------------------------------------------\n",
            " 78% 3130177/4000000 [7:03:44<1:50:14, 131.50it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0832        |\n",
            "| elapsed time            | 07:22:59      |\n",
            "| episodes                | 26800         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008124261   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00042815524 |\n",
            "| loss_td                 | 0.1011969     |\n",
            "| losses_all              | 0.019826978   |\n",
            "| max 100 episode reward  | 366           |\n",
            "| mean 100 episode reward | 19.8          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3130181       |\n",
            "-------------------------------------------\n",
            " 79% 3145134/4000000 [7:05:49<1:48:50, 130.91it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0831        |\n",
            "| elapsed time            | 07:25:04      |\n",
            "| episodes                | 26900         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008117947   |\n",
            "| loss_margin             | 0.00767678    |\n",
            "| loss_n_td               | 0.00023610407 |\n",
            "| loss_td                 | 0.08142938    |\n",
            "| losses_all              | 0.016647927   |\n",
            "| max 100 episode reward  | 342           |\n",
            "| mean 100 episode reward | 18.6          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3145140       |\n",
            "-------------------------------------------\n",
            " 79% 3160425/4000000 [7:07:55<1:41:41, 137.61it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.083        |\n",
            "| elapsed time            | 07:27:10     |\n",
            "| episodes                | 27000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.00810981   |\n",
            "| loss_margin             | 0.0031424593 |\n",
            "| loss_n_td               | 0.028473843  |\n",
            "| loss_td                 | 0.14198928   |\n",
            "| losses_all              | 0.035495184  |\n",
            "| max 100 episode reward  | 233          |\n",
            "| mean 100 episode reward | 18.5         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3160436      |\n",
            "------------------------------------------\n",
            " 79% 3176237/4000000 [7:10:02<1:41:51, 134.80it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0829       |\n",
            "| elapsed time            | 07:29:17     |\n",
            "| episodes                | 27100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008112082  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0018298315 |\n",
            "| loss_td                 | 0.17397459   |\n",
            "| losses_all              | 0.028262416  |\n",
            "| max 100 episode reward  | 367          |\n",
            "| mean 100 episode reward | 28.5         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3176251      |\n",
            "------------------------------------------\n",
            " 80% 3180397/4000000 [7:10:34<1:34:31, 144.52it/s]saved best model\n",
            " 80% 3191487/4000000 [7:12:04<1:36:13, 140.04it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0828        |\n",
            "| elapsed time            | 07:31:19      |\n",
            "| episodes                | 27200         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008105334   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00018145048 |\n",
            "| loss_td                 | 0.2031956     |\n",
            "| losses_all              | 0.022724027   |\n",
            "| max 100 episode reward  | 380           |\n",
            "| mean 100 episode reward | 30.4          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3191492       |\n",
            "-------------------------------------------\n",
            " 80% 3199997/4000000 [7:13:13<1:37:00, 137.45it/s]saved checkpoint\n",
            " 80% 3205761/4000000 [7:14:00<1:32:48, 142.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0827       |\n",
            "| elapsed time            | 07:33:15     |\n",
            "| episodes                | 27300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008107659  |\n",
            "| loss_margin             | 0.0037679486 |\n",
            "| loss_n_td               | 0.001790884  |\n",
            "| loss_td                 | 0.17420158   |\n",
            "| losses_all              | 0.02128867   |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 15.7         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3205773      |\n",
            "------------------------------------------\n",
            " 81% 3222069/4000000 [7:16:11<1:39:09, 130.75it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0825       |\n",
            "| elapsed time            | 07:35:26     |\n",
            "| episodes                | 27400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008096843  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0047360007 |\n",
            "| loss_td                 | 0.07331663   |\n",
            "| losses_all              | 0.015924409  |\n",
            "| max 100 episode reward  | 361          |\n",
            "| mean 100 episode reward | 29           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3222079      |\n",
            "------------------------------------------\n",
            " 81% 3238473/4000000 [7:18:22<1:35:43, 132.58it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0824       |\n",
            "| elapsed time            | 07:37:38     |\n",
            "| episodes                | 27500        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0080871    |\n",
            "| loss_margin             | 0.00352275   |\n",
            "| loss_n_td               | 0.0009840793 |\n",
            "| loss_td                 | 0.070941105  |\n",
            "| losses_all              | 0.01803238   |\n",
            "| max 100 episode reward  | 329          |\n",
            "| mean 100 episode reward | 24.7         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3238486      |\n",
            "------------------------------------------\n",
            " 81% 3253299/4000000 [7:20:24<1:31:12, 136.45it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0823       |\n",
            "| elapsed time            | 07:39:40     |\n",
            "| episodes                | 27600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008080449  |\n",
            "| loss_margin             | 0.0047594924 |\n",
            "| loss_n_td               | 0.0023458912 |\n",
            "| loss_td                 | 0.08139403   |\n",
            "| losses_all              | 0.01617701   |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 18.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3253310      |\n",
            "------------------------------------------\n",
            " 82% 3270696/4000000 [7:22:43<1:25:43, 141.80it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0822       |\n",
            "| elapsed time            | 07:41:58     |\n",
            "| episodes                | 27700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008070353  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 4.261848e-05 |\n",
            "| loss_td                 | 0.08950502   |\n",
            "| losses_all              | 0.017393708  |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 31.9         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3270700      |\n",
            "------------------------------------------\n",
            " 82% 3285413/4000000 [7:24:42<1:30:32, 131.53it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0821       |\n",
            "| elapsed time            | 07:43:57     |\n",
            "| episodes                | 27800        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008063886  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0027765003 |\n",
            "| loss_td                 | 0.066177964  |\n",
            "| losses_all              | 0.014475632  |\n",
            "| max 100 episode reward  | 366          |\n",
            "| mean 100 episode reward | 23.6         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3285414      |\n",
            "------------------------------------------\n",
            " 82% 3299521/4000000 [7:26:36<1:23:24, 139.98it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.082         |\n",
            "| elapsed time            | 07:45:51      |\n",
            "| episodes                | 27900         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.008065087   |\n",
            "| loss_margin             | 0.00089459866 |\n",
            "| loss_n_td               | 0.0059287106  |\n",
            "| loss_td                 | 0.14176685    |\n",
            "| losses_all              | 0.018763203   |\n",
            "| max 100 episode reward  | 301           |\n",
            "| mean 100 episode reward | 16.2          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3299531       |\n",
            "-------------------------------------------\n",
            " 82% 3299988/4000000 [7:26:41<1:21:35, 142.99it/s]saved checkpoint\n",
            " 83% 3315797/4000000 [7:28:46<1:24:37, 134.74it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0819       |\n",
            "| elapsed time            | 07:48:01     |\n",
            "| episodes                | 28000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008046385  |\n",
            "| loss_margin             | 0.0020953678 |\n",
            "| loss_n_td               | 0.0028000262 |\n",
            "| loss_td                 | 0.09242988   |\n",
            "| losses_all              | 0.016543642  |\n",
            "| max 100 episode reward  | 360          |\n",
            "| mean 100 episode reward | 24           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3315804      |\n",
            "------------------------------------------\n",
            " 83% 3329775/4000000 [7:30:40<1:19:39, 140.24it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0819       |\n",
            "| elapsed time            | 07:49:55     |\n",
            "| episodes                | 28100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008037276  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0014094467 |\n",
            "| loss_td                 | 0.2449241    |\n",
            "| losses_all              | 0.022977833  |\n",
            "| max 100 episode reward  | 338          |\n",
            "| mean 100 episode reward | 10.2         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3329779      |\n",
            "------------------------------------------\n",
            " 84% 3344232/4000000 [7:32:36<1:16:28, 142.90it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0818      |\n",
            "| elapsed time            | 07:51:52    |\n",
            "| episodes                | 28200       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.00801713  |\n",
            "| loss_margin             | 0.010237996 |\n",
            "| loss_n_td               | 0.06502462  |\n",
            "| loss_td                 | 0.091947824 |\n",
            "| losses_all              | 0.018125288 |\n",
            "| max 100 episode reward  | 329         |\n",
            "| mean 100 episode reward | 18.5        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 3344243     |\n",
            "-----------------------------------------\n",
            " 84% 3359025/4000000 [7:34:37<1:14:46, 142.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0817       |\n",
            "| elapsed time            | 07:53:52     |\n",
            "| episodes                | 28300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.008000595  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0014333895 |\n",
            "| loss_td                 | 0.07806674   |\n",
            "| losses_all              | 0.015810719  |\n",
            "| max 100 episode reward  | 329          |\n",
            "| mean 100 episode reward | 15.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3359034      |\n",
            "------------------------------------------\n",
            " 84% 3373504/4000000 [7:36:37<1:16:38, 136.25it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0816      |\n",
            "| elapsed time            | 07:55:52    |\n",
            "| episodes                | 28400       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.007991298 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.000578693 |\n",
            "| loss_td                 | 0.067960694 |\n",
            "| losses_all              | 0.013987144 |\n",
            "| max 100 episode reward  | 309         |\n",
            "| mean 100 episode reward | 14          |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 3373513     |\n",
            "-----------------------------------------\n",
            " 85% 3388442/4000000 [7:38:37<1:16:59, 132.39it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0815       |\n",
            "| elapsed time            | 07:57:52     |\n",
            "| episodes                | 28500        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0079791015 |\n",
            "| loss_margin             | 0.0025367513 |\n",
            "| loss_n_td               | 0.0007015144 |\n",
            "| loss_td                 | 0.130213     |\n",
            "| losses_all              | 0.019885898  |\n",
            "| max 100 episode reward  | 281          |\n",
            "| mean 100 episode reward | 17.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3388444      |\n",
            "------------------------------------------\n",
            " 85% 3399999/4000000 [7:40:12<1:22:26, 121.29it/s]saved checkpoint\n",
            " 85% 3403057/4000000 [7:40:37<1:11:14, 139.66it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0814       |\n",
            "| elapsed time            | 07:59:52     |\n",
            "| episodes                | 28600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007985491  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0036835345 |\n",
            "| loss_td                 | 0.06407644   |\n",
            "| losses_all              | 0.014318695  |\n",
            "| max 100 episode reward  | 281          |\n",
            "| mean 100 episode reward | 15.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3403065      |\n",
            "------------------------------------------\n",
            " 85% 3417474/4000000 [7:42:35<1:13:44, 131.67it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0814        |\n",
            "| elapsed time            | 08:01:50      |\n",
            "| episodes                | 28700         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007986051   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00046660588 |\n",
            "| loss_td                 | 0.14916267    |\n",
            "| losses_all              | 0.019603442   |\n",
            "| max 100 episode reward  | 348           |\n",
            "| mean 100 episode reward | 20.2          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3417476       |\n",
            "-------------------------------------------\n",
            " 86% 3431689/4000000 [7:44:30<1:10:38, 134.09it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0813        |\n",
            "| elapsed time            | 08:03:45      |\n",
            "| episodes                | 28800         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007988958   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00022157004 |\n",
            "| loss_td                 | 0.15048866    |\n",
            "| losses_all              | 0.01786877    |\n",
            "| max 100 episode reward  | 366           |\n",
            "| mean 100 episode reward | 18.9          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3431701       |\n",
            "-------------------------------------------\n",
            " 86% 3445785/4000000 [7:46:26<1:11:15, 129.62it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0812       |\n",
            "| elapsed time            | 08:05:41     |\n",
            "| episodes                | 28900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007992493  |\n",
            "| loss_margin             | 7.693842e-05 |\n",
            "| loss_n_td               | 0.004928044  |\n",
            "| loss_td                 | 0.038890522  |\n",
            "| losses_all              | 0.013383007  |\n",
            "| max 100 episode reward  | 329          |\n",
            "| mean 100 episode reward | 22.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3445799      |\n",
            "------------------------------------------\n",
            " 87% 3461818/4000000 [7:48:35<1:02:47, 142.85it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0811       |\n",
            "| elapsed time            | 08:07:50     |\n",
            "| episodes                | 29000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007986915  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0032061026 |\n",
            "| loss_td                 | 0.061362132  |\n",
            "| losses_all              | 0.014130995  |\n",
            "| max 100 episode reward  | 377          |\n",
            "| mean 100 episode reward | 25.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3461828      |\n",
            "------------------------------------------\n",
            " 87% 3477057/4000000 [7:50:39<1:04:31, 135.08it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.081        |\n",
            "| elapsed time            | 08:09:54     |\n",
            "| episodes                | 29100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0079864375 |\n",
            "| loss_margin             | 0.003968343  |\n",
            "| loss_n_td               | 0.0013367825 |\n",
            "| loss_td                 | 0.13791966   |\n",
            "| losses_all              | 0.016663661  |\n",
            "| max 100 episode reward  | 305          |\n",
            "| mean 100 episode reward | 19.2         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3477060      |\n",
            "------------------------------------------\n",
            " 87% 3492350/4000000 [7:52:42<1:04:07, 131.95it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0809       |\n",
            "| elapsed time            | 08:11:58     |\n",
            "| episodes                | 29200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007981648  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0012476873 |\n",
            "| loss_td                 | 0.07543665   |\n",
            "| losses_all              | 0.016866755  |\n",
            "| max 100 episode reward  | 352          |\n",
            "| mean 100 episode reward | 21.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3492361      |\n",
            "------------------------------------------\n",
            " 87% 3499989/4000000 [7:53:44<58:24, 142.69it/s]saved checkpoint\n",
            " 88% 3508325/4000000 [7:54:51<59:09, 138.52it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0808        |\n",
            "| elapsed time            | 08:14:06      |\n",
            "| episodes                | 29300         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007981819   |\n",
            "| loss_margin             | 0.003696477   |\n",
            "| loss_n_td               | 0.00022829842 |\n",
            "| loss_td                 | 0.102413565   |\n",
            "| losses_all              | 0.01588383    |\n",
            "| max 100 episode reward  | 329           |\n",
            "| mean 100 episode reward | 23.2          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3508328       |\n",
            "-------------------------------------------\n",
            " 88% 3522781/4000000 [7:56:49<56:40, 140.33it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0808      |\n",
            "| elapsed time            | 08:16:04    |\n",
            "| episodes                | 29400       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.007973049 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.001552221 |\n",
            "| loss_td                 | 0.035476476 |\n",
            "| losses_all              | 0.012421574 |\n",
            "| max 100 episode reward  | 281         |\n",
            "| mean 100 episode reward | 15.6        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 3522784     |\n",
            "-----------------------------------------\n",
            " 88% 3538650/4000000 [7:58:56<55:54, 137.55it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0807        |\n",
            "| elapsed time            | 08:18:11      |\n",
            "| episodes                | 29500         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007964248   |\n",
            "| loss_margin             | 0.0033541527  |\n",
            "| loss_n_td               | 0.00045277795 |\n",
            "| loss_td                 | 0.05720307    |\n",
            "| losses_all              | 0.0135704465  |\n",
            "| max 100 episode reward  | 360           |\n",
            "| mean 100 episode reward | 27.7          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3538659       |\n",
            "-------------------------------------------\n",
            " 89% 3553552/4000000 [8:00:57<53:37, 138.78it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0806       |\n",
            "| elapsed time            | 08:20:12     |\n",
            "| episodes                | 29600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.00795135   |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0072616423 |\n",
            "| loss_td                 | 0.13470778   |\n",
            "| losses_all              | 0.019832388  |\n",
            "| max 100 episode reward  | 341          |\n",
            "| mean 100 episode reward | 20.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3553563      |\n",
            "------------------------------------------\n",
            " 89% 3569469/4000000 [8:03:05<50:59, 140.73it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0805      |\n",
            "| elapsed time            | 08:22:20    |\n",
            "| episodes                | 29700       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.007947678 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.001406145 |\n",
            "| loss_td                 | 0.10407303  |\n",
            "| losses_all              | 0.02085157  |\n",
            "| max 100 episode reward  | 365         |\n",
            "| mean 100 episode reward | 31.3        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 3569478     |\n",
            "-----------------------------------------\n",
            " 90% 3583365/4000000 [8:04:58<52:08, 133.16it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0804       |\n",
            "| elapsed time            | 08:24:14     |\n",
            "| episodes                | 29800        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007945716  |\n",
            "| loss_margin             | 0.0008388907 |\n",
            "| loss_n_td               | 0.009260325  |\n",
            "| loss_td                 | 0.14103203   |\n",
            "| losses_all              | 0.019468691  |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 18.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3583377      |\n",
            "------------------------------------------\n",
            " 90% 3599165/4000000 [8:07:07<49:55, 133.81it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0804        |\n",
            "| elapsed time            | 08:26:22      |\n",
            "| episodes                | 29900         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007933833   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00020469086 |\n",
            "| loss_td                 | 0.1290517     |\n",
            "| losses_all              | 0.021756519   |\n",
            "| max 100 episode reward  | 348           |\n",
            "| mean 100 episode reward | 23.4          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3599174       |\n",
            "-------------------------------------------\n",
            " 90% 3599997/4000000 [8:07:14<48:54, 136.29it/s]saved checkpoint\n",
            " 90% 3611874/4000000 [8:08:52<48:06, 134.46it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0803        |\n",
            "| elapsed time            | 08:28:08      |\n",
            "| episodes                | 30000         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007929522   |\n",
            "| loss_margin             | 0.00027002022 |\n",
            "| loss_n_td               | 0.0033859322  |\n",
            "| loss_td                 | 0.082664326   |\n",
            "| losses_all              | 0.015880756   |\n",
            "| max 100 episode reward  | 318           |\n",
            "| mean 100 episode reward | 8.97          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3611879       |\n",
            "-------------------------------------------\n",
            " 91% 3626208/4000000 [8:10:50<48:26, 128.58it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0802        |\n",
            "| elapsed time            | 08:30:05      |\n",
            "| episodes                | 30100         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007914587   |\n",
            "| loss_margin             | 0.0026272275  |\n",
            "| loss_n_td               | 0.00086726714 |\n",
            "| loss_td                 | 0.06713387    |\n",
            "| losses_all              | 0.012593323   |\n",
            "| max 100 episode reward  | 342           |\n",
            "| mean 100 episode reward | 12.6          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3626212       |\n",
            "-------------------------------------------\n",
            " 91% 3639977/4000000 [8:12:43<43:34, 137.69it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0802       |\n",
            "| elapsed time            | 08:31:58     |\n",
            "| episodes                | 30200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007904875  |\n",
            "| loss_margin             | 0.0144416485 |\n",
            "| loss_n_td               | 0.012281873  |\n",
            "| loss_td                 | 0.11527555   |\n",
            "| losses_all              | 0.0171659    |\n",
            "| max 100 episode reward  | 342          |\n",
            "| mean 100 episode reward | 14.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3639977      |\n",
            "------------------------------------------\n",
            " 91% 3655173/4000000 [8:14:46<42:28, 135.33it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0801       |\n",
            "| elapsed time            | 08:34:01     |\n",
            "| episodes                | 30300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007894638  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0004264217 |\n",
            "| loss_td                 | 0.12186215   |\n",
            "| losses_all              | 0.01464804   |\n",
            "| max 100 episode reward  | 362          |\n",
            "| mean 100 episode reward | 27           |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3655173      |\n",
            "------------------------------------------\n",
            " 92% 3668625/4000000 [8:16:36<39:46, 138.84it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.08         |\n",
            "| elapsed time            | 08:35:51     |\n",
            "| episodes                | 30400        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007881327  |\n",
            "| loss_margin             | 0.0072737634 |\n",
            "| loss_n_td               | 0.01555153   |\n",
            "| loss_td                 | 0.07476656   |\n",
            "| losses_all              | 0.013439587  |\n",
            "| max 100 episode reward  | 295          |\n",
            "| mean 100 episode reward | 14.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3668625      |\n",
            "------------------------------------------\n",
            " 92% 3683407/4000000 [8:18:35<38:28, 137.15it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.08         |\n",
            "| elapsed time            | 08:37:50     |\n",
            "| episodes                | 30500        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007855613  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0031156596 |\n",
            "| loss_td                 | 0.062715724  |\n",
            "| losses_all              | 0.0150592495 |\n",
            "| max 100 episode reward  | 290          |\n",
            "| mean 100 episode reward | 17.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3683409      |\n",
            "------------------------------------------\n",
            " 92% 3696725/4000000 [8:20:23<36:58, 136.71it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0799       |\n",
            "| elapsed time            | 08:39:38     |\n",
            "| episodes                | 30600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007827579  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0012653946 |\n",
            "| loss_td                 | 0.124532744  |\n",
            "| losses_all              | 0.018361164  |\n",
            "| max 100 episode reward  | 333          |\n",
            "| mean 100 episode reward | 17.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3696729      |\n",
            "------------------------------------------\n",
            " 92% 3699997/4000000 [8:20:50<39:46, 125.69it/s]saved checkpoint\n",
            " 93% 3711025/4000000 [8:22:20<34:00, 141.64it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0798       |\n",
            "| elapsed time            | 08:41:35     |\n",
            "| episodes                | 30700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007792252  |\n",
            "| loss_margin             | 0.0037227385 |\n",
            "| loss_n_td               | 0.0018829391 |\n",
            "| loss_td                 | 0.16112585   |\n",
            "| losses_all              | 0.015835006  |\n",
            "| max 100 episode reward  | 361          |\n",
            "| mean 100 episode reward | 20.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3711029      |\n",
            "------------------------------------------\n",
            " 93% 3723889/4000000 [8:24:04<34:25, 133.70it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0798        |\n",
            "| elapsed time            | 08:43:19      |\n",
            "| episodes                | 30800         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0077667297  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00048228083 |\n",
            "| loss_td                 | 0.15930548    |\n",
            "| losses_all              | 0.021160223   |\n",
            "| max 100 episode reward  | 197           |\n",
            "| mean 100 episode reward | 11.7          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3723903       |\n",
            "-------------------------------------------\n",
            " 93% 3738302/4000000 [8:25:59<32:58, 132.29it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0797       |\n",
            "| elapsed time            | 08:45:14     |\n",
            "| episodes                | 30900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007750511  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0004308756 |\n",
            "| loss_td                 | 0.22056723   |\n",
            "| losses_all              | 0.016603602  |\n",
            "| max 100 episode reward  | 318          |\n",
            "| mean 100 episode reward | 15.3         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3738311      |\n",
            "------------------------------------------\n",
            " 94% 3749649/4000000 [8:27:33<30:59, 134.61it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0796       |\n",
            "| elapsed time            | 08:46:48     |\n",
            "| episodes                | 31000        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0077538644 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0036501172 |\n",
            "| loss_td                 | 0.048543207  |\n",
            "| losses_all              | 0.0128464475 |\n",
            "| max 100 episode reward  | 366          |\n",
            "| mean 100 episode reward | 13.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3749653      |\n",
            "------------------------------------------\n",
            " 94% 3764473/4000000 [8:29:31<28:09, 139.39it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0796      |\n",
            "| elapsed time            | 08:48:46    |\n",
            "| episodes                | 31100       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.007757243 |\n",
            "| loss_margin             | 0.013601452 |\n",
            "| loss_n_td               | 0.075861074 |\n",
            "| loss_td                 | 0.07297418  |\n",
            "| losses_all              | 0.017247647 |\n",
            "| max 100 episode reward  | 342         |\n",
            "| mean 100 episode reward | 25.1        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 3764475     |\n",
            "-----------------------------------------\n",
            " 94% 3779377/4000000 [8:31:34<26:40, 137.88it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0795       |\n",
            "| elapsed time            | 08:50:49     |\n",
            "| episodes                | 31200        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0077522006 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.004491403  |\n",
            "| loss_td                 | 0.11101135   |\n",
            "| losses_all              | 0.017645262  |\n",
            "| max 100 episode reward  | 355          |\n",
            "| mean 100 episode reward | 18.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3779387      |\n",
            "------------------------------------------\n",
            " 95% 3794795/4000000 [8:33:42<25:54, 131.99it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0795       |\n",
            "| elapsed time            | 08:52:57     |\n",
            "| episodes                | 31300        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0077499803 |\n",
            "| loss_margin             | 0.0025996268 |\n",
            "| loss_n_td               | 0.0007845357 |\n",
            "| loss_td                 | 0.08083263   |\n",
            "| losses_all              | 0.0160412    |\n",
            "| max 100 episode reward  | 366          |\n",
            "| mean 100 episode reward | 31.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3794804      |\n",
            "------------------------------------------\n",
            " 95% 3799987/4000000 [8:34:26<25:44, 129.53it/s]saved checkpoint\n",
            " 95% 3810721/4000000 [8:35:54<23:19, 135.27it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0794        |\n",
            "| elapsed time            | 08:55:09      |\n",
            "| episodes                | 31400         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0077430266  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00090989494 |\n",
            "| loss_td                 | 0.23838791    |\n",
            "| losses_all              | 0.020831607   |\n",
            "| max 100 episode reward  | 365           |\n",
            "| mean 100 episode reward | 21.6          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3810721       |\n",
            "-------------------------------------------\n",
            " 96% 3824239/4000000 [8:37:44<22:03, 132.76it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0793       |\n",
            "| elapsed time            | 08:57:00     |\n",
            "| episodes                | 31500        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007727994  |\n",
            "| loss_margin             | 0.0025504231 |\n",
            "| loss_n_td               | 0.0013430412 |\n",
            "| loss_td                 | 0.11109276   |\n",
            "| losses_all              | 0.01935358   |\n",
            "| max 100 episode reward  | 333          |\n",
            "| mean 100 episode reward | 12.8         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3824252      |\n",
            "------------------------------------------\n",
            " 96% 3838343/4000000 [8:39:39<19:31, 137.95it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0793       |\n",
            "| elapsed time            | 08:58:54     |\n",
            "| episodes                | 31600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0077230893 |\n",
            "| loss_margin             | 0.01995873   |\n",
            "| loss_n_td               | 0.0033403705 |\n",
            "| loss_td                 | 0.106346115  |\n",
            "| losses_all              | 0.015497532  |\n",
            "| max 100 episode reward  | 333          |\n",
            "| mean 100 episode reward | 22.4         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3838354      |\n",
            "------------------------------------------\n",
            " 96% 3854537/4000000 [8:41:49<17:25, 139.09it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0792       |\n",
            "| elapsed time            | 09:01:04     |\n",
            "| episodes                | 31700        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007726715  |\n",
            "| loss_margin             | 0.0005305074 |\n",
            "| loss_n_td               | 0.047743887  |\n",
            "| loss_td                 | 0.088335544  |\n",
            "| losses_all              | 0.023394194  |\n",
            "| max 100 episode reward  | 366          |\n",
            "| mean 100 episode reward | 22.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3854542      |\n",
            "------------------------------------------\n",
            " 97% 3868497/4000000 [8:43:43<16:02, 136.67it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0791       |\n",
            "| elapsed time            | 09:02:58     |\n",
            "| episodes                | 31800        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007718093  |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0006492977 |\n",
            "| loss_td                 | 0.04357574   |\n",
            "| losses_all              | 0.011964206  |\n",
            "| max 100 episode reward  | 347          |\n",
            "| mean 100 episode reward | 16.7         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3868507      |\n",
            "------------------------------------------\n",
            " 97% 3881881/4000000 [8:45:33<14:27, 136.11it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0791       |\n",
            "| elapsed time            | 09:04:48     |\n",
            "| episodes                | 31900        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0077103544 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.004748749  |\n",
            "| loss_td                 | 0.1726691    |\n",
            "| losses_all              | 0.0283415    |\n",
            "| max 100 episode reward  | 360          |\n",
            "| mean 100 episode reward | 16.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3881891      |\n",
            "------------------------------------------\n",
            " 97% 3897435/4000000 [8:47:40<12:13, 139.86it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.079         |\n",
            "| elapsed time            | 09:06:55      |\n",
            "| episodes                | 32000         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0076970016  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00028465095 |\n",
            "| loss_td                 | 0.106304556   |\n",
            "| losses_all              | 0.015959872   |\n",
            "| max 100 episode reward  | 365           |\n",
            "| mean 100 episode reward | 28.1          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3897436       |\n",
            "-------------------------------------------\n",
            " 97% 3899999/4000000 [8:48:01<12:42, 131.17it/s]saved checkpoint\n",
            " 98% 3913853/4000000 [8:49:52<10:26, 137.60it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0789       |\n",
            "| elapsed time            | 09:09:08     |\n",
            "| episodes                | 32100        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.0076913424 |\n",
            "| loss_margin             | 0.0          |\n",
            "| loss_n_td               | 0.0018691588 |\n",
            "| loss_td                 | 0.1120795    |\n",
            "| losses_all              | 0.019306999  |\n",
            "| max 100 episode reward  | 350          |\n",
            "| mean 100 episode reward | 31.1         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3913855      |\n",
            "------------------------------------------\n",
            " 98% 3930009/4000000 [8:52:02<08:23, 139.13it/s]-----------------------------------------\n",
            "| % time spent exploring  | 1           |\n",
            "| demo sample rate        | 0.0789      |\n",
            "| elapsed time            | 09:11:18    |\n",
            "| episodes                | 32200       |\n",
            "| epsilon                 | 0.01        |\n",
            "| loss_l2                 | 0.007681616 |\n",
            "| loss_margin             | 0.0         |\n",
            "| loss_n_td               | 0.002239331 |\n",
            "| loss_td                 | 0.35855284  |\n",
            "| losses_all              | 0.0252461   |\n",
            "| max 100 episode reward  | 365         |\n",
            "| mean 100 episode reward | 25.5        |\n",
            "| min 100 episode reward  | 0           |\n",
            "| pre_train               | False       |\n",
            "| steps                   | 3930010     |\n",
            "-----------------------------------------\n",
            " 99% 3945817/4000000 [8:54:09<06:40, 135.28it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0788        |\n",
            "| elapsed time            | 09:13:25      |\n",
            "| episodes                | 32300         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0076710894  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00063328876 |\n",
            "| loss_td                 | 0.2733444     |\n",
            "| losses_all              | 0.02273454    |\n",
            "| max 100 episode reward  | 365           |\n",
            "| mean 100 episode reward | 25.6          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3945817       |\n",
            "-------------------------------------------\n",
            " 99% 3959917/4000000 [8:56:03<04:43, 141.27it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0787        |\n",
            "| elapsed time            | 09:15:18      |\n",
            "| episodes                | 32400         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.007649011   |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 0.00037338576 |\n",
            "| loss_td                 | 0.08303512    |\n",
            "| losses_all              | 0.0140975285  |\n",
            "| max 100 episode reward  | 261           |\n",
            "| mean 100 episode reward | 10.2          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3959922       |\n",
            "-------------------------------------------\n",
            " 99% 3975433/4000000 [8:58:06<03:01, 135.62it/s]-------------------------------------------\n",
            "| % time spent exploring  | 1             |\n",
            "| demo sample rate        | 0.0787        |\n",
            "| elapsed time            | 09:17:21      |\n",
            "| episodes                | 32500         |\n",
            "| epsilon                 | 0.01          |\n",
            "| loss_l2                 | 0.0076361327  |\n",
            "| loss_margin             | 0.0           |\n",
            "| loss_n_td               | 1.8699373e-05 |\n",
            "| loss_td                 | 0.1466997     |\n",
            "| losses_all              | 0.016082931   |\n",
            "| max 100 episode reward  | 322           |\n",
            "| mean 100 episode reward | 25.3          |\n",
            "| min 100 episode reward  | 0             |\n",
            "| pre_train               | False         |\n",
            "| steps                   | 3975441       |\n",
            "-------------------------------------------\n",
            "100% 3989969/4000000 [9:00:03<01:14, 134.77it/s]------------------------------------------\n",
            "| % time spent exploring  | 1            |\n",
            "| demo sample rate        | 0.0786       |\n",
            "| elapsed time            | 09:19:18     |\n",
            "| episodes                | 32600        |\n",
            "| epsilon                 | 0.01         |\n",
            "| loss_l2                 | 0.007617157  |\n",
            "| loss_margin             | 0.00601802   |\n",
            "| loss_n_td               | 0.0028948027 |\n",
            "| loss_td                 | 0.061684318  |\n",
            "| losses_all              | 0.013714639  |\n",
            "| max 100 episode reward  | 365          |\n",
            "| mean 100 episode reward | 20.9         |\n",
            "| min 100 episode reward  | 0            |\n",
            "| pre_train               | False        |\n",
            "| steps                   | 3989971      |\n",
            "------------------------------------------\n",
            "100% 4000000/4000000 [9:01:23<00:00, 123.14it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u3ghxyr50fh",
        "colab_type": "code",
        "outputId": "56748710-6a1b-4599-f666-382e31c546e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "!git status "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch master\n",
            "Your branch is up to date with 'origin/master'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
            "\n",
            "\t\u001b[31mmodified:   run_atari.py\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_9L_dwWbBoZ",
        "colab_type": "code",
        "outputId": "d443fad9-bc96-4515-c502-690cdd863c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!git add . \n",
        "!git commit -m \"add print freq\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master 59c461c] add print freq\n",
            " 1 file changed, 3 insertions(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwMQX0RXFcSg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a82585f1-5e92-453b-c93c-93061bac5f6d"
      },
      "source": [
        "!git reset --hard HEAD^"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HEAD is now at 0fb4d10 Merge branch 'master' of https://github.com/Kokkini/DQfD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A2hNQE_bMcN",
        "colab_type": "code",
        "outputId": "ff697c94-b50d-447c-d976-bbc4e44156f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "!git push"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 3, done.\n",
            "Delta compression using up to 4 threads.\n",
            "Compressing objects:  33% (1/3)   \rCompressing objects:  66% (2/3)   \rCompressing objects: 100% (3/3)   \rCompressing objects: 100% (3/3), done.\n",
            "Writing objects:  33% (1/3)   \rWriting objects:  66% (2/3)   \rWriting objects: 100% (3/3)   \rWriting objects: 100% (3/3), 380 bytes | 380.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas:   0% (0/2)\u001b[K\rremote: Resolving deltas:  50% (1/2)\u001b[K\rremote: Resolving deltas: 100% (2/2)\u001b[K\rremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/Kokkini/DQfD.git\n",
            "   0fb4d10..59c461c  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAZjuQCVbN-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}